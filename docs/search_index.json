[["index.html", "GOING Genomic of Individual Growth Preface", " GOING Genomic of Individual Growth Sylvain Schmitt 2021-02-24 Preface This numeric book support all the analyses of the GOING project on the Genomic of Individual Growth in tropical tree species Symphonia globulifera. Have a nice reading. Sylvain "],["introduction.html", "Introduction", " Introduction In the present study, we assessed genotypic diversity within closely-related sympatric tree species belonging to the widespread tropical tree species complex Symphonia globulifera. We addressed the fine-scale spatial and temporal genetic adaptations of individuals through differential growth strategies in response to forest gap dynamics. We finally compared the breadth of successional niches encountered by Symphonia species to other locally abundant species. Combining tree diameter censuses, indirect measures of light environment of the recent past and present, and single nucleotide polymorphisms (SNPs), we used population genomics, environmental association analyses, genome wide association and growth modelling to address the following questions: Are individual genotypes structured by the mosaic of light and competition environments resulting from forest gap dynamics? Is the growth of individuals determined by genotypes? Is there an association between genotypic adaptations to gap dynamics and to growth? How are genotypic adaptations to gap dynamics and to growth structured in time, i.e., across life stages? Are breadths of successional niches for Symphonia species wider than those of other locally abundant species? "],["study-site-sampling.html", "Chapter 1 Study site &amp; sampling 1.1 Study site 1.2 Plant material", " Chapter 1 Study site &amp; sampling 1.1 Study site The study was conducted in the Paracou field station, in the coastal forests of French Guiana, South America. The site is characterized by an average of 3,041 mm annual rainfall and a mean air temperature of 25.71 °C (Aguilos et al. 2018). Old tropical forest with an exceptional richness (i.e. over 750 woody species) grows across the succession of small hills of this area, which rise to 10–40 m a.s.l. (Gourlet-Fleury et al. 2004). The site comprises 16 permanent plots (fifteen 6.25 ha plus one 25 ha) which have been censused (DBH&gt;10) every 1-2 years for more than 35 years. Nine of the plots were logged and subjected to human-induced disturbance in 1986 (details on the experiment in Hérault &amp; Piponiot 2018). 1.2 Plant material Four hundred and two individuals of Symphonia globulifera (Clusiaceae) were sampled in 2017 during the dry season (from September to December) in Paracou. Symphonia globulifera L.f (Clusiaceae) was previously recognized as composed of two morphotypes in French Guiana (Sabatier et al. 1997; Molino &amp; Sabatier 2001; Baraloto et al. 2007). S. globulifera sensu stricto and Symphonia sp.1 occur in sympatry but in differentiated habitats, with S. globulifera preferentially growing in valley bottoms with an acquisitive functional strategy and S. sp1 preferentially exploiting a variety of drier habitats with a conservative functional strategy (Schmitt 2020, in prep; Allié et al. 2015; Schmitt et al. 2020). Symphonia have been highlighted as a species complex with low (phylo-)genetic species resolution and high levels of plastid DNA sharing among sister species (Baraloto et al. 2012; Gonzalez et al. 2009; Torroba-Balmori et al. 2017; Caron et al. 2019). In addition, outgroups for genetic analysis in Symphonia were comprised of 13 individuals of Symphonia globulifera from Africa (Sao Tome, Gabon, Cameroun, Congo, Benin, Liberia, Ivory Coast, and Ghana), seven Symphonia globulifera from South America (Brazil, Costa Rica and Panama), two Symphonia nectarifera Jum. &amp; H. Perrier from Madagascar, two Symphonia urophylla (Decne. ex Planch. &amp; Triana) Benth. &amp; Hook.f. ex Vesque from Madagascar, five Pentadesma butyracea Sabine from Benin and Cameroon and one Pentadesma grandifolia Baker f. from Cameroon. Leaves were collected from the 432 individuals (402 + 30 outgroups) and dessicated using silica gel. References "],["design-of-probes-set.html", "Chapter 2 Design of probes set 2.1 Scotti et al. (in prep) scaffolds preparation 2.2 Olsson et al. (2017) scaffolds preparation 2.3 Tysklind et al (in prep) transcript preparation 2.4 Neutral region selection 2.5 Fuctional region selection", " Chapter 2 Design of probes set The genomic and transcriptomic resources used for the design were comprised of a published low-coverage draft genome from Africa (Olsson et al. 2017), an unpublished draft genome from French Guiana [Scotti et al., in prep], an unpublished transcriptome from 20 juveniles from French Guiana [Tysklind et al., in prep], and reduced-representation genomic sequence reads of individuals from French Guiana [Torroba-Balmori et al., unpublished]. We aligned genomic reads on the two genome drafts with bwa (Li &amp; Durbin 2009). We kept scaffolds from the two genome drafts with a length superior to 1 kbp and at least one matching alignment with a read with a single match on the genome, and merged the two filtered genome drafts with quickmerge (Chakraborty et al. 2016). We aligned transcripts on the new filtered genome draft with BLAT (Kent 2002) and selected 533 scaffolds without transcript-match, i.e. anonymous scaffolds. We masked repetitive regions with RepeatMasker (Smit et al. 2015) and selected 533 1-kbp anonymous loci within the 533 previous scaffolds. Similarly, we filtered transcripts from the 20 juveniles of Symphonia globulifera from French Guiana [Tysklind et al., in prep] based on SNP quality, type and frequency. We further detected open reading frames (ORFs) using transdecoder (Haas et al. 2013), and selected transcripts with non-overlapping ORFs including a start codon. We kept ORFs with an alignment on scaffolds from the aforementioned genome draft for Symphonia using BLAT (Kent 2002), and masked repetitive regions with RepeatMasker (Smit et al. 2015). We selected 1,150 genic loci of 500-bp to 1-kbp, from 100 bp before the start to a maximum of 900 bp after the end of the ORFs, resulting in 1-Mbp genomic loci that included a coding region. 2.1 Scotti et al. (in prep) scaffolds preparation 2.1.1 Filtering scaffolds over \\(1kbp\\) We first filtered scaffolds with a width superior to 1000 bp. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/ mkdir scf_1000 for scf in $( ls raw/ | grep scafSeq$); do echo item: $scf perl ~/Tools/SeqFilter/bin/SeqFilter -l 1000 raw/$scf --out scf_1000/$scf done 2.1.2 Renaming For all scaffolds we used the following code : **Ivan_2018_[file name without .scafSeq]_[scaffold name]**. dir.create(file.path(path, &quot;Ivan_2018&quot;, &quot;renamed_scf_1000&quot;)) files &lt;- list.files(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;)) sapply(files, function(file){ scf &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;, file)) names(scf) &lt;- paste0(&quot;Ivan_2018_&quot;, gsub(&quot;.scafSeq&quot;, &quot;&quot;, file), &quot;_&quot;, gsub(&quot; &quot;, &quot;_&quot;, names(scf))) writeXStringSet(scf, file.path(path, &quot;Ivan_2018&quot;, &quot;renamed_scf_1000&quot;, paste0(gsub(&quot;.scafSeq&quot;, &quot;&quot;, file), &quot;.1000.renamed.scafSeq&quot;))) }, simplify = F) unlink(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;), recursive = T) 2.1.3 Libraries merging We successively merged scaffolds from 6 libraries with quickmerge. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/renamed_scf_1000 ref=(sympho47_1L1_002.1000.renamed.scafSeq merge1.fasta merge2.fasta merge3.fasta merge4.fasta merge5.fasta merge6.fasta merge7.fasta) query=(sympho47_1L2_001.1000.renamed.scafSeq sympho47_2L1_008.1000.renamed.scafSeq sympho47_2L1_009.1000.renamed.scafSeq sympho47_2L1_010.1000.renamed.scafSeq sympho47_2L1_011.1000.renamed.scafSeq sympho47_2L1_012.1000.renamed.scafSeq sympho47_3L2_013.1000.renamed.scafSeq sympho47_4L1_014.1000.renamed.scafSeq) for i in {0..7} do mkdir merge$i cp &quot;${ref[$i]}&quot; &quot;${query[$i]}&quot; ./merge$i/ cd merge$i nucmer -l 100 -prefix out ${ref[$i]} ${query[$i]} delta-filter -i 95 -r -q out.delta &gt; out.rq.delta ~/Tools/quickmerge/quickmerge -d out.rq.delta -q ${query[$i]} -r ${ref[$i]} -hco 5.0 -c 1.5 -l n -ml m cd .. cp merge$i/merged.fasta ./merge$((i+1)).fasta done cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018 mkdir merged_1000 cp renamed_scf_1000/merge5/merged.fasta merged_1000/merged_1000.fa cd merged_1000 makeblastdb -in merged_1000.fa -parse_seqids -dbtype nucl 2.1.4 Removing scaffolds with multimatch blasted consensus sequence from Torroba-Balmori et al. (unpublished) We used the consensus sequence for French Guianan reads from Torroba-Balmori et al. (unpublished) previously assembled with ipyrad. We kept the first sequence of the consensus loci file and recoded it to fasta (see loci2fa.py script below). We then blasted the consensus sequences on merged scaffolds from Scotti et al (in prep) with blastn in order to detect scaffolds with repetitive regions (multi-mapped consensus sequences). Repetitive sequences have been saved as a list removed in final selected scaffolds list. infile = open(&quot;symphoGbS2.loci&quot;, &quot;r&quot;) outfile = open(&quot;symphoGbS2.firstline.fasta&quot;, &quot;w&quot;) loci = infile.read().split(&quot;|\\n&quot;)[:-1] for loc in loci: reads = loc.split(&quot;\\n&quot;) name, seq = reads[0].split() print &gt;&gt;outfile, &quot;&gt;&quot;+name+&quot;\\n&quot;+seq outfile.close() cd ~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfile python loci2fa.py cat symphoGbS2.firstline.fasta | tr - N &gt;&gt; symphoGbS2.firstline.fasta cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018 query=~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfiles/symphoGbS2.firstline.fasta blastn -db merged_1000/merged_1000.fa -query $query -out blast_consensus_torroba2.txt -evalue 1e-10 -best_hit_score_edge 0.05 -best_hit_overhang 0.25 -outfmt 6 -perc_identity 75 -max_target_seqs 10 blast &lt;- read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_blast&quot;, &quot;blast_consensus_torroba2.txt&quot;), col_names = F) names(blast) &lt;- c(&quot;Read&quot;, &quot;Scaffold&quot;, &quot;Perc_Ident&quot;, &quot;Alignment_length&quot;, &quot;Mismatches&quot;, &quot;Gap_openings&quot;, &quot;R_start&quot;, &quot;R_end&quot;, &quot;S_start&quot;, &quot;S_end&quot;, &quot;E&quot;, &quot;Bits&quot;) write_file(paste(unique(blast$Scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_blast&quot;, &quot;selected_scaffolds_blast_consensus2.list&quot;)) seqtk subseq merged_1000/merged_1000.fa selected_scaffolds_blast_consensus2.list &gt;&gt; selected_scaffolds_blast_consensus2.fa In total 542 scaffolds from Scotti et al (in prep) matched consensus sequences from Torroba-Balmori et al. (unpublished). Several scaffolds obtained multiple matches that we cannot use for probes. We thus excluded the whole scaffold if the scaffold is shorter than 2000 bp, or the scaffold region matching the raw read if the scaffold is longer than 2000 bp. Figure 2.1: Number of match with Torroba consensus reads vs gene width. Table 2.1: Scaffold to cut due to multiple read match. Scaffold width remove cut Ivan_2018_sympho47_2L1_012_scaffold197676__8.6 4993 4993-4932 Ivan_2018_sympho47_2L1_012_scaffold246452__6.6 3103 2980-3058 Ivan_2018_sympho47_2L1_012_scaffold26367__7.7 2168 2118-2168 Ivan_2018_sympho47_2L1_012_scaffold463128__4.7 2188 667-586 Ivan_2018_sympho47_2L1_008_scaffold309475__2.1 3525 342-292 Following scaffolds have been removed due to multiple matches and a length \\(&lt;200bp\\): 2L1_012_scaffold645876__7.5, 2L1_012_scaffold176548__7.1, 2L1_012_scaffold21882__4.9, 2L1_012_scaffold9236__6.0. The others have been cut (see table 2.1). 2.1.5 Total filtered scaffolds 2.2 Olsson et al. (2017) scaffolds preparation African genome from Olsson et al. (2017). 2.2.1 Renaming We renamed scaffolds from Olsson using the following code : Olsson_2017_[scaffold name]. scf &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;symph_genome.fa&quot;)) names(scf) &lt;- paste0(&#39;Olsson_2017_&#39;, names(scf)) dir.create(file.path(path, &quot;Olsson_2016&quot;, &quot;db&quot;)) writeXStringSet(scf, file.path(path, &quot;Olsson_2016&quot;, &quot;db&quot;, &quot;Olsson2017.fa&quot;))) 2.2.2 Removing scaffolds with multimatch blasted consensus sequence from Torroba-Balmori et al. (unpublished) We used the consensus sequence for French Guianan reads from Torroba-Balmori et al. (unpublished), by blasting them on scaffolds from Olsson et al. (2017) with blastn. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016 cd Olsson2017 makeblastdb -in Olsson2017.fa -parse_seqids -dbtype nucl cd .. query=~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfiles/symphoGbS2.firstline.fasta blastn -db Olsson2017/Olsson2017.fa -query $query -out blast_consensus_torroba2.txt -evalue 1e-10 -best_hit_score_edge 0.05 -best_hit_overhang 0.25 -outfmt 6 -perc_identity 75 -max_target_seqs 10 blast &lt;- read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_blast&quot;, &quot;blast_consensus_torroba2.txt&quot;), col_names = F) names(blast) &lt;- c(&quot;Read&quot;, &quot;Scaffold&quot;, &quot;Perc_Ident&quot;, &quot;Alignment_length&quot;, &quot;Mismatches&quot;, &quot;Gap_openings&quot;, &quot;R_start&quot;, &quot;R_end&quot;, &quot;S_start&quot;, &quot;S_end&quot;, &quot;E&quot;, &quot;Bits&quot;) write_file(paste(unique(blast$Scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_blast&quot;, &quot;selected_scaffolds_blast_consensus2.list&quot;)) seqtk subseq Olsson2017/Olsson2017.fa selected_scaffolds_blast_consensus2.list &gt;&gt; selected_scaffolds_blast_consensus2.fa We obtained most of scaffolds with a single match including a broad range of sizes (from 100 bp to 33.2 kbp). In total 688 scaffolds from Olsson et al. (2017) match consensus sequences from Torroba-Balmori et al. (unpublished). Deveral scaffolds obtained multiple matches that we cannot use for probes. We thus excluded the whole scaffold if the scaffold is shorter than 2000 bp, or the scaffold region matching the raw read if the scaffold is longer than 2000 bp. Figure 2.2: Number of match with Torroba consensus reads vs gene width. Table 2.2: Scaffold to cut due to multiple read match. Scaffold width remove cut Olsson_2017_deg7180004393135 2380 1700-1631 Olsson_2017_deg7180004374686 2120 2073-1992 Olsson_2017_scf7180005372912 3152 3102-3152 Olsson_2017_scf7180005387046 2048 174-256 Olsson_2017_scf7180005323991 2482 2330-2267 Following scaffolds have been removed due to multiple matches and a length \\(&lt;200bp\\): deg7180004378417, deg7180003744575, deg7180002657883, deg7180004705895, deg7180004369764, deg7180002776754, deg7180004453462, deg7180004453461, deg7180002668453, deg7180005298947, deg7180003723902, deg7180005298948, deg7180004372504, deg7180002659849, deg7180004372505, deg7180004377385, deg7180003260802, deg7180003625436, deg7180004705895, deg7180002776754, deg7180004705894, deg7180002852093, deg7180004822905, deg7180005023024, deg7180004478675, deg7180004428004, deg7180004428003, deg7180004507379, deg7180002656221, deg7180004374687, deg7180004372498, deg7180004372497, deg7180002654368, deg7180002674357, deg7180004700334, deg7180004899808, deg7180004899808, deg7180002726303, scf7180005372913, deg7180005163225, deg7180003214542, scf7180005400822, deg7180005163224, deg7180003138164, deg7180004981997, deg7180004981996, deg7180005171251, deg7180005106503, deg7180003910181, deg7180005026532, deg7180003853280, deg7180004724986, deg7180005246885, deg7180004710959, deg7180004681149, deg7180004580422, deg7180004472718, deg7180003290510, deg7180005004768, deg7180004756559, scf7180005435685, deg7180004725719, deg7180004599019, deg7180004599018, deg7180002749392, deg7180002739372, deg7180004754314, deg7180004847375, deg7180004580009, deg7180004386399, deg7180004377195, deg7180004377194, deg7180004399409, deg7180004392029, deg7180004385805, deg7180004386398, deg7180002816623, deg7180002985310, scf7180005421751, deg7180004374725, deg7180004372798, deg7180004374726, deg7180002668107, deg7180003199928, deg7180003093903, deg7180003310549, deg7180004796671, deg7180003505925, deg7180002988969. And other have been cut (see table 2.2). 2.2.3 Total filtered scaffolds 2.3 Tysklind et al (in prep) transcript preparation Tysklind et al (in prep) used 20 Symphonia juveniles from the transplantation garden experiment for transcriptomic analysis. RNA sequence were captured. The analysis followed the scheme suggested by Lopez-Maestre et al. (2016) (see below). First, reads were assembled with Trinity into transcripts. In parallel, SNPs were detected with Kissplice. Then SNPs have been mapped on the transcritpome with BLAT. In parallel SNPs have been tested to be morphotype-specific at the level \\(\\alpha = 0.001\\) with KissDE and transcriptome Open Reading Frames (ORF) have been identified with Transdecoder. Finally, SNPs functional impact have been evaluated through k2rt. Consequently, for every SNP we have the following information: (i) inside coding DNA sequence (CDS), (ii) synonymous or not, (iii) morphotype-specificity. Analysis scheme from Lopez-Maestre et al. (2016). 2.3.1 Filtering SNP on quality We assessed transcriptomic analysis quality with possible sequencing errors, and SNPs in multiple assembled genes or isoforms (see table 2.3). We found 38 594 SNPs with possible sequencing error, and 609 214 SNPs associated to multiple assembled genes that we removed from further analysis. Table 2.3: Quality check with single SNPs. variable n Percentage 2.3.2 Filtering SNP on type We also highlighted SNPs which met impossible association of characteristic (table 2.4), that we removed from further analysis. Table 2.4: Single SNPs with unpossible association of characteristic. First column indicates if the SNP is in a coding sequence, second column indicates is the SNP is not synonymous, third column indicates if the SNP is morphotype-specific, and fourth column indicates the headcount. Coding sequence Not synonymous Morphotype-specific n type False False morphotype specific 9 505 unpossible False False morphotype specific 5 362 unpossible False True morphotype specific 11 819 unpossible False True morphotype specific 5 565 unpossible N/A False morphotype specific 42 unpossible N/A False morphotype specific 21 unpossible N/A N/A morphotype specific 2 557 unpossible N/A N/A morphotype specific 424 unpossible N/A True morphotype specific 63 unpossible N/A True morphotype specific 9 unpossible True N/A morphotype specific 26 482 unpossible True N/A morphotype specific 14 342 unpossible 2.3.3 Filtering transcripts on SNP frequency We found a high frequency of SNPs per candidate genes (the majority between 1 SNP per 10 or 100 bp), with some scaffolds having a frequency superior to 0.2 (see figure 2.3). We assumed those hyper SNP-rich scaffolds to be errors and decided to remove them of the reference transcriptome. In order to do that, we fitted a \\(\\Gamma\\) law into the SNP frequency distribution and we kept scaffolds with a SNP frequency under the \\(99^{th}\\) quantile (\\(q_{99} = 0.07810194\\)). We thus removed: 358 308 SNPs including 20 521 transcripts representing 1 490 candidate genes Figure 2.3: Distribution of SNP frequencies in scaffolds. Histogram (gray bars) represents the data, red line represents the Gamma law fit, and blue area represents X*sigma were scaffolds are not excluded. filtered_data &lt;- snp_genes %&gt;% filter(freq &lt;= q99) %&gt;% left_join(data, by = &quot;gene_id&quot;) %&gt;% select(transcript_id, sequence) %&gt;% unique() %&gt;% mutate(transcript_id = paste0(&quot;&gt;&quot;, transcript_id)) filtered_data_fasta &lt;- do.call(rbind, lapply(seq(nrow(filtered_data)), function(i) t(filtered_data[i, ]))) write.table(filtered_data_fasta, row.names = F, col.names = F, quote = F, file = file.path(path, &quot;..&quot;, &quot;filtered_transcripts.fasta&quot;)) 2.3.4 Total filtered transcript We have a total of: 1 382 525 filtered SNPs (over 2 398 550) including 177 388 transcripts (over 257 140, including pseudo-genes isoforms) representing 63 707 candidate genes (over 76 032) for a total of Mbp 2.4 Neutral region selection 2.4.1 Raw reads from Torroba-Balmori et al. (unpublished) alignment on scaffolds from Scotti et al. (in prep) We used the French Guianan raw reads from Torroba-Balmori et al. (unpublished), by aligning them on scaffolds from Olsson et al. (2017) with bwa. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J alignIvan #SBATCH -o alignIvan_output.out #SBATCH -e alignIvan_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL # Environment module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 # read preparation cd ~/work/Symphonia_Torroba/ tar -xvzf Gbs.tar.gz cd raw rm PR_49.fastq RG_1.fastq for file in ./*.fastq do echo $file filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; perl -pe &#39;s|[\\h]||g&#39; $file &gt; &quot;${filename}&quot;.renamed.fastq rm $file done # variables cd ~/work/Symphonia_Genomes/Ivan_2018/torroba_alignment reference=~/work/Symphonia_Genomes/Ivan_2018/merged_1000/merged_1000.fa query_path=~/work/Symphonia_Torroba/raw # alignment bwa index $reference mkdir bwa for file in $query_path/*.fastq do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; rg=&quot;@RG\\tID:${filename}\\tSM:${filename}\\tPL:IONTORRENT&quot; bwa mem -M -R &quot;${rg}&quot; $reference $file &gt; bwa/&quot;${filename}.sam&quot; # rm $file done # sam2bam for file in ./bwa/*.sam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD SortSam I=$file O=bwa/&quot;${filename}&quot;.bam SORT_ORDER=coordinate done # Bam index for file in bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD BuildBamIndex I=$file O=bwa/&quot;${filename}&quot;.bai done # sam2bed mkdir bed for file in ./bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools bamtobed -i bwa/&quot;${filename}&quot;.bam &gt; bed/&quot;${filename}&quot;.bed done # merge bed mkdir merged_bed for file in ./bed/*.bed do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools merge -i bed/&quot;${filename}&quot;.bed &gt; merged_bed/&quot;${filename}&quot;.bed done cat bed/* | sort -k 1,1 -k2,2n &gt; all.nonunique.bed bedtools merge -i all.nonunique.bed -c 1 -o count &gt; all.merged.bed bed &lt;- read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;all.merged.bed&quot;), col_names = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;coverage&quot;) write_file(paste(unique(bed$scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/merged_1000/merged_1000.fa seqtk subseq $ref scaffolds.list &gt;&gt; scaffolds.fa Table 2.5: alignment coverage summary N Width (Mbp) Coverage (%) aligned sequence 1 786 852 130.3105 29.87923 selected scaffold 179 665 421.7514 96.70448 total 190 098 436.1239 100.00000 2.4.2 Masking scaffolds with multimatch from Scotti et al. (in prep) bed &lt;- data.table::fread(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;all.nonunique.bed&quot;), header = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;read&quot;, &quot;quality&quot;, &quot;orientation&quot;) multimatch_reads &lt;- bed %&gt;% filter(duplicated(read)) %&gt;% select(read) %&gt;% unique() %&gt;% unlist() bed %&gt;% filter(read %in% multimatch_reads) %&gt;% write_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;multimatch.bed&quot;), col_names = F) rm(bed, multimatch_reads) ; invisible(gc()) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment bedtools maskfasta -fi scaffolds.fa -bed multimatch.bed -fo masked.scaffolds.fa scf &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;masked.scaffolds.fa&quot;)) scf &lt;- data.frame(scaffold = names(scf), width = width(scf), N = letterFrequency(scf, letters = &quot;N&quot;)) %&gt;% mutate(Nperc = N/width*100) %&gt;% filter(Nperc &lt; 25 &amp; width &gt; 1000) %&gt;% select(scaffold) write_file(paste(scf$scaffold, collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment seqtk subseq masked.scaffolds.fa final.scaffolds.list &gt;&gt; final.scaffolds.fa Table 2.6: alignment coverage summary N Width (Mbp) Mask (%N) Coverage (%) selected scaffold 315 226 776.5915 6.651114 178.0667 total 190 098 436.1239 NA 100.0000 2.4.3 Raw reads from Torroba-Balmori et al. (unpublished) alignment on scaffolds from Olsson et al. (2017) We used again the French Guianan raw reads from Torroba-Balmori et al. (unpublished), to align them on scaffolds from Olsson et al. (2017) with bwa. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J alignOlsson #SBATCH -o alignOlsson_output.out #SBATCH -e alignOlsson_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL # Environment module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 # read preparation cd ~/work/Symphonia_Torroba/ tar -xvzf Gbs.tar.gz cd raw rm PR_49.fastq RG_1.fastq for file in ./*.fastq do echo $file filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; perl -pe &#39;s|[\\h]||g&#39; $file &gt; &quot;${filename}&quot;.renamed.fastq rm $file done # variables cd ~/work/Symphonia_Genomes/Olsson_2016/torroba_alignment reference=~/work/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa query_path=~/work/Symphonia_Torroba/raw # alignment bwa index $reference mkdir bwa for file in $query_path/*.fastq do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; rg=&quot;@RG\\tID:${filename}\\tSM:${filename}\\tPL:IONTORRENT&quot; bwa mem -M -R &quot;${rg}&quot; $reference $file &gt; bwa/&quot;${filename}.sam&quot; rm $file done # sam2bam for file in ./bwa/*.sam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD SortSam I=$file O=bwa/&quot;${filename}&quot;.bam SORT_ORDER=coordinate done # Bam index for file in bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD BuildBamIndex I=$file O=bwa/&quot;${filename}&quot;.bai done # sam2bed mkdir bed for file in ./bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools bamtobed -i bwa/&quot;${filename}&quot;.bam &gt; bed/&quot;${filename}&quot;.bed done # merge bed mkdir merged_bed for file in ./bed/*.bed do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools merge -i bed/&quot;${filename}&quot;.bed &gt; merged_bed/&quot;${filename}&quot;.bed done cat bed/* | sort -k 1,1 -k2,2n &gt; all.nonunique.bed bedtools merge -i all.nonunique.bed -c 1 -o count &gt; all.merged.bed bed &lt;- read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;all.merged.bed&quot;), col_names = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;coverage&quot;) write_file(paste(unique(bed$scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa seqtk subseq $ref scaffolds.list &gt;&gt; scaffolds.fa Table 2.7: alignment coverage summary N Width (Mbp) Coverage (%) aligned sequence 1 786 852 130.3105 12.68385 selected scaffold 1 056 548 590.1957 57.44708 total 2 653 526 1 027.3729 100.00000 2.4.4 Masking scaffolds with multimatch from Olsson et al. (2017) bed &lt;- data.table::fread(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;all.nonunique.bed&quot;), header = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;read&quot;, &quot;quality&quot;, &quot;orientation&quot;) multimatch_reads &lt;- bed %&gt;% filter(duplicated(read)) %&gt;% select(read) %&gt;% unique() %&gt;% unlist() bed %&gt;% filter(read %in% multimatch_reads) %&gt;% write_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;multimatch.bed&quot;), col_names = F) rm(bed, multimatch_reads) ; invisible(gc()) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment bedtools maskfasta -fi scaffolds.fa -bed multimatch.bed -fo masked.scaffolds.fa scf &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;masked.scaffolds.fa&quot;)) scf &lt;- data.frame(scaffold = names(scf), width = width(scf), N = letterFrequency(scf, letters = &quot;N&quot;)) %&gt;% mutate(Nperc = N/width*100) %&gt;% filter(Nperc &lt; 25 &amp; width &gt; 1000) %&gt;% select(scaffold) write_file(paste(scf$scaffold, collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa seqtk subseq masked.scaffolds.fa final.scaffolds.list &gt;&gt; final.scaffolds.fa Table 2.8: alignment coverage summary N Width (Mbp) Mask (%N) Coverage (%) selected scaffold 245 646 464.1304 1.896894 45.17643 total 2 653 526 1 027.3729 NA 100.00000 2.4.5 Removing scaffolds already matching transcripts func &lt;-unlist(read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;transcript_alignment&quot;, &quot;selected_scaffolds.list&quot;), col_names = F)) neutral &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.fa&quot;)) writeXStringSet(neutral[setdiff(names(neutral), func)], file.path(path, &quot;neutral_selection&quot;, &quot;Ivan.selected.scaffolds.fa&quot;)) func &lt;-unlist(read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;transcript_alignment&quot;, &quot;selected_scaffolds.list&quot;), col_names = F)) neutral &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.fa&quot;)) writeXStringSet(neutral[setdiff(names(neutral), func)], file.path(path, &quot;neutral_selection&quot;, &quot;Olsson.selected.scaffolds.fa&quot;)) 2.4.6 Merge of selected scaffolds We merged selected scaffolds from Scotti et al (in prep) and Olsson et al. (2017) with quickmerge. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection ref=Ivan.selected.scaffolds.fa query=Olsson.selected.scaffolds.fa nucmer -l 100 -prefix out $ref $query delta-filter -i 95 -r -q out.delta &gt; out.rq.delta ~/Tools/quickmerge/quickmerge -d out.rq.delta -q $query -r $ref -hco 5.0 -c 1.5 -l n -ml m We merged selected scaffolds from Scotti et al (in prep) and Olsson et al. (2017) with quickmerge. We found 13 343 overlaps resulting a final merged assembly of 82 792 scaffolds for a total length of 146.80 Mb. Figure 2.4: Merging result from quickmerge. Left graph represents the overlap distribution. Right graph represent the merged scaffolds distribution. 2.4.7 Final subset of selected neutral scaffolds We finally selected 0.533 Mb of sequences by sampling 533 1-kb sequences among 533 scaffolds (1 sequence per scaffold) with a probability \\(p=\\frac{scaffold\\_length}{total\\_length}\\). scf &lt;- readDNAStringSet(file.path(path, &quot;neutral_selection&quot;, &quot;merged.fasta&quot;)) selection &lt;- data.frame(scf = names(scf), width = width(scf), N = letterFrequency(scf, &quot;N&quot;)) %&gt;% sample_n(533, weight = width) %&gt;% select(scf) %&gt;% unlist() scf_sel &lt;- subseq(scf[selection], end=1000, width=1000) writeXStringSet(scf_sel, file.path(path, &quot;neutral_selection&quot;, &quot;selected.scaffolds.fa&quot;)) Table 2.9: Selected neutral scaffolds N Width (Mbp) Mask (%N) 533 0.533 0.0036529 2.4.8 Repetitive regions final check Last but not least, we do not want to include repetitive regions in our targets for baits design. We consequently aligned raw reads from one library from Scotti et al. (in prep) on our targets with bwa. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection reference=selected.scaffolds.fa query=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/raw_reads/globu1_symphonia_globulifera_CTTGTA_L001_R1_001.fastq.gz bwa index $reference bwa mem -M $reference $query &gt; raw_read_alignment.sam picard=~/Tools/picard/picard.jar java -Xmx4g -jar $picard SortSam I=raw_read_alignment.sam O=raw_read_alignment.bam SORT_ORDER=coordinate bedtools bamtobed -i raw_read_alignment.bam &gt; raw_read_alignment.bed cat raw_read_alignment.bed | sort -k 1,1 -k2,2n &gt; raw_read_alignment.sorted.bed bedtools merge -i raw_read_alignment.sorted.bed -c 1 -o count &gt; raw_read_alignment.merged.bed We obtained a continuous decreasing distribution of read coverage across our scaffolds regions (figure 2.5). We fitted a \\(\\Gamma\\) distribution with positive parameters for scaffolds regions with a coverage under 5 000 (non continuous distribution with optimization issues). We obtained a distribution with a mean of 324 reads per region and a \\(99^{th}\\) quantile of 4 042. We decided to mask regions with a coverage over the \\(99^{th}\\) quantile and remove scaffolds with a mask superior to 75% of its total length (figure ??). Figure 2.5: Read coverage distribution. repetitive_target &lt;- bed %&gt;% filter(coverage &gt; qgamma(0.99, alpha, beta)) %&gt;% mutate(size = end - start) repetitive_target %&gt;% select(target, start, end) %&gt;% arrange(target, start, end) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;neutral_selection&quot;, &quot;repetitive_targets.bed&quot;), col_names = F) Figure 2.6: target regions with a coverage over the 99th quantile of the fitted Gamma distribution (4042). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection cat repetitive_targets.bed | sort -k 1,1 -k2,2n &gt; repetitive_targets.sorted.bed bedtools maskfasta -fi selected.scaffolds.fa -bed repetitive_targets.sorted.bed -fo targets.masked.fasta targets &lt;- readDNAStringSet(file.path(path, &quot;neutral_selection&quot;, &quot;targets.masked.fasta&quot;)) writeXStringSet(targets[which(letterFrequency(targets, &quot;N&quot;)/width(targets) &lt; 0.65)], file.path(path, &quot;neutral_selection&quot;, &quot;targets.filtered.masked.fasta&quot;)) Table 2.10: Selected, masked and filtered funcional targets. N Width (Mbp) Mask (%N) 415 0.415 0.024412 2.5 Fuctional region selection We used open reading frames (ORF) to target genes within scaffolds. ORFs have been detected with transdecoder on assembled transcripts. First, we filtered ORFs including a start codon(figure 2.7). Then, we aligned ORFs on pre-selected and merged genomic scaffolds with blat. We obtained 7 744 aligned scaffolds (table 2.11 and figure 2.8). Thanks to alignments, we removed overlapping genes (figure 2.9) and obtained 4 076 pre-selected genes with a total length of 757 hbp (figure 2.10). Finally, we used transcript differential expression to select all genes deferentially expressed between Symphonia globulifera and Symphonia sp1 (figure 2.11). We selected 1150 sequences of 500 to 1-kbp representing 1 063 Mbp (table 2.12). To validate our final target set, we aligned with bwa raw reads from one library from Scotti et al. (in prep). 2.5.1 Open Reading Frames (ORFs) filtering 173 828 ORFs including a start codon (Methyonin, M) were detected (over 231 883, 75%, see figure 2.7. Figure 2.7: Open Reading Frames left and right peptides. orf &lt;- src_sqlite(file.path(path, &quot;Niklas_transcripts/Trinotate/&quot;, &quot;symphonia.trinity500.trinotate.sqlite&quot;)) %&gt;% tbl(&quot;ORF&quot;) %&gt;% dplyr::rename(orf = orf_id, trsc = transcript_id, orfSize = length) %&gt;% filter(substr(peptide, 1, 1) == &quot;M&quot;) %&gt;% select(-peptide, -strand) %&gt;% collect() %&gt;% rowwise() %&gt;% mutate(orfStart = min(as.numeric(lend), as.numeric(rend)), orfEnd = max(as.numeric(lend), as.numeric(rend))) %&gt;% select(-lend, -rend) %&gt;% select(trsc, orfStart, orfEnd, orf) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;orf.all.bed&quot;), col_names = F) 2.5.2 ORF alignment on genomics scaffolds 7 744 scaffolds matched with ORFs (10.5% for 15.4 Mbp, see table 2.11 and figure 2.8). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat orf.all.bed | sort -k 1,1 -k2,2n &gt; orf.all.sorted.bed trsc=/home/sylvain/Documents/BIOGECO/PhD/data/Symphonia_Niklas/filtered_transcripts.fasta bedtools getfasta -name -fi $trsc -bed orf.all.sorted.bed -fo orf.fasta scf=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection/merged.fasta orf=./orf.fasta blat $scf $orf alignment.psl Table 2.11: Alignment coverage of Tysklind et al. (in prep) ORFs over genomic scaffolds with blat. N Width (Mbp) Coverage (%) aligned sequence 21 146 2.201315 1.499565 selected scaffold 7 744 15.425248 10.507881 total 82 792 146.796946 100.000000 Figure 2.8: Alignment result of Tysklind et al. (in prep) ORFs over genomic scaffolds with blat. Left graph represents the overlap distribution. Right graph represent the selected and deduplicated scaffolds distribution. 2.5.3 Overlaping genes filtering 995 genes were overlapping and filtered out (figure 2.9). alignment %&gt;% separate(orf, into = c(&quot;gene&quot;, &quot;isoform&quot;, &quot;geneNumber&quot;, &quot;orfNumber&quot;), sep = &quot;::&quot;, remove = F) %&gt;% select(gene, orf, orfStart, orfEnd, scf, scfStart, scfEnd) %&gt;% unique() %&gt;% select(scf, scfStart, scfEnd, orf, gene) %&gt;% arrange(scf, scfStart, scfEnd) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;genes.all.bed&quot;), col_names = F) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat genes.all.bed | sort -k 1,1 -k2,2n &gt; genes.all.sorted.bed bedtools merge -i genes.all.sorted.bed -c 5 -o collapse &gt; genes.merged.bed Figure 2.9: Genes overlap 2.5.4 Pre-selected genes We obtained 4 076 genes pre-selected for a total length of 757 kbp (figure 2.10). Figure 2.10: Available genes for target sequences design. 2.5.5 Differential Expression (DE) of genes Figure 2.11 shows genes differential expression. First circle represent genes with isoforms not enriched whereas second and third circle represents respectivelly genes with isoforms S. sp1 and S. globulifera enriched. Relatively few genes contained enriched isoforms, and most of them were S. globulifera enriched. Legend Figure 2.11: Genes differential expression. 2.5.6 Final subset of selected functional scaffolds We finally selected 1150 sequences of 500 to 1-kbp with 100 bp before geneStart and a maximum of 900 bp after, resulting in 1 063, 544 kbp of targets. All differentially expressed genes between morphotypes were selected (159). And the rest of sequences were selected among non differentially expressed genes randomly (1001). targets &lt;- genes %&gt;% left_join(de) %&gt;% filter(deg %in% c(&quot;Eglo&quot;, &quot;Esp&quot;)) %&gt;% rbind(genes %&gt;% left_join(de) %&gt;% filter(deg %in% c(&quot;DE&quot;, NA)) %&gt;% sample_n(1309)) %&gt;% group_by(scf, gene) %&gt;% filter(n() &lt; 2) %&gt;% mutate(targetStart = max(0, geneStart - 100)) %&gt;% mutate(targetEnd = min(targetStart + 1000, scfSize)) %&gt;% mutate(targetSize = targetEnd - targetStart) %&gt;% filter(targetSize &gt; 500) %&gt;% mutate(target = paste0(gene, &quot;_on_&quot;, scf)) %&gt;% ungroup() targets %&gt;% select(scf, targetStart, targetEnd, target) %&gt;% arrange(scf, targetStart, targetEnd, target) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;targets.all.bed&quot;), col_names = F) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat targets.all.bed | sort -k 1,1 -k2,2n &gt; targets.all.sorted.bed scf=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection/merged.fasta bedtools getfasta -name -fi $scf -bed targets.all.sorted.bed -fo targets.fasta Table 2.12: Selected functional targets N Width (Mbp) Mask (%N) 1 165 1.068207 0.0025285 2.5.7 Repetitive regions final check Last but not least, we do not want to include repetitive regions in our targets for baits design. We consequently aligned raw reads from one library from Scotti et al. (in prep) on our targets with bwa. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 reference=targets.fasta query=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/raw_reads/globu1_symphonia_globulifera_CTTGTA_L001_R1_001.fastq.gz bwa index $reference bwa mem -M $reference $query &gt; raw_read_alignment.sam picard=~/Tools/picard/picard.jar java -Xmx4g -jar $picard SortSam I=raw_read_alignment.sam O=raw_read_alignment.bam SORT_ORDER=coordinate bedtools bamtobed -i raw_read_alignment.bam &gt; raw_read_alignment.bed cat raw_read_alignment.bed | sort -k 1,1 -k2,2n &gt; raw_read_alignment.sorted.bed bedtools merge -i raw_read_alignment.sorted.bed -c 1 -o count &gt; raw_read_alignment.merged.bed We obtained a continuous decreasing distribution of read coverage across our scaffolds regions (figure 2.12). We fitted a \\(\\Gamma\\) distribution with positive parameters for scaffolds regions with a coverage under 5 000 (non continuous distribution with optimization issues). We obtained a distribution with a mean of 309 reads per region and a \\(99^{th}\\) quantile of 2 606. We decided to mask regions with a coverage over the \\(99^{th}\\) quantile and remove scaffolds with a mask superior to 75% of its total length (figure ??). Figure 2.12: Read coverage distribution. repetitive_target &lt;- bed %&gt;% filter(coverage &gt; qgamma(0.99, alpha, beta)) %&gt;% mutate(size = end - start) repetitive_target %&gt;% select(target, start, end) %&gt;% arrange(target, start, end) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;repetitive_targets.bed&quot;), col_names = F) Figure 2.13: target regions with a coverage over the 99th quantile of the fitted Gamma distribution (2606). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat repetitive_targets.bed | sort -k 1,1 -k2,2n &gt; repetitive_targets.sorted.bed bedtools maskfasta -fi targets.fasta -bed repetitive_targets.sorted.bed -fo targets.masked.fasta targets &lt;- readDNAStringSet(file.path(path, &quot;functional_selection2&quot;, &quot;targets.masked.fasta&quot;)) writeXStringSet(targets[which(letterFrequency(targets, &quot;N&quot;)/width(targets) &lt; 0.65)], file.path(path, &quot;functional_selection2&quot;, &quot;targets.filtered.masked.fasta&quot;)) Table 2.13: Selected, masked and filtered funcional targets. N Width (Mbp) Mask (%N) 975 0.896759 0.0168273 References "],["genomic-libraries-and-sequence-capture.html", "Chapter 3 Genomic libraries and sequence capture 3.1 Plates 3.2 Libraries preparation protocol 3.3 Libraries preparation results 3.4 Capture 3.5 Amplifcation 2 and Library Repeat Plates reorganization 3.6 Pool building 3.7 Purification &amp; Concentration 3.8 Size assessment 3.9 Size selection 3.10 Capture", " Chapter 3 Genomic libraries and sequence capture Genomic DNA was extracted from 5 mg of dried leaf tissue with a CTAB protocol (Doyle &amp; Doyle 1987). DNA extracts were digested with ‘Ultra II FS Enzyme Mix’ (new England Biolabs Inc, MA, USA) for a target size of 150 bp, and libraries built with the ‘NEBNext Ultra II FS DNA Library Prep kit for Illumina’(New England Biolabs Inc, MA, USA). We amplified and tagged libraries using 5 \\(\\mu L\\) of adaptor-ligated DNA, 8.3 \\(\\mu L\\) of ‘NEBNext Ultra II Q5 Master Mix’ (new England Biolabs Inc, MA, USA), 2x 1.6 \\(\\mu L\\) of Index Primer i5 and i7 from ‘NEBNext Multiplex Oligos for Illumina (Dual Index Primers Set 1 and Set 2)’ (new England Biolabs Inc, MA, USA). Initial denaturation (98°C for 30 s) was followed by 8 cycles (98°C for 10 s and 65°C for 1 min 30 s) and a final extension (65°C for 5 min). We pooled libraries in four equimolar multiplexes for each genus. We obtained a custom made set of 20,000 80-mer probes for each genus using myBaits Custom 1-20K (Arbor Biosciences, MI, USA) and conducted the capture experiments using the corresponding myBaits V4 protocol with a hybridization time of 80 hours. We pooled the four multiplexes and sequenced them in two lanes of an Illumina HiSeq 4000 instrument obtaining 2x150bp pair-end reads for each genus. 3.1 Plates This sub-chapter describes plates preparation after the extraction and before libraries preparation. First we looked into plates design after extraction. Then we quantified their concentration, volume and DNA quantity, before rearranging them based on their concentration. Finally plates concentration was adjusted to 20 \\(ng.\\mu L^{-1}\\) and sorted by electrophoresis evaluation. 3.1.1 Extraction 3.1.1.1 Extraction Plates Plates after extraction were arranged following figure 3.1. Figure 3.1: Extraction plates organization All plates were quantified through NanoDrop and some of them with Qbit which is more accurate We used Qbit-NanoDrop relation to have an estimation of concentration for all samples. Finally electrophoresis were also used to asses DNA quality and degradation. 3.1.1.2 Extraction NanoDrop NanoDrop evaluated \\(1 \\mu L\\) of samples DNA concentration (figure 3.2) by absorption in addition to contamination. But NanoDrop is known to be inaccurate, especially under 25 \\(ng.\\mu L^{-1}\\). Figure 3.2: Extraction plate NanoDrop concentration (in ng/microL) 3.1.1.3 Extraction QBit We used Qbit on 12 samples to have a more precise idea of samples concentration. Qbit uses fluorescence to measure samples concentration in \\(ng.\\mu L^{-1}\\). We compared QBit estimation of concentration to NanoDrop estimation. We used a bayesian approach to fit the model \\(Concentration_{Qbit} \\sim \\mathcal{N}(\\beta*Concentration_{NanoDrop},\\sigma)\\) with a null intercept. We found a pretty strong relation with a beta around 0.3. We used this relation to better estimate the concentration of all samples. ## Running /usr/lib/R/bin/R CMD SHLIB foo.c ## gcc -std=gnu99 -I&quot;/usr/share/R/include&quot; -DNDEBUG -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/Rcpp/include/&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/unsupported&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/BH/include&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/StanHeaders/include/src/&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/StanHeaders/include/&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppParallel/include/&quot; -I&quot;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/rstan/include&quot; -DEIGEN_NO_DEBUG -DBOOST_DISABLE_ASSERTS -DBOOST_PENDING_INTEGER_LOG2_HPP -DSTAN_THREADS -DBOOST_NO_AUTO_PTR -include &#39;/home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp&#39; -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1 -fpic -g -O2 -fdebug-prefix-map=/build/r-base-jbaK_j/r-base-3.6.3=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c foo.c -o foo.o ## In file included from /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/Core:88, ## from /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/Dense:1, ## from /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13, ## from &lt;command-line&gt;: ## /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/src/Core/util/Macros.h:613:1: error: unknown type name ‘namespace’ ## 613 | namespace Eigen { ## | ^~~~~~~~~ ## /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/src/Core/util/Macros.h:613:17: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘{’ token ## 613 | namespace Eigen { ## | ^ ## In file included from /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/Dense:1, ## from /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13, ## from &lt;command-line&gt;: ## /home/sylvain/R/x86_64-pc-linux-gnu-library/3.6/RcppEigen/include/Eigen/Core:96:10: fatal error: complex: Aucun fichier ou dossier de ce type ## 96 | #include &lt;complex&gt; ## | ^~~~~~~~~ ## compilation terminated. ## make: *** [/usr/lib/R/etc/Makeconf:168 : foo.o] Erreur 1 Table 3.1: Summary table of the model term estimate std.error rhat beta 0.2947404 0.0216958 1.001771 sigma 7.8998422 2.2102589 1.004300 Figure 3.3: Model result of the relation between DNA concentration measured with Qbit and NanoDrop. Color indicates the electrophoresis classification of the samples. 3.1.1.4 Extraction Electrophoresis We evaluated samples quality and degradation by an electrophoresis of 1 to 1.5 \\(\\mu L\\) of sample DNA with 1 to 1.5 \\(\\mu L\\) of weight migrating 20 minutes with 20 V on an agarose gel with 80 \\(mL\\) of 0.1 X TAE with 1 \\(\\mu L\\) of red gel. Samples were classified as good, medium and bad. “Good” samples only included a band at high molecular weight. “Bad” samples only included a smir at low molecular weight indicating degraded DNA. “Medium” samples included both. Figure 3.4: Extraction plate Electrophoresis quality 3.1.2 Library plates design We first designed new plates based on the samples concentration in order to bring all samples to the same concentration for further easier manipulations in libraries preparation. 3.1.2.1 Pool We pooled all individuals with 2 extraction and with a nanodrop concentration inferior to 25 \\(ng.\\mu L^{-1}\\). Individuals with only one extraction will be further concentrated. Warning, P7-3-2812 has been pooled from P2.C12 to P7.C12 instead of P7.D12. Table 3.2: Preview of Samples to be pooled. From plates 1, 2 and 3 to plate 5, 6 and 7 ID Plate_extraction Position_extraction nanodrop P10_3_2912 1 G10 NA P10_3_2912 6 G10 10.70 P11_1_742 3 C2 23.29 P11_1_742 5 D3 18.96 P13_2_2819 2 F5 NA P13_2_2819 7 F5 21.52 3.1.2.2 Pool and new samples nanodrop Pooled individuals and new individuals from Itubera Brazil (n = 3), La Selva Costa Rica (n = 2) and Baro Colorado Island Panama (n = 2) has been quantified again with the nanodrop. Table 3.3: Preview of New nanodrops. ID nanodrop Plate Position P7-3-2837 16.180 Pull NA IT_H4 9.486 Itubera H4 P11-1-742 23.470 Pull NA IT_G3 39.320 Itubera G3 IT_E4 -27.780 Itubera E4 3.1.2.3 Concentration Plates We reorganised plates in a new scheme ordered by concentration following figure 3.5 design with figure 3.6 concentrations. Figure 3.5: Previous extraction position in plates arranged by concentration. Figure 3.6: Concentration in plates arranged by concentration. 3.1.2.4 Samples volume In order to adjust samples concentration we needed first to assess their current volume, see figure 3.7. Volume after extraction was around 45 \\(\\mu L\\) (estimated loss). Samples have lost volume with NanoDrop, Qbit, electrophoresis, and libraries trial, one or two times. Some sample won volume with pooling. We can consider all samples to have lost 1 \\(\\mu L\\) with NanoDrop. Samples used in Qbit lost an additional 1.5 to 3 \\(\\mu L\\). Finally samples used in trial libraries lost between 0.5 and 5 \\(\\mu L\\) (with library test II repeated). Pooled samples from plate 5, 6 an 7 won 49 \\(\\mu L\\) from NanoDroped samples from plate 1, 2, 3 and 4 unused for NanoDrop, Qbit nor libraries trial (original 50 minus 1 nanodropped). Added samples from Itubera, La Selva and Baro Colorado Island have an estimated volume of 10 \\(\\mu L\\) (overestimated). Figure 3.7: Samples estimated volumes. 3.1.2.5 DNA quality We assessed DNA fragment quality and size through electrophoresis and reorganized columns inside plates by quality. ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 MHDN… PCR1 B1 49 1.45 PCR2 ## 2 P15_… PCR1 D1 50 3.01 PCR2 ## 3 P3_2… PCR1 E1 50 3.10 PCR2 ## 4 MHDN… PCR1 F1 49 3.17 PCR2 ## 5 P5_4… PCR1 G1 50 3.36 PCR2 ## 6 P13_… PCR1 H1 50 3.45 PCR2 ## 7 P13_… PCR1 F2 50 3.93 PCR2 ## 8 P7_3… PCR1 G2 50 4.77 PCR2 ## 9 EE16… PCR1 A3 49 5.44 PCR2 ## 10 MH31… PCR1 B3 49 5.48 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P15_… PCR1 E3 49 22.7 PCR2 ## 2 P1_4… PCR1 H3 49 23.2 PCR2 ## 3 OH29… PCR1 D5 44.1 24.2 PCR2 ## 4 P4_2… PCR1 F5 49 24.2 PCR2 ## 5 P13_… PCR1 G5 49 24.3 PCR2 ## 6 P7_2… PCR1 C6 49 24.8 PCR2 ## 7 P4_1… PCR1 E6 49 25.1 PCR2 ## 8 P16_… PCR1 A7 49 25.5 PCR2 ## 9 P10_… PCR1 D7 49 25.6 PCR2 ## 10 P10_… PCR1 F7 49 25.8 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 48 x 7 ## # Groups: ID [48] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P3_2… PCR1 A1 49 56.0 PCR2 ## 2 P7_2… PCR1 B1 49 57.7 PCR2 ## 3 P13_… PCR1 F1 49 60.5 PCR2 ## 4 P6_4… PCR1 H1 49 63.7 PCR2 ## 5 P7_3… PCR1 A2 49 63.8 PCR2 ## 6 P15_… PCR1 B2 49 64.5 PCR2 ## 7 P7_3… PCR1 C2 49 69.6 PCR2 ## 8 P13_… PCR1 D2 49 70.2 PCR2 ## 9 P7_3… PCR1 H2 49 73.2 PCR2 ## 10 P15_… PCR1 C3 47.7 75.1 PCR2 ## # … with 38 more rows, and 1 more variable: dest_Position &lt;chr&gt; ID Plate_concentration Position_concentration volumeplus5 concentration Plate_library Position_library P15_3_267 1 D1 98 3.006352 1 B1 P3_2_739 1 E1 98 3.100669 1 C1 P5_4_658 1 G1 98 3.360040 1 E1 P13_2_929 1 H1 98 3.451410 1 F1 P13_4_149 1 F2 98 3.934784 1 G1 P7_3_2837 1 G2 98 4.768899 1 H1 P4_1_3000 1 C3 98 5.903650 1 C2 P6_3_346 1 E3 98 6.180706 1 D2 P11_1_742 1 G3 98 6.917557 1 E2 P7_3_679 1 B2 98 3.766782 1 B4 P15_4_40 1 C2 98 3.834572 1 C4 P7_2_3049 1 D2 98 3.852257 1 F7 P10_3_2912 1 E2 95 3.917100 1 G7 P7_2_2520 1 H2 98 5.093114 1 H7 P4_2_3487 1 D3 98 6.104073 1 A8 P6_3_2800 1 D4 98 8.008096 1 D8 P7_3_2812 2 A11 98 19.143388 2 F3 Figure 3.8: Plates electrophoresis status before rearrangement. Figure 3.9: Plates electrophoresis status after rearrangement. 3.1.2.6 Concentration All individuals with an estimated concentration inferior to 19 \\(ng.\\mu L^{-1}\\) (Plates 1 and 2) have been dried in the speed vacuum centrifuge. And corresponding volume of miliQ water will be added to reach a concentration of 20 \\(ng.\\mu L^{-1}\\) (or at least 6.5 \\(\\mu L\\) to reach sample volume). Their DNA content in \\(ng\\) has been computed multiplying concentration with volume. The volume of water to add is thus the DNA content divided by the objective concentration of 20 \\(ng.\\mu L^{-1}\\): \\(V = \\frac{C_0*V_0}{20}\\). Corresponding volumes are shown in figure 3.11. Figure 3.10: Samples to be concentrated. Estimated concentration in ng/microL Figure 3.11: Volume to resupspend dry samples. ## # A tibble: 192 x 6 ## source_Plate source_Position sample_volume new_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 PCR1 A1 0 10 PCR2 ## 2 PCR1 B1 0 14 PCR2 ## 3 PCR1 C1 0 14.4 PCR2 ## 4 PCR1 D1 0 10 PCR2 ## 5 PCR1 E1 0 15.6 PCR2 ## 6 PCR1 F1 0 16 PCR2 ## 7 PCR1 G1 0 18.3 PCR2 ## 8 PCR1 H1 0 22.2 PCR2 ## 9 PCR1 A2 0 12 PCR2 ## 10 PCR1 B2 0 12.1 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; 3.1.2.7 Samples volume The objective was to get 100 \\(ng\\) of DNA in 6.5 \\(\\mu L\\) of sample for the library preparation. Consequently we needed to extract with the robot \\(V = \\frac{n}{C} = \\frac{100}{C}\\) with \\(C\\) the sample concentration in \\(ng.\\mu L^{-1}\\). Figure 3.12: Sample volume (microL) ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position sample_volume water_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P15_… PCR1 A1 4.4 2.1 PCR2 ## 2 P1_4… PCR1 B1 4.3 2.2 PCR2 ## 3 OH29… PCR1 C1 4.1 2.4 PCR2 ## 4 P4_2… PCR1 D1 4.1 2.4 PCR2 ## 5 P13_… PCR1 E1 4.1 2.4 PCR2 ## 6 P7_2… PCR1 F1 4 2.5 PCR2 ## 7 P4_1… PCR1 G1 4 2.5 PCR2 ## 8 P16_… PCR1 H1 3.9 2.6 PCR2 ## 9 P10_… PCR1 A2 3.9 2.6 PCR2 ## 10 P10_… PCR1 B2 3.9 2.6 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 48 x 7 ## # Groups: ID [48] ## ID source_Plate source_Position sample_volume water_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P3_2… PCR1 A1 3.6 9.4 PCR2 ## 2 P7_2… PCR1 B1 3.5 9.5 PCR2 ## 3 P13_… PCR1 C1 3.3 9.7 PCR2 ## 4 P6_4… PCR1 D1 3.1 9.9 PCR2 ## 5 P7_3… PCR1 E1 3.1 9.9 PCR2 ## 6 P15_… PCR1 F1 3.1 9.9 PCR2 ## 7 P7_3… PCR1 G1 2.9 10.1 PCR2 ## 8 P13_… PCR1 H1 2.8 10.2 PCR2 ## 9 P7_3… PCR1 A2 2.7 10.3 PCR2 ## 10 P15_… PCR1 B2 2.7 10.3 PCR2 ## # … with 38 more rows, and 1 more variable: dest_Position &lt;chr&gt; Plate_library Position_library sample_volume water_volume 3 F3 4.775924 1.724076 3 G3 4.736586 1.763414 3 H3 4.670727 1.829273 3 A4 4.573145 1.926855 3 C7 4.997520 1.502480 3 D7 4.929270 1.570730 3 E7 4.927122 1.572878 3 F7 4.890194 1.609806 3 G7 4.854509 1.645491 3 H7 4.837206 1.662794 3 A8 4.792790 1.707210 3 B8 4.757841 1.742159 3 C8 4.751178 1.748822 3 D8 4.702448 1.797552 3 E8 4.663665 1.836335 3 F8 4.659822 1.840178 3 G8 4.633729 1.866271 3 H8 4.576847 1.923153 3 A9 4.514726 1.985274 3.2 Libraries preparation protocol The protocol is given per sample with the corresponding volume for a plate of 96 samples in bracket. 3.2.1 Material preparation 0.5 \\(\\mu L\\) of 10mM TrisHCL + 10 mM NaCl (48 \\(\\mu L\\) per plate) 46.875 \\(\\mu L\\) of 0.1X TE buffer (2 136.875 \\(\\mu L\\) per plate) = 4.7 \\(\\mu L\\) of TE buffer (213.7 \\(\\mu L\\) per plate) + 42.3 \\(\\mu L\\) of water (1 923.3 \\(\\mu L\\) per plate) 400 \\(\\mu L\\) of fresh 80% Ethanol (38 400 \\(\\mu L\\) per plate) 3.2.2 Fragmentation Prepare 6.5 \\(\\mu L\\) of samples with ca 100 \\(ng\\) of DNA (see previous chapter) On ice, pipette up and down ULTRA II FS Reaction Buffer 10X, vortex 5\" and spin On ice, vortex 5\" Ultra II FS Enzyme Mix and spin On ice, premix 0.5 \\(\\mu L\\) of Ultra II FS Enzyme Mix (48 \\(\\mu L\\) per plate) with 1.75 \\(\\mu L\\) of Ultra II FS Reaction Buffer (168 \\(\\mu L\\) per plate), vortex and spin On ice, add 2.25 \\(\\mu L\\) of premix to each sample, vortex 5\" and spin: Component Volume per library Volume per plate DNA 6.5 \\(\\mu L\\) Ultra II FS Enzyme Mix 0.5 \\(\\mu L\\) 48 \\(\\mu L\\) Ultra II FS Reaction Buffer 1.75 \\(\\mu L\\) 168 \\(\\mu L\\) Total 8.75 \\(\\mu L\\) Thermocycle with following programs depending on electrophoresis quality: Good: 13'@37°C, 30'@65°C, Hold@-4°C Medium: 9'@37°C, 30'@65°C, Hold@-4°C Bad: 1'@37°C, 30'@65°C, Hold@-4°C Optionally, put the NEBNext adaptor for Illumina out of the freezer (long to melt) Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.3 Adaptor ligation On ice, prepare diluted adaptor (1:5) with 0.125 \\(\\mu L\\) of NEBNext adaptor for Illumina (12 \\(\\mu L\\) per plate) diluted into 0.5 \\(\\mu L\\) of 10mM TrisHCL + 10 mM NaCl (48 \\(\\mu L\\) per plate) On ice, premix 7.5 \\(\\mu L\\) of NEBNext Ultra II Ligation Master Mix (720 \\(\\mu L\\) per plate) with 0.25 \\(\\mu L\\) of NEBNext ligation enhancer (24 \\(\\mu L\\) per plate), vortex and spin On ice, add 0.625 \\(\\mu L\\) of diluted adaptor and 7.75 \\(\\mu L\\) of premix to samples, mix and spin: Component Volume per library Volume per plate DNA 8.75 \\(\\mu L\\) NEBNext Ultra II Ligation Master Mix 7.5 \\(\\mu L\\) 720 \\(\\mu L\\) NEBNext ligation enhancer 0.25 \\(\\mu L\\) 24 \\(\\mu L\\) diluted NEBNext adaptor (1:5) 0.625 \\(\\mu L\\) 50 \\(\\mu L\\) Total 17.25 \\(\\mu L\\) Incubate 15'@20°C with lid open On ice, add 0.75 \\(\\mu L\\) of USER Enzyme (72 \\(\\mu L\\) per plate) to samples, mix and spin Incubate 15'@37°C with lid hot (&gt;47°C) Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.4 Size selection Bring the sample volume from 17.125 \\(\\mu L\\) to 27.125 \\(\\mu L\\) adding 10 \\(\\mu L\\) of 0.1X TE buffer (1 716 \\(\\mu L\\) per plate) Vortex PGTB beads from batch E at room temperature Add 7 \\(\\mu L\\) (~0.28X) of beads (672 \\(\\mu L\\) per plate) to each sample, mix, vortex 5\" keeping beads, incubet 5’, spin, place on magnet, wait 5’, and transfer ~32 \\(\\mu L\\) of sample to a new plate Add 3.5 \\(\\mu L\\) (~0.14X) of beads (336 \\(\\mu L\\) per plate) to each sample, mix, wait 5’ without the magnet Place on magnet, wait 5\" and discard ~35.5 \\(\\mu L\\) of supernatant Add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate) to the beads on the magnet, wait 30’ remove supernatant Repeat, add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate) to the beads on the magnet, wait 30\" remove supernatant Air dry beads 3’ on magnet Remove magnet, elute into 12 \\(\\mu L\\) of hot 0.1X TE (1 152 \\(\\mu L\\) per plate) (~40°C), mix, incubate 2’, spin, put on magnet, wait 5’ Transfer 2 x 5 \\(\\mu L\\) of supernatant to 2 new plates Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.5 Enrichment and purification protocol given for delivered oligos at \\(100mM\\), not NEBNext tag at \\(10mM\\) Prepare diluted index (1:10) with 0.16 \\(\\mu L\\) of Index Primer i5 and i7 diluted in 1.44 \\(\\mu L\\) of mQ \\(H_2O\\) (1.92 \\(\\mu L\\) of i5 per row and 1.28 \\(\\mu L\\) of i7 per column) Mix in each plate (2 for the 2 PCR), mix and spin : Component Volume per library Volume per plate/row/column sample 5 \\(\\mu L\\) NEBNext Ultra II Q5 Master Mix 8.3 \\(\\mu L\\) 796.8 \\(\\mu L\\) diluted Index Primer i5 (1:10) 1.6 \\(\\mu L\\) 19.2 \\(\\mu L\\) diluted Index Primer i7 (1:10) 1.6 \\(\\mu L\\) 12.8 \\(\\mu L\\) Total 16.5 \\(\\mu L\\) Thermocycle with following program 30\"@98°C 8 cycles of 10\"@98°C and 75\"@65°C 5'@65°C Hold@4°C Optionally, amplify only the first plate, assess it with electrophoresis, and adjust cycles number for the second amplifcation depending on gel migration Pool PCR results (~16.5 \\(\\mu L\\) per sample) from the 2 plates into one (~33.3K \\(\\mu L\\) per sample) Vortex PGTB beads from batch E at room temperature Add 30 \\(\\mu L\\) (~0.9X) of beads (2 880 \\(\\mu L\\) per plate), mix, vortex 5\" keeping beads, spin, place on magnet, wait 5’, and remove supernatant (~ 63 \\(\\mu L\\) per sample) Add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate), wait 30’ remove supernatant Repeat, add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate), wait 30\" remove supernatant Air dry beads 3’ on magnet Remove magnet, elute into 22 \\(\\mu L\\) of hot 0.1X TE (2 112 \\(\\mu L\\) per plate) (~40°C), mix, incubate 2’, and spin Place on magnet, wait 5’, transfer 22 \\(\\mu L\\) of supernatant to a new plate and store at \\(-20^\\circ\\) 3.3 Libraries preparation results 3.3.1 Post-enrichment PCR1 quantification After the enrichment and the purification of the first PCR (PCR1), we quantified double strand DNA in every plates in order to adjust the second PCR (PCR2), and more especially in order to increase the number of cycles in PCR2. We used both Quant-It and few samples on Qbit and transformed raw absorbance results into concentration with regressions. 3.3.2 Post-enrichment (PCR1 &amp; PCR2) and amplification quantification Library showing no band or light smir in the electrophoresis have been amplified, resulting in amplified plates A1 and A2. We used the Quant-It to dose all samples (original libraries and amplified libraries). 3.3.3 Amplification result We used electrophoresis and noticed if re-amplified sampled had a band (B), a light smir (L) or nothing (A). Samples without anything (A) had their library repeated. Figure 3.13: Electrophoresis Amplified 3.3.4 Library &amp; extraction repetition result 69 libraries were still not satisfying after amplification. Those library have been rebuilt from source DNA. Among them, 43 were still not good at the electrophoresis and have bee re-extracted. Electrophoresis of re-extracted samples show a high heterogeneity of size, and around 8 of them seem to have not worked. All new samples habe been quantified. 3.4 Capture We did 16 reactions of gene capture by hybridization. Each reaction had up to 32 samples. We proceeded as follow: Amplifcation 1 Plate reorganization: plates state and volme have been assessed and 6 new plates (P1 to P6) have been build from (i) original libraries (P1-P5), (ii) reamplified libraries (A1-A2), and (iii) extraction and library repeat (P6). In order to do so, P6 staid unchanged, and new plate 1 to 5 were either reamplified libraries or original libraries if not reamplified. Tip: remove unwanted cone from boxes when transfering original P1 to P5 to new ones to work with multi-channel pipette and prepare correspondance table to transfer reamplified plates A1 and A2 to new P1 to P5 plates crossing each line one-by-one. DNA dosage 1: with PicoGreen, we will assess DNA concentration of each sample with a lader from 5 to 30 \\(ng.\\mu L^{-1}\\) in order to correctly dose low concentration samples. Tip: PicoGreen have to be used before the 26/03 12h or after the 1/04. Amplification 2: Samples that have never been reamplified with a concentration below 1 \\(ng.\\mu L^{-1}\\) have been reorganized on a new plate (A3) and reamplified with 8 cycles. DNA dosage 2: Re-amplified samples (A3) have been dosed through NanoDrop and other more accurate technology depending on the availability. Amplifcation 2 and Library Repeat Plates reorganization: Re-amplified samples (A3) have been redistributed in their original position within library plates, and plates and 6.2 eorganized in a unique plate 6.3 for pools building. Pool building: Pool building followed plate organization, with re-extracted samples (P6.2) pooled together due to high fragment size heterogeneity. Pool building must be equimolar and thus depended on DNA dosage. Because we won’t pipette less than 0.5 \\(\\mu L\\) of the most concentrated sample of one pool, depending on the concentration of the less concentrated sample, we needed to do dilution. Purification &amp; Concentration: AMPure beads have been used to clean pools. We also used this step to concentrate samples in a smaller volume for the reaction (targeted volume of reaction is 7 \\(\\mu L\\) with 100 to 500 \\(ng\\) of DNA). Size assessment: Pools fragments size have been assessed with TapeStation, in order to check for correct fragment size distribution, and eventually further clean library pools. Size selection: if size distribution result was not good enough, we further cleaned library pools through size selection with a Pippin. Info: we thus avoid capture fail with too small fragments but we risk losing libraries. Capture: Finally we realized capture by hybridization following ArborScience protocol 3.4.1 Amplifcation 1 Plate reorganization First amplification plates (A1 and A2) have been redistributed within their original library plates removing previous libraries. Figure 3.14: Original libraries to be kept (P1-P5). Figure 3.15: Original position of amplified samples. 3.4.2 DNA dosage 1 Samples concentration has been assessed by PicoGreen with ca 60 samples having a concentration below \\(1 ng.\\mu L^{-1}\\) among which 50 have not been reamplified (34 among original libraries, and the rest among repeated libraries or extractions). Those samples have been reamplified. Figure 3.16: Sampled dosage by PicoGreen (concetration in ng.uL). Figure 3.17: Samples to be re-amplified. 3.4.3 Amplification 2 Figure 3.18: Original position of amplified samples in A3. 3.4.4 DNA dosage 2 Figure 3.19: Reampified sampled dosage by PicoGreen (concetration in ng.uL). 3.5 Amplifcation 2 and Library Repeat Plates reorganization Figure 3.20: Original position of plate 6.1 and 6.2 reorganization in 6.3. 3.6 Pool building Due to non uniformity of fragment size, re-extracted samples from P6 (P6.2) have been treated in a single separated reaction (so 15 remaining). All other samples have been pulled by batch of 32 following plate order. We wanted 100 to 500 ng of DNA per reaction, and the reaction with the least samples have 16 samples. Consequently we used 15 ng of each sample, resulting in 240 to 645 ng of DNA per sample (but we may lost material in purification, so we aimed for extra). Samples reaching to high concentration, for which we should sample less than 0.5 \\(\\mu L\\) have been diluted 2 to 4 times. Figure 3.21: Sample reaction tube per plate. Figure 3.22: Sample reaction volume per plate. 3.7 Purification &amp; Concentration Figure 3.23: Reactions DNA content assessed by NanoDrop. 3.8 Size assessment We had an heterogeneity of fragments size distribution among pools with a large spectrum (Fig. 3.24). We used TapeStation to select fragments between 330 and 700 bp. Figure 3.24: Pools size assessment. 3.9 Size selection We did pools of pools for the size selection with Pippin (Fig. 3.25), resulting in \\(22*4=88 \\mu L\\) per pool. But the Pippin used 30 \\(\\mu L\\) and we wanted to do two reactions of Pippin per pool. So we reduced pool volume to 60 \\(\\mu L\\) per pool with the speed vac. Then we used Pippin with a repeat of the 4 pools with 30 \\(\\mu L\\) per pool. We used Pippin to filter fragments between 330 and 750 bp. After the Pippin, we cleaned the sampled with 1.8X PGTB Beads from Batch J, and assessed their concentration with QuBIT and their fragment size distribution with TapeStation. We obtained between 180 and 280 ng of DNA (Table 3.4), with fragments distributed between 300 and 700 bp (Fig. 3.26). Figure 3.25: Pool of reactions. Table 3.4: Pool of pools result. Pool Repetition Volume (\\(\\mu L\\)) Concentration (\\(ng. \\mu L^{-1}\\)) DNA (\\(ng\\)) DNA origin (\\(ng\\)) Loss factor 1 1 37 4.94 182.78 874.0 5 2 1 37 5.33 197.21 489.0 2 3 1 37 7.38 273.06 588.5 2 4 1 37 3.98 147.26 514.0 3 Figure 3.26: Size selected pools assessment. 3.10 Capture We split the 4 pools in 16 reactions (4 replicates for each) and realized the capture following ArborScience protocol. After amplification we obtained between 227 and 987 ng of DNA per pool assessed by Qubit (with the four replicates summed, Table 3.5). We then pooled back the reaction, assessed their concentration by qPCR and adjust final samples for sequencing by an equimolar pooling Pool 1 and 2 and 3 and 4 together. We thus obtained 22 \\(\\mu L\\) of Lane 1 at \\(7.19~nM\\) and 19 \\(\\mu L\\) of Lane 2 at \\(10.18~nM\\) (see google sheets for more details). The material has been sent to Genotoul Get team for sequencing on Illumina HiSeq 3000 on two lanes of pair-ends 150 bp sequences. Table 3.5: Capture result (Qubit). Reaction Pool Concentration (\\(ng. \\mu L^{-1}\\)) DNA (\\(ng\\)) DNA pool (\\(ng\\)) 1 1 11.300 440.700 957.450 2 1 5.850 228.150 957.450 3 1 5.500 214.500 957.450 4 1 1.900 74.100 957.450 5 2 1.250 48.750 242.775 6 2 1.075 41.925 242.775 7 2 2.350 91.650 242.775 8 2 1.550 60.450 242.775 9 3 7.350 286.650 986.700 10 3 5.650 220.350 986.700 11 3 5.800 226.200 986.700 12 3 6.500 253.500 986.700 13 4 1.380 53.820 227.955 14 4 1.095 42.705 227.955 15 4 1.935 75.465 227.955 16 4 1.435 55.965 227.955 \\[ C~in~nM = \\frac{C~in~ng/\\mu L}{660 .average~fragment~size}.10^6\\] Dilution for qPCR (1 pM) Dilute in cascade your samples from 20.4 - 4.9 nM to almost 1 pM. So we need a 10 000 times dilution. We will do 4 1:10 dilutuions with \\(1 \\mu L\\) of sample in \\(9 \\mu L\\) of \\(H_2O~miliQ\\). Change of tips for every step and better use pipette in the middle of their range than in their extreme (e.g. for \\(100 \\mu L\\) better use a \\(200 \\mu L\\) than a \\(100 \\mu L\\) pipette). References "],["references.html", "References", " References "]]

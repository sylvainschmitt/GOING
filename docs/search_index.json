[["index.html", "GOING Genomics of Individual Growth Preface", " GOING Genomics of Individual Growth Sylvain Schmitt 2021-03-05 Preface This digital book supports all the analyses of the GOING project on the Genomics of Individual Growth in the tropical tree Symphonia globulifera L.f. Have a nice reading. Sylvain "],["introduction.html", "Introduction", " Introduction In the present study, we assessed genotypic diversity within closely-related sympatric tree species belonging to the widespread tropical tree species complex Symphonia globulifera. We addressed the fine-scale spatial and temporal genetic adaptations of individuals through differential growth strategies in response to forest gap dynamics. We finally compared the breadth of successional niches encountered by Symphonia species to other locally abundant species. Combining tree diameter censuses, indirect measures of light environment of the recent past and present, and single nucleotide polymorphisms (SNPs), we used population genomics, environmental association analyses, genome wide association and growth modelling to address the following questions: Are individual genotypes structured by the mosaic of light and competition environments resulting from forest gap dynamics? Is the growth of individuals determined by genotypes? Is there an association between genotypic adaptations to gap dynamics and to growth? How are genotypic adaptations to gap dynamics and to growth structured in time, i.e., across life stages? Are breadths of successional niches for Symphonia species wider than those of other locally abundant species? "],["study-site-sampling.html", "Chapter 1 Study site &amp; sampling 1.1 Study site 1.2 Plant material", " Chapter 1 Study site &amp; sampling 1.1 Study site The study was conducted in the Paracou field station, in the coastal forests of French Guiana, South America. The site is characterized by an average of 3,041 mm annual rainfall and a mean air temperature of 25.71 °C (Aguilos et al. 2018). Old tropical forest with an exceptional richness (i.e. over 750 woody species) grows across the succession of small hills of this area, which rise to 10–40 m a.s.l. (Gourlet-Fleury et al. 2004). The site comprises 16 permanent plots (fifteen 6.25 ha plus one 25 ha) which have been censused (DBH&gt;10) every 1-2 years for more than 35 years. Nine of the plots were logged and subjected to human-induced disturbance in 1986 (details on the experiment in Hérault &amp; Piponiot 2018). 1.2 Plant material Four hundred and two individuals of Symphonia globulifera (Clusiaceae) were sampled in 2017 during the dry season (from September to December) in Paracou. Symphonia globulifera L.f (Clusiaceae) was previously recognized as composed of two morphotypes in French Guiana (Sabatier et al. 1997; Molino &amp; Sabatier 2001; Baraloto et al. 2007). S. globulifera sensu stricto and Symphonia sp.1 occur in sympatry but in differentiated habitats, with S. globulifera preferentially growing in valley bottoms with an acquisitive functional strategy and S. sp1 preferentially exploiting a variety of drier habitats with a conservative functional strategy (Allié et al. 2015; Schmitt 2020, in prep; Schmitt et al. 2020). Symphonia have been highlighted as a species complex with low (phylo-)genetic species resolution and high levels of plastid DNA sharing among sister species (Baraloto et al. 2012; Gonzalez et al. 2009; Torroba-Balmori et al. 2017; Caron et al. 2019). In addition, outgroups for genetic analysis in Symphonia were comprised of 13 individuals of Symphonia globulifera from Africa (Sao Tome, Gabon, Cameroon, Congo, Benin, Liberia, Ivory Coast, and Ghana), seven Symphonia globulifera from South America (Brazil, Costa Rica and Panama), two Symphonia nectarifera Jum. &amp; H. Perrier from Madagascar, two Symphonia urophylla (Decne. ex Planch. &amp; Triana) Benth. &amp; Hook.f. ex Vesque from Madagascar, five Pentadesma butyracea Sabine from Benin and Cameroon and one Pentadesma grandifolia Baker f. from Cameroon. Leaves were collected from the 432 individuals (402 + 30 outgroups) and dessicated using silica gel. References "],["design-of-probes-set.html", "Chapter 2 Design of probes set 2.1 Scotti et al. (in prep) scaffolds preparation 2.2 Olsson et al. (2017) scaffolds preparation 2.3 Tysklind et al (in prep) transcript preparation 2.4 Neutral region selection 2.5 Fuctional region selection", " Chapter 2 Design of probes set The genomic and transcriptomic resources used for the design were comprised of a published low-coverage draft genome from Africa (Olsson et al. 2017), an unpublished draft genome from French Guiana [Scotti et al., in prep], an unpublished transcriptome from 20 juveniles from French Guiana [Tysklind et al., in prep], and reduced-representation genomic sequence reads of individuals from French Guiana [Torroba-Balmori et al., unpublished]. We aligned genomic reads on the two genome drafts with bwa (Li &amp; Durbin 2009). We kept scaffolds from the two genome drafts with a length of more than 1 kbp and at least one matching alignment with a read with a single match on the genome, and merged the two filtered genome drafts with quickmerge (Chakraborty et al. 2016). We aligned transcripts on the new filtered genome draft with BLAT (Kent 2002) and selected 533 scaffolds without transcript-match, i.e. anonymous scaffolds. We masked repetitive regions with RepeatMasker (Smit et al. 2015) and selected 533 1-kbp anonymous loci within the 533 previous scaffolds. Similarly, we filtered transcripts from the 20 juveniles of Symphonia globulifera from French Guiana [Tysklind et al., in prep] based on SNP quality, type and frequency. We further detected open reading frames (ORFs) using transdecoder (Haas et al. 2013), and selected transcripts with non-overlapping ORFs including a start codon. We kept ORFs with an alignment on scaffolds from the aforementioned genome draft for Symphonia using BLAT (Kent 2002), and masked repetitive regions with RepeatMasker (Smit et al. 2015). We selected 1,150 genic loci of 500-bp to 1-kbp, from 100 bp before the start to a maximum of 900 bp after the end of the ORFs, resulting in 1-Mbp genomic loci that included a coding region. 2.1 Scotti et al. (in prep) scaffolds preparation 2.1.1 Filtering scaffolds over \\(1kbp\\) We first filtered scaffolds with a width of more than 1000 bp. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/ mkdir scf_1000 for scf in $( ls raw/ | grep scafSeq$); do echo item: $scf perl ~/Tools/SeqFilter/bin/SeqFilter -l 1000 raw/$scf --out scf_1000/$scf done 2.1.2 Renaming For all scaffolds we used the following code : **Ivan_2018_[file name without .scafSeq]_[scaffold name]**. dir.create(file.path(path, &quot;Ivan_2018&quot;, &quot;renamed_scf_1000&quot;)) files &lt;- list.files(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;)) sapply(files, function(file){ scf &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;, file)) names(scf) &lt;- paste0(&quot;Ivan_2018_&quot;, gsub(&quot;.scafSeq&quot;, &quot;&quot;, file), &quot;_&quot;, gsub(&quot; &quot;, &quot;_&quot;, names(scf))) writeXStringSet(scf, file.path(path, &quot;Ivan_2018&quot;, &quot;renamed_scf_1000&quot;, paste0(gsub(&quot;.scafSeq&quot;, &quot;&quot;, file), &quot;.1000.renamed.scafSeq&quot;))) }, simplify = F) unlink(file.path(path, &quot;Ivan_2018&quot;, &quot;scf_1000&quot;), recursive = T) 2.1.3 Libraries merging We successively merged scaffolds from 6 libraries with quickmerge. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/renamed_scf_1000 ref=(sympho47_1L1_002.1000.renamed.scafSeq merge1.fasta merge2.fasta merge3.fasta merge4.fasta merge5.fasta merge6.fasta merge7.fasta) query=(sympho47_1L2_001.1000.renamed.scafSeq sympho47_2L1_008.1000.renamed.scafSeq sympho47_2L1_009.1000.renamed.scafSeq sympho47_2L1_010.1000.renamed.scafSeq sympho47_2L1_011.1000.renamed.scafSeq sympho47_2L1_012.1000.renamed.scafSeq sympho47_3L2_013.1000.renamed.scafSeq sympho47_4L1_014.1000.renamed.scafSeq) for i in {0..7} do mkdir merge$i cp &quot;${ref[$i]}&quot; &quot;${query[$i]}&quot; ./merge$i/ cd merge$i nucmer -l 100 -prefix out ${ref[$i]} ${query[$i]} delta-filter -i 95 -r -q out.delta &gt; out.rq.delta ~/Tools/quickmerge/quickmerge -d out.rq.delta -q ${query[$i]} -r ${ref[$i]} -hco 5.0 -c 1.5 -l n -ml m cd .. cp merge$i/merged.fasta ./merge$((i+1)).fasta done cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018 mkdir merged_1000 cp renamed_scf_1000/merge5/merged.fasta merged_1000/merged_1000.fa cd merged_1000 makeblastdb -in merged_1000.fa -parse_seqids -dbtype nucl 2.1.4 Removing scaffolds with multimatch blasted consensus sequence from Torroba-Balmori et al. (unpublished) We used the consensus sequence for French Guianan reads from Torroba-Balmori et al. (unpublished) previously assembled with ipyrad. We kept the first sequence of the consensus loci file and recoded it to fasta (see loci2fa.py script below). We then blasted the consensus sequences on merged scaffolds from Scotti et al (in prep) with blastn in order to detect scaffolds with repetitive regions (multi-mapped consensus sequences). Repetitive sequences have been saved as a list and removed to generate the final list of selected scaffolds. infile = open(&quot;symphoGbS2.loci&quot;, &quot;r&quot;) outfile = open(&quot;symphoGbS2.firstline.fasta&quot;, &quot;w&quot;) loci = infile.read().split(&quot;|\\n&quot;)[:-1] for loc in loci: reads = loc.split(&quot;\\n&quot;) name, seq = reads[0].split() print &gt;&gt;outfile, &quot;&gt;&quot;+name+&quot;\\n&quot;+seq outfile.close() cd ~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfile python loci2fa.py cat symphoGbS2.firstline.fasta | tr - N &gt;&gt; symphoGbS2.firstline.fasta cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018 query=~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfiles/symphoGbS2.firstline.fasta blastn -db merged_1000/merged_1000.fa -query $query -out blast_consensus_torroba2.txt -evalue 1e-10 -best_hit_score_edge 0.05 -best_hit_overhang 0.25 -outfmt 6 -perc_identity 75 -max_target_seqs 10 blast &lt;- read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_blast&quot;, &quot;blast_consensus_torroba2.txt&quot;), col_names = F) names(blast) &lt;- c(&quot;Read&quot;, &quot;Scaffold&quot;, &quot;Perc_Ident&quot;, &quot;Alignment_length&quot;, &quot;Mismatches&quot;, &quot;Gap_openings&quot;, &quot;R_start&quot;, &quot;R_end&quot;, &quot;S_start&quot;, &quot;S_end&quot;, &quot;E&quot;, &quot;Bits&quot;) write_file(paste(unique(blast$Scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_blast&quot;, &quot;selected_scaffolds_blast_consensus2.list&quot;)) seqtk subseq merged_1000/merged_1000.fa selected_scaffolds_blast_consensus2.list &gt;&gt; selected_scaffolds_blast_consensus2.fa In total 542 scaffolds from Scotti et al (in prep) matched consensus sequences from Torroba-Balmori et al. (unpublished). Several scaffolds obtained multiple matches that we cannot use for probes. We thus excluded the whole scaffold if the scaffold is shorter than 2000 bp, or the scaffold region matching the raw read if the scaffold is longer than 2000 bp. Figure 2.1: Number of match with Torroba consensus reads vs gene width. Table 2.1: Scaffold to cut due to multiple read match. Scaffold width remove cut Ivan_2018_sympho47_2L1_012_scaffold197676__8.6 4993 4993-4932 Ivan_2018_sympho47_2L1_012_scaffold246452__6.6 3103 2980-3058 Ivan_2018_sympho47_2L1_012_scaffold26367__7.7 2168 2118-2168 Ivan_2018_sympho47_2L1_012_scaffold463128__4.7 2188 667-586 Ivan_2018_sympho47_2L1_008_scaffold309475__2.1 3525 342-292 The following scaffolds have been removed due to multiple matches and a length \\(&lt;200bp\\): 2L1_012_scaffold645876__7.5, 2L1_012_scaffold176548__7.1, 2L1_012_scaffold21882__4.9, 2L1_012_scaffold9236__6.0. The others have been cut (see table 2.1). 2.1.5 Total filtered scaffolds 2.2 Olsson et al. (2017) scaffolds preparation African genome from Olsson et al. (2017). 2.2.1 Renaming We renamed scaffolds from Olsson using the following code : Olsson_2017_[scaffold name]. scf &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;symph_genome.fa&quot;)) names(scf) &lt;- paste0(&#39;Olsson_2017_&#39;, names(scf)) dir.create(file.path(path, &quot;Olsson_2016&quot;, &quot;db&quot;)) writeXStringSet(scf, file.path(path, &quot;Olsson_2016&quot;, &quot;db&quot;, &quot;Olsson2017.fa&quot;))) 2.2.2 Removing scaffolds with multimatch blasted consensus sequence from Torroba-Balmori et al. (unpublished) We used the consensus sequence for French Guianan reads from Torroba-Balmori et al. (unpublished), by blasting them on scaffolds from Olsson et al. (2017) with blastn. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016 cd Olsson2017 makeblastdb -in Olsson2017.fa -parse_seqids -dbtype nucl cd .. query=~/Documents/BIOGECO/PhD/data/Symphonia_Torroba/assembly/symphoGbS2_outfiles/symphoGbS2.firstline.fasta blastn -db Olsson2017/Olsson2017.fa -query $query -out blast_consensus_torroba2.txt -evalue 1e-10 -best_hit_score_edge 0.05 -best_hit_overhang 0.25 -outfmt 6 -perc_identity 75 -max_target_seqs 10 blast &lt;- read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_blast&quot;, &quot;blast_consensus_torroba2.txt&quot;), col_names = F) names(blast) &lt;- c(&quot;Read&quot;, &quot;Scaffold&quot;, &quot;Perc_Ident&quot;, &quot;Alignment_length&quot;, &quot;Mismatches&quot;, &quot;Gap_openings&quot;, &quot;R_start&quot;, &quot;R_end&quot;, &quot;S_start&quot;, &quot;S_end&quot;, &quot;E&quot;, &quot;Bits&quot;) write_file(paste(unique(blast$Scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_blast&quot;, &quot;selected_scaffolds_blast_consensus2.list&quot;)) seqtk subseq Olsson2017/Olsson2017.fa selected_scaffolds_blast_consensus2.list &gt;&gt; selected_scaffolds_blast_consensus2.fa We obtained most scaffolds with a single match including a broad range of sizes (from 100 bp to 33.2 kbp). In total 688 scaffolds from Olsson et al. (2017) match consensus sequences from Torroba-Balmori et al. (unpublished). Several scaffolds obtained multiple matches that we cannot use for probes. We thus excluded the whole scaffold if the scaffold is shorter than 2000 bp, or the scaffold region matching the raw read if the scaffold is longer than 2000 bp. Figure 2.2: Number of matches with Torroba-Balmori’s consensus reads vs gene width. Table 2.2: Scaffolds to cut due to multiple read matches. Scaffold width remove cut Olsson_2017_deg7180004393135 2380 1700-1631 Olsson_2017_deg7180004374686 2120 2073-1992 Olsson_2017_scf7180005372912 3152 3102-3152 Olsson_2017_scf7180005387046 2048 174-256 Olsson_2017_scf7180005323991 2482 2330-2267 The following scaffolds have been removed due to multiple matches and a length \\(&lt;200bp\\): deg7180004378417, deg7180003744575, deg7180002657883, deg7180004705895, deg7180004369764, deg7180002776754, deg7180004453462, deg7180004453461, deg7180002668453, deg7180005298947, deg7180003723902, deg7180005298948, deg7180004372504, deg7180002659849, deg7180004372505, deg7180004377385, deg7180003260802, deg7180003625436, deg7180004705895, deg7180002776754, deg7180004705894, deg7180002852093, deg7180004822905, deg7180005023024, deg7180004478675, deg7180004428004, deg7180004428003, deg7180004507379, deg7180002656221, deg7180004374687, deg7180004372498, deg7180004372497, deg7180002654368, deg7180002674357, deg7180004700334, deg7180004899808, deg7180004899808, deg7180002726303, scf7180005372913, deg7180005163225, deg7180003214542, scf7180005400822, deg7180005163224, deg7180003138164, deg7180004981997, deg7180004981996, deg7180005171251, deg7180005106503, deg7180003910181, deg7180005026532, deg7180003853280, deg7180004724986, deg7180005246885, deg7180004710959, deg7180004681149, deg7180004580422, deg7180004472718, deg7180003290510, deg7180005004768, deg7180004756559, scf7180005435685, deg7180004725719, deg7180004599019, deg7180004599018, deg7180002749392, deg7180002739372, deg7180004754314, deg7180004847375, deg7180004580009, deg7180004386399, deg7180004377195, deg7180004377194, deg7180004399409, deg7180004392029, deg7180004385805, deg7180004386398, deg7180002816623, deg7180002985310, scf7180005421751, deg7180004374725, deg7180004372798, deg7180004374726, deg7180002668107, deg7180003199928, deg7180003093903, deg7180003310549, deg7180004796671, deg7180003505925, deg7180002988969. And other have been cut (see table 2.2). 2.2.3 Total filtered scaffolds 2.3 Tysklind et al (in prep) transcript preparation Tysklind et al (in prep) used 20 Symphonia juveniles from the transplantation garden experiment for transcriptomic analysis. RNA sequences were captured. The analysis followed the scheme suggested by Lopez-Maestre et al. (2016) (see below). First, reads were assembled with Trinity into transcripts. In parallel, SNPs were detected with Kissplice. Then SNPs were mapped on the transcriptome with BLAT. In parallel SNPs have been tested to be morphotype-specific at the level \\(\\alpha = 0.001\\) with KissDE and transcriptome Open Reading Frames (ORF) have been identified with Transdecoder. Finally, SNPs with a functional impact were identified through k2rt. Consequently, for every SNP we have the following information: (i) inside coding DNA sequence (CDS), (ii) synonymous or not, (iii) morphotype-specificity. Analysis scheme from Lopez-Maestre et al. (2016). 2.3.1 Filtering SNP on quality We assessed transcriptomic analysis quality with possible sequencing errors, and SNPs in multiple assembled genes or isoforms (see table 2.3). We found 38 594 SNPs with possible sequencing error, and 609 214 SNPs associated to multiple assembled genes that we removed from further analysis. Table 2.3: Quality check with single SNPs. variable n Percentage 2.3.2 Filtering SNP on type We also highlighted SNPs which met impossible association of characteristic (table 2.4), that we removed from further analysis. Table 2.4: Single SNPs with impossible association of characteristics. First column indicates if the SNP is in a coding sequence, second column indicates if the SNP is non-synonymous, third column indicates if the SNP is morphotype-specific, and fourth column indicates the headcount. Coding sequence Not synonymous Morphotype-specific n type 2.3.3 Filtering transcripts on SNP frequency We found a high frequency of SNPs per candidate gene (the majority between 1 SNP per 10 or 100 bp), with some scaffolds having a SNP frequency superior to 0.2 (see figure 2.3). We assumed those hyper SNP-rich scaffolds to be errors and decided to remove them from the reference transcriptome. In order to do that, we fitted a \\(\\Gamma\\) law into the SNP frequency distribution and we kept scaffolds with a SNP frequency under the \\(99^{th}\\) quantile (\\(q_{99} = 0.07810194\\)). We thus removed: 358 308 SNPs located on 20 521 transcripts representing 1 490 candidate genes Figure 2.3: Distribution of SNP frequencies in scaffolds. Histogram (grey bars) represents the data, red line represents the Gamma law fit, and blue area represents X*sigma where scaffolds are not excluded. filtered_data &lt;- snp_genes %&gt;% filter(freq &lt;= q99) %&gt;% left_join(data, by = &quot;gene_id&quot;) %&gt;% select(transcript_id, sequence) %&gt;% unique() %&gt;% mutate(transcript_id = paste0(&quot;&gt;&quot;, transcript_id)) filtered_data_fasta &lt;- do.call(rbind, lapply(seq(nrow(filtered_data)), function(i) t(filtered_data[i, ]))) write.table(filtered_data_fasta, row.names = F, col.names = F, quote = F, file = file.path(path, &quot;..&quot;, &quot;filtered_transcripts.fasta&quot;)) 2.3.4 Total filtered transcript We have a total of: 1 382 525 filtered SNPs (over 2 398 550) located on 177 388 transcripts (over 257 140, when pseudo-genes and isoforms) representing 63 707 candidate genes (over 76 032, respectively) for a total of 283.4 Mbp 2.4 Neutral region selection 2.4.1 Raw reads from Torroba-Balmori et al. (unpublished) alignment on scaffolds from Scotti et al. (in prep) We used the French Guianan raw reads from Torroba-Balmori et al. (unpublished), by aligning them on scaffolds from Olsson et al. (2017) with bwa. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J alignIvan #SBATCH -o alignIvan_output.out #SBATCH -e alignIvan_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL # Environment module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 # read preparation cd ~/work/Symphonia_Torroba/ tar -xvzf Gbs.tar.gz cd raw rm PR_49.fastq RG_1.fastq for file in ./*.fastq do echo $file filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; perl -pe &#39;s|[\\h]||g&#39; $file &gt; &quot;${filename}&quot;.renamed.fastq rm $file done # variables cd ~/work/Symphonia_Genomes/Ivan_2018/torroba_alignment reference=~/work/Symphonia_Genomes/Ivan_2018/merged_1000/merged_1000.fa query_path=~/work/Symphonia_Torroba/raw # alignment bwa index $reference mkdir bwa for file in $query_path/*.fastq do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; rg=&quot;@RG\\tID:${filename}\\tSM:${filename}\\tPL:IONTORRENT&quot; bwa mem -M -R &quot;${rg}&quot; $reference $file &gt; bwa/&quot;${filename}.sam&quot; # rm $file done # sam2bam for file in ./bwa/*.sam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD SortSam I=$file O=bwa/&quot;${filename}&quot;.bam SORT_ORDER=coordinate done # Bam index for file in bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD BuildBamIndex I=$file O=bwa/&quot;${filename}&quot;.bai done # sam2bed mkdir bed for file in ./bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools bamtobed -i bwa/&quot;${filename}&quot;.bam &gt; bed/&quot;${filename}&quot;.bed done # merge bed mkdir merged_bed for file in ./bed/*.bed do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools merge -i bed/&quot;${filename}&quot;.bed &gt; merged_bed/&quot;${filename}&quot;.bed done cat bed/* | sort -k 1,1 -k2,2n &gt; all.nonunique.bed bedtools merge -i all.nonunique.bed -c 1 -o count &gt; all.merged.bed bed &lt;- read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;all.merged.bed&quot;), col_names = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;coverage&quot;) write_file(paste(unique(bed$scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/merged_1000/merged_1000.fa seqtk subseq $ref scaffolds.list &gt;&gt; scaffolds.fa Table 2.5: alignment coverage summary N Width (Mbp) Coverage (%) aligned sequence 1 786 852 130.3105 29.87923 selected scaffold 179 665 421.7514 96.70448 total 190 098 436.1239 100.00000 2.4.2 Masking scaffolds with multimatch from Scotti et al. (in prep) bed &lt;- data.table::fread(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;all.nonunique.bed&quot;), header = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;read&quot;, &quot;quality&quot;, &quot;orientation&quot;) multimatch_reads &lt;- bed %&gt;% filter(duplicated(read)) %&gt;% select(read) %&gt;% unique() %&gt;% unlist() bed %&gt;% filter(read %in% multimatch_reads) %&gt;% write_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;multimatch.bed&quot;), col_names = F) rm(bed, multimatch_reads) ; invisible(gc()) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment bedtools maskfasta -fi scaffolds.fa -bed multimatch.bed -fo masked.scaffolds.fa scf &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;masked.scaffolds.fa&quot;)) scf &lt;- data.frame(scaffold = names(scf), width = width(scf), N = letterFrequency(scf, letters = &quot;N&quot;)) %&gt;% mutate(Nperc = N/width*100) %&gt;% filter(Nperc &lt; 25 &amp; width &gt; 1000) %&gt;% select(scaffold) write_file(paste(scf$scaffold, collapse = &quot;\\n&quot;), file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/torroba_alignment seqtk subseq masked.scaffolds.fa final.scaffolds.list &gt;&gt; final.scaffolds.fa Table 2.6: alignment coverage summary N Width (Mbp) Mask (%N) Coverage (%) selected scaffold 315 226 776.5915 6.651114 178.0667 total 190 098 436.1239 NA 100.0000 2.4.3 Raw reads from Torroba-Balmori et al. (unpublished) alignment on scaffolds from Olsson et al. (2017) We used again the French Guianan raw reads from Torroba-Balmori et al. (unpublished), to align them on scaffolds from Olsson et al. (2017) with bwa. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J alignOlsson #SBATCH -o alignOlsson_output.out #SBATCH -e alignOlsson_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL # Environment module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 # read preparation cd ~/work/Symphonia_Torroba/ tar -xvzf Gbs.tar.gz cd raw rm PR_49.fastq RG_1.fastq for file in ./*.fastq do echo $file filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; perl -pe &#39;s|[\\h]||g&#39; $file &gt; &quot;${filename}&quot;.renamed.fastq rm $file done # variables cd ~/work/Symphonia_Genomes/Olsson_2016/torroba_alignment reference=~/work/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa query_path=~/work/Symphonia_Torroba/raw # alignment bwa index $reference mkdir bwa for file in $query_path/*.fastq do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; rg=&quot;@RG\\tID:${filename}\\tSM:${filename}\\tPL:IONTORRENT&quot; bwa mem -M -R &quot;${rg}&quot; $reference $file &gt; bwa/&quot;${filename}.sam&quot; rm $file done # sam2bam for file in ./bwa/*.sam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD SortSam I=$file O=bwa/&quot;${filename}&quot;.bam SORT_ORDER=coordinate done # Bam index for file in bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; java -Xmx4g -jar $PICARD BuildBamIndex I=$file O=bwa/&quot;${filename}&quot;.bai done # sam2bed mkdir bed for file in ./bwa/*.bam do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools bamtobed -i bwa/&quot;${filename}&quot;.bam &gt; bed/&quot;${filename}&quot;.bed done # merge bed mkdir merged_bed for file in ./bed/*.bed do filename=$(basename &quot;$file&quot;) filename=&quot;${filename%.*}&quot; bedtools merge -i bed/&quot;${filename}&quot;.bed &gt; merged_bed/&quot;${filename}&quot;.bed done cat bed/* | sort -k 1,1 -k2,2n &gt; all.nonunique.bed bedtools merge -i all.nonunique.bed -c 1 -o count &gt; all.merged.bed bed &lt;- read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;all.merged.bed&quot;), col_names = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;coverage&quot;) write_file(paste(unique(bed$scaffold), collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa seqtk subseq $ref scaffolds.list &gt;&gt; scaffolds.fa Table 2.7: alignment coverage summary N Width (Mbp) Coverage (%) aligned sequence 1 786 852 130.3105 12.68385 selected scaffold 1 056 548 590.1957 57.44708 total 2 653 526 1 027.3729 100.00000 2.4.4 Masking scaffolds with multimatch from Olsson et al. (2017) bed &lt;- data.table::fread(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;all.nonunique.bed&quot;), header = F) names(bed) &lt;- c(&quot;scaffold&quot;, &quot;start&quot;, &quot;end&quot;, &quot;read&quot;, &quot;quality&quot;, &quot;orientation&quot;) multimatch_reads &lt;- bed %&gt;% filter(duplicated(read)) %&gt;% select(read) %&gt;% unique() %&gt;% unlist() bed %&gt;% filter(read %in% multimatch_reads) %&gt;% write_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;multimatch.bed&quot;), col_names = F) rm(bed, multimatch_reads) ; invisible(gc()) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment bedtools maskfasta -fi scaffolds.fa -bed multimatch.bed -fo masked.scaffolds.fa scf &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;masked.scaffolds.fa&quot;)) scf &lt;- data.frame(scaffold = names(scf), width = width(scf), N = letterFrequency(scf, letters = &quot;N&quot;)) %&gt;% mutate(Nperc = N/width*100) %&gt;% filter(Nperc &lt; 25 &amp; width &gt; 1000) %&gt;% select(scaffold) write_file(paste(scf$scaffold, collapse = &quot;\\n&quot;), file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.list&quot;)) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/torroba_alignment ref=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Olsson_2016/Olsson2017/Olsson2017.fa seqtk subseq masked.scaffolds.fa final.scaffolds.list &gt;&gt; final.scaffolds.fa Table 2.8: alignment coverage summary N Width (Mbp) Mask (%N) Coverage (%) selected scaffold 245 646 464.1304 1.896894 45.17643 total 2 653 526 1 027.3729 NA 100.00000 2.4.5 Removing scaffolds already matching transcripts func &lt;-unlist(read_tsv(file.path(path, &quot;Ivan_2018&quot;, &quot;transcript_alignment&quot;, &quot;selected_scaffolds.list&quot;), col_names = F)) neutral &lt;- readDNAStringSet(file.path(path, &quot;Ivan_2018&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.fa&quot;)) writeXStringSet(neutral[setdiff(names(neutral), func)], file.path(path, &quot;neutral_selection&quot;, &quot;Ivan.selected.scaffolds.fa&quot;)) func &lt;-unlist(read_tsv(file.path(path, &quot;Olsson_2016&quot;, &quot;transcript_alignment&quot;, &quot;selected_scaffolds.list&quot;), col_names = F)) neutral &lt;- readDNAStringSet(file.path(path, &quot;Olsson_2016&quot;, &quot;torroba_alignment&quot;, &quot;final.scaffolds.fa&quot;)) writeXStringSet(neutral[setdiff(names(neutral), func)], file.path(path, &quot;neutral_selection&quot;, &quot;Olsson.selected.scaffolds.fa&quot;)) 2.4.6 Merge of selected scaffolds We merged selected scaffolds from Scotti et al (in prep) and Olsson et al. (2017) with quickmerge. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection ref=Ivan.selected.scaffolds.fa query=Olsson.selected.scaffolds.fa nucmer -l 100 -prefix out $ref $query delta-filter -i 95 -r -q out.delta &gt; out.rq.delta ~/Tools/quickmerge/quickmerge -d out.rq.delta -q $query -r $ref -hco 5.0 -c 1.5 -l n -ml m We merged selected scaffolds from Scotti et al (in prep) and Olsson et al. (2017) with quickmerge. We found 13 343 overlaps resulting a final merged assembly of 82 792 scaffolds for a total length of 146.80 Mb. Figure 2.4: Merging result from quickmerge. Left graph represents the overlap distribution. Right graph represent the merged scaffolds distribution. 2.4.7 Final subset of selected neutral scaffolds We finally selected 0.533 Mb of sequences by sampling 533 1-kb sequences among 533 scaffolds (1 sequence per scaffold) with a probability \\(p=\\frac{scaffold\\_length}{total\\_length}\\). scf &lt;- readDNAStringSet(file.path(path, &quot;neutral_selection&quot;, &quot;merged.fasta&quot;)) selection &lt;- data.frame(scf = names(scf), width = width(scf), N = letterFrequency(scf, &quot;N&quot;)) %&gt;% sample_n(533, weight = width) %&gt;% select(scf) %&gt;% unlist() scf_sel &lt;- subseq(scf[selection], end=1000, width=1000) writeXStringSet(scf_sel, file.path(path, &quot;neutral_selection&quot;, &quot;selected.scaffolds.fa&quot;)) Table 2.9: Selected neutral scaffolds N Width (Mbp) Mask (%N) 533 0.533 0.0036529 2.4.8 Repetitive regions final check Last but not least, we do not want to include repetitive regions in our targets for baits design. We consequently aligned raw reads from one library from Scotti et al. (in prep) on our targets with bwa. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection reference=selected.scaffolds.fa query=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/raw_reads/globu1_symphonia_globulifera_CTTGTA_L001_R1_001.fastq.gz bwa index $reference bwa mem -M $reference $query &gt; raw_read_alignment.sam picard=~/Tools/picard/picard.jar java -Xmx4g -jar $picard SortSam I=raw_read_alignment.sam O=raw_read_alignment.bam SORT_ORDER=coordinate bedtools bamtobed -i raw_read_alignment.bam &gt; raw_read_alignment.bed cat raw_read_alignment.bed | sort -k 1,1 -k2,2n &gt; raw_read_alignment.sorted.bed bedtools merge -i raw_read_alignment.sorted.bed -c 1 -o count &gt; raw_read_alignment.merged.bed We obtained a continuous decreasing distribution of read coverage across our scaffolds regions (figure 2.5). We fitted a \\(\\Gamma\\) distribution with positive parameters for scaffolds regions with a coverage under 5 000 (non continuous distribution with optimization issues). We obtained a distribution with a mean of 324 reads per region and a \\(99^{th}\\) quantile of 4 042. We decided to mask regions with a coverage over the \\(99^{th}\\) quantile and remove scaffolds with a mask superior to 75% of its total length (figure 2.5). Figure 2.5: Read coverage distribution. repetitive_target &lt;- bed %&gt;% filter(coverage &gt; qgamma(0.99, alpha, beta)) %&gt;% mutate(size = end - start) repetitive_target %&gt;% select(target, start, end) %&gt;% arrange(target, start, end) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;neutral_selection&quot;, &quot;repetitive_targets.bed&quot;), col_names = F) Figure 2.6: target regions with a coverage over the 99th quantile of the fitted Gamma distribution (4042). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection cat repetitive_targets.bed | sort -k 1,1 -k2,2n &gt; repetitive_targets.sorted.bed bedtools maskfasta -fi selected.scaffolds.fa -bed repetitive_targets.sorted.bed -fo targets.masked.fasta targets &lt;- readDNAStringSet(file.path(path, &quot;neutral_selection&quot;, &quot;targets.masked.fasta&quot;)) writeXStringSet(targets[which(letterFrequency(targets, &quot;N&quot;)/width(targets) &lt; 0.65)], file.path(path, &quot;neutral_selection&quot;, &quot;targets.filtered.masked.fasta&quot;)) Table 2.10: Selected, masked and filtered funcional targets. N Width (Mbp) Mask (%N) 415 0.415 0.024412 2.5 Fuctional region selection We used open reading frames (ORF) to target genes within scaffolds. ORFs have been detected with transdecoder on assembled transcripts. First, we filtered ORFs including a start codon(figure 2.7). Then, we aligned ORFs on pre-selected and merged genomic scaffolds with blat. We obtained 7 744 aligned scaffolds (table 2.11 and figure 2.8). Thanks to alignments, we removed overlapping genes (figure 2.9) and obtained 4 076 pre-selected genes with a total length of 757 kbp (figure 2.10). Finally, we used transcript differential expression to select all genes differentially expressed between Symphonia globulifera and Symphonia sp1 (figure 2.11). We selected 1150 sequences of 500 to 1-kbp representing 1 063 Mbp (table 2.12). To validate our final target set, we aligned with bwa raw reads from one library from Scotti et al. (in prep). 2.5.1 Open Reading Frames (ORFs) filtering 173 828 ORFs including a start codon (Methyonin, M) were detected (over 231 883, 75%, see figure 2.7. Figure 2.7: Open Reading Frames left and right peptides. orf &lt;- src_sqlite(file.path(path, &quot;Niklas_transcripts/Trinotate/&quot;, &quot;symphonia.trinity500.trinotate.sqlite&quot;)) %&gt;% tbl(&quot;ORF&quot;) %&gt;% dplyr::rename(orf = orf_id, trsc = transcript_id, orfSize = length) %&gt;% filter(substr(peptide, 1, 1) == &quot;M&quot;) %&gt;% select(-peptide, -strand) %&gt;% collect() %&gt;% rowwise() %&gt;% mutate(orfStart = min(as.numeric(lend), as.numeric(rend)), orfEnd = max(as.numeric(lend), as.numeric(rend))) %&gt;% select(-lend, -rend) %&gt;% select(trsc, orfStart, orfEnd, orf) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;orf.all.bed&quot;), col_names = F) 2.5.2 ORF alignment on genomics scaffolds 7 744 scaffolds matched with ORFs (10.5% for 15.4 Mbp, see table 2.11 and figure 2.8). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat orf.all.bed | sort -k 1,1 -k2,2n &gt; orf.all.sorted.bed trsc=/home/sylvain/Documents/BIOGECO/PhD/data/Symphonia_Niklas/filtered_transcripts.fasta bedtools getfasta -name -fi $trsc -bed orf.all.sorted.bed -fo orf.fasta scf=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection/merged.fasta orf=./orf.fasta blat $scf $orf alignment.psl Table 2.11: Alignment coverage of Tysklind et al. (in prep) ORFs over genomic scaffolds with blat. N Width (Mbp) Coverage (%) aligned sequence 21 146 2.201315 1.499565 selected scaffold 7 744 15.425248 10.507881 total 82 792 146.796946 100.000000 Figure 2.8: Alignment result of Tysklind et al. (in prep) ORFs over genomic scaffolds with blat. Left graph represents the overlap distribution. Right graph represent the selected and deduplicated scaffolds distribution. 2.5.3 Overlaping genes filtering 995 genes were overlapping and filtered out (figure 2.9). alignment %&gt;% separate(orf, into = c(&quot;gene&quot;, &quot;isoform&quot;, &quot;geneNumber&quot;, &quot;orfNumber&quot;), sep = &quot;::&quot;, remove = F) %&gt;% select(gene, orf, orfStart, orfEnd, scf, scfStart, scfEnd) %&gt;% unique() %&gt;% select(scf, scfStart, scfEnd, orf, gene) %&gt;% arrange(scf, scfStart, scfEnd) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;genes.all.bed&quot;), col_names = F) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat genes.all.bed | sort -k 1,1 -k2,2n &gt; genes.all.sorted.bed bedtools merge -i genes.all.sorted.bed -c 5 -o collapse &gt; genes.merged.bed Figure 2.9: Genes overlap 2.5.4 Pre-selected genes We obtained 4 076 genes pre-selected for a total length of 757 kbp (figure 2.10). Figure 2.10: Available genes for target sequences design. 2.5.5 Differential Expression (DE) of genes Figure 2.11 shows genes differential expression. First circle represents genes with isoforms not enriched whereas second and third circle represent, respectively, genes with isoforms S. sp1 and S. globulifera enriched. Relatively few genes contained enriched isoforms, and most of them were S. globulifera enriched. Legend Figure 2.11: Genes differential expression. 2.5.6 Final subset of selected functional scaffolds We finally selected 1150 sequences of 500 to 1-kbp with 100 bp before geneStart and a maximum of 900 bp after, resulting in 1 063, 544 kbp of targets. All differentially expressed genes between morphotypes were selected (159). And the rest of sequences were randomly selected among non differentially expressed genes (1001). targets &lt;- genes %&gt;% left_join(de) %&gt;% filter(deg %in% c(&quot;Eglo&quot;, &quot;Esp&quot;)) %&gt;% rbind(genes %&gt;% left_join(de) %&gt;% filter(deg %in% c(&quot;DE&quot;, NA)) %&gt;% sample_n(1309)) %&gt;% group_by(scf, gene) %&gt;% filter(n() &lt; 2) %&gt;% mutate(targetStart = max(0, geneStart - 100)) %&gt;% mutate(targetEnd = min(targetStart + 1000, scfSize)) %&gt;% mutate(targetSize = targetEnd - targetStart) %&gt;% filter(targetSize &gt; 500) %&gt;% mutate(target = paste0(gene, &quot;_on_&quot;, scf)) %&gt;% ungroup() targets %&gt;% select(scf, targetStart, targetEnd, target) %&gt;% arrange(scf, targetStart, targetEnd, target) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;targets.all.bed&quot;), col_names = F) cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat targets.all.bed | sort -k 1,1 -k2,2n &gt; targets.all.sorted.bed scf=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/neutral_selection/merged.fasta bedtools getfasta -name -fi $scf -bed targets.all.sorted.bed -fo targets.fasta Table 2.12: Selected functional targets N Width (Mbp) Mask (%N) 1 165 1.068207 0.0025285 2.5.7 Repetitive regions final check Last but not least, we do not want to include repetitive regions in our targets for baits design. We consequently aligned raw reads from one library from Scotti et al. (in prep) on our targets with bwa. cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 reference=targets.fasta query=~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/Ivan_2018/raw_reads/globu1_symphonia_globulifera_CTTGTA_L001_R1_001.fastq.gz bwa index $reference bwa mem -M $reference $query &gt; raw_read_alignment.sam picard=~/Tools/picard/picard.jar java -Xmx4g -jar $picard SortSam I=raw_read_alignment.sam O=raw_read_alignment.bam SORT_ORDER=coordinate bedtools bamtobed -i raw_read_alignment.bam &gt; raw_read_alignment.bed cat raw_read_alignment.bed | sort -k 1,1 -k2,2n &gt; raw_read_alignment.sorted.bed bedtools merge -i raw_read_alignment.sorted.bed -c 1 -o count &gt; raw_read_alignment.merged.bed We obtained a continuous decreasing distribution of read coverage across our scaffolds regions (figure 2.12). We fitted a \\(\\Gamma\\) distribution with positive parameters for scaffolds regions with a coverage under 5 000 (non continuous distribution with optimization issues). We obtained a distribution with a mean of 309 reads per region and a \\(99^{th}\\) quantile of 2 606. We decided to mask regions with a coverage over the \\(99^{th}\\) quantile and remove scaffolds with a mask superior to 75% of its total length (figure 2.12). Figure 2.12: Read coverage distribution. repetitive_target &lt;- bed %&gt;% filter(coverage &gt; qgamma(0.99, alpha, beta)) %&gt;% mutate(size = end - start) repetitive_target %&gt;% select(target, start, end) %&gt;% arrange(target, start, end) %&gt;% mutate_if(is.numeric, as.character) %&gt;% write_tsv(path = file.path(path, &quot;functional_selection2&quot;, &quot;repetitive_targets.bed&quot;), col_names = F) Figure 2.13: target regions with a coverage over the 99th quantile of the fitted Gamma distribution (2606). cd ~/Documents/BIOGECO/PhD/data/Symphonia_Genomes/functional_selection2 cat repetitive_targets.bed | sort -k 1,1 -k2,2n &gt; repetitive_targets.sorted.bed bedtools maskfasta -fi targets.fasta -bed repetitive_targets.sorted.bed -fo targets.masked.fasta targets &lt;- readDNAStringSet(file.path(path, &quot;functional_selection2&quot;, &quot;targets.masked.fasta&quot;)) writeXStringSet(targets[which(letterFrequency(targets, &quot;N&quot;)/width(targets) &lt; 0.65)], file.path(path, &quot;functional_selection2&quot;, &quot;targets.filtered.masked.fasta&quot;)) Table 2.13: Selected, masked and filtered funcional targets. N Width (Mbp) Mask (%N) 975 0.896759 0.0168273 References "],["genomic-libraries-and-sequence-capture.html", "Chapter 3 Genomic libraries and sequence capture 3.1 Plates 3.2 Libraries preparation protocol 3.3 Library preparation results 3.4 Capture", " Chapter 3 Genomic libraries and sequence capture Genomic DNA was extracted from 5 mg of dried leaf tissue with a CTAB protocol (Doyle &amp; Doyle 1987). DNA extracts were digested with ‘Ultra II FS Enzyme Mix’ (new England Biolabs Inc, MA, USA) for a target size of 150 bp, and libraries built with the ‘NEBNext Ultra II FS DNA Library Prep kit for Illumina’(New England Biolabs Inc, MA, USA). We amplified and tagged libraries using 5 \\(\\mu L\\) of adaptor-ligated DNA, 8.3 \\(\\mu L\\) of ‘NEBNext Ultra II Q5 Master Mix’ (new England Biolabs Inc, MA, USA), 2x 1.6 \\(\\mu L\\) of Index Primer i5 and i7 from ‘NEBNext Multiplex Oligos for Illumina (Dual Index Primers Set 1 and Set 2)’ (new England Biolabs Inc, MA, USA). Initial denaturation (98°C for 30 s) was followed by 8 cycles (98°C for 10 s and 65°C for 1 min 30 s) and a final extension (65°C for 5 min). We pooled libraries in four equimolar multiplexes for each genus. We obtained a custom made set of 20,000 80-mer probes using myBaits Custom 1-20K (Arbor Biosciences, MI, USA) and conducted the capture experiments using the corresponding myBaits V4 protocol with a hybridization time of 80 hours. We pooled the four multiplexes and sequenced them in two lanes of an Illumina HiSeq 4000 instrument obtaining 2x150bp pair-end reads. 3.1 Plates This sub-chapter describes preparation of plates after the extraction and before library preparation. First we looked into plates design after extraction. Then we quantified their concentration, volume and DNA quantity, before rearranging them based on their concentration. Finally plates concentration was adjusted to 20 \\(ng.\\mu L^{-1}\\) and sorted by electrophoresis evaluation. 3.1.1 Extraction 3.1.1.1 Extraction Plates Plates after extraction were arranged following figure 3.1. Figure 3.1: Extraction plates organization All plates were quantified through NanoDrop and some of them with Qubit which is more accurate. We used Qubit-NanoDrop relation to have an estimation of concentration for all samples. Finally electrophoreses were also used to assess DNA quality and degradation. 3.1.1.2 Extraction NanoDrop NanoDrop evaluated \\(1 \\mu L\\) of samples DNA concentration (figure 3.2) by absorption in addition to contamination. But NanoDrop is known to be inaccurate, especially under 25 \\(ng.\\mu L^{-1}\\). Figure 3.2: Extraction plate NanoDrop concentration (in ng/microL) 3.1.1.3 Extraction Qubit We used Qubit on 12 samples to have a more precise idea of samples concentration. Qubit uses fluorescence to measure samples concentration in \\(ng.\\mu L^{-1}\\). We compared Qubit estimation of concentration to NanoDrop estimation. We used a bayesian approach to fit the model \\(Concentration_{Qubit} \\sim \\mathcal{N}(\\beta*Concentration_{NanoDrop},\\sigma)\\) with a null intercept. We found a pretty strong relation with a beta around 0.3. We used this relation to better estimate the concentration of all samples. Table 3.1: Summary table of the model term estimate std.error rhat beta 0.294358 0.0226327 0.9998834 sigma 7.881824 2.2547057 1.0013069 Figure 3.3: Model result of the relation between DNA concentration measured with Qubit and NanoDrop. Color indicates the electrophoresis classification of the samples. 3.1.1.4 Extraction Electrophoresis We evaluated samples quality and degradation by an electrophoresis of 1 to 1.5 \\(\\mu L\\) of sample DNA with 1 to 1.5 \\(\\mu L\\) of weight migrating 20 minutes with 20 V on an agarose gel with 80 \\(mL\\) of 0.1 X TAE with 1 \\(\\mu L\\) of red gel. Samples were classified as good, medium and bad. “Good” samples only included a band at high molecular weight. “Bad” samples only included a smear at low molecular weight indicating degraded DNA. “Medium” samples included both. Figure 3.4: Extraction plate Electrophoresis quality 3.1.2 Library plates design We first designed new plates based on the samples concentration in order to bring all samples to the same concentration for further easier manipulations in library preparation. 3.1.2.1 Pool We pooled all individuals with 2 extractions and with a nanodrop concentration inferior to 25 \\(ng.\\mu L^{-1}\\). Individuals with only one extraction were further concentrated. Warning, P7-3-2812 has been pooled from P2.C12 to P7.C12 instead of P7.D12. Table 3.2: Preview of Samples to be pooled. From plates 1, 2 and 3 to plate 5, 6 and 7 ID Plate_extraction Position_extraction nanodrop P10_3_2912 1 G10 NA P10_3_2912 6 G10 10.70 P11_1_742 3 C2 23.29 P11_1_742 5 D3 18.96 P13_2_2819 2 F5 NA P13_2_2819 7 F5 21.52 3.1.2.2 Pool and new samples nanodrop Pooled individuals and new individuals from Itubera Brazil (n = 3), La Selva Costa Rica (n = 2) and Barro Colorado Island Panama (n = 2) have been quantified again with the nanodrop. Table 3.3: Preview of New nanodrops. ID nanodrop Plate Position P4-2-3487 20.71 Pull NA LS-SG18 49.53 America NA IT_H5 12.86 Itubera H5 IT_H3 16.37 Itubera H3 IT_B4 19.42 Itubera B4 3.1.2.3 Concentration Plates We reorganised plates in a new scheme ordered by concentration following figure 3.5 design with figure 3.6 concentrations. Figure 3.5: Previous extraction position in plates arranged by concentration. Figure 3.6: Concentration in plates arranged by concentration. 3.1.2.4 Samples volume In order to adjust samples concentration we needed first to assess their current volume, see figure 3.7. Volume after extraction was around 45 \\(\\mu L\\) (estimated loss). Samples have lost volume with NanoDrop, Qubit, electrophoresis, and libraries trial, one or two times. Some samples gained volume with pooling. We can consider all samples to have lost 1 \\(\\mu L\\) with NanoDrop. Samples used in Qubit lost an additional 1.5 to 3 \\(\\mu L\\). Finally samples used in trial libraries lost between 0.5 and 5 \\(\\mu L\\) (with library test II repeated). Pooled samples from plate 5, 6 an 7 gained 49 \\(\\mu L\\) from NanoDrop samples from plate 1, 2, 3 and 4 unused for NanoDrop, Qubit nor libraries trial (original 50 minus 1 due to NanoDrop measurement). Added samples from Itubera, La Selva and Barro Colorado Island have an estimated volume of 10 \\(\\mu L\\) (overestimated). Figure 3.7: Samples estimated volumes. 3.1.2.5 DNA quality We assessed DNA fragment quality and size through electrophoresis and reorganized columns inside plates by quality. ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 MHDN… PCR1 B1 49 1.44 PCR2 ## 2 P15_… PCR1 D1 50 3.00 PCR2 ## 3 P3_2… PCR1 E1 50 3.10 PCR2 ## 4 MHDN… PCR1 F1 49 3.17 PCR2 ## 5 P5_4… PCR1 G1 50 3.36 PCR2 ## 6 P13_… PCR1 H1 50 3.45 PCR2 ## 7 P13_… PCR1 F2 50 3.93 PCR2 ## 8 P7_3… PCR1 G2 50 4.76 PCR2 ## 9 EE16… PCR1 A3 49 5.44 PCR2 ## 10 MH31… PCR1 B3 49 5.47 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P15_… PCR1 E3 49 22.7 PCR2 ## 2 P1_4… PCR1 H3 49 23.2 PCR2 ## 3 OH29… PCR1 D5 44.1 24.2 PCR2 ## 4 P4_2… PCR1 F5 49 24.2 PCR2 ## 5 P13_… PCR1 G5 49 24.2 PCR2 ## 6 P7_2… PCR1 C6 49 24.8 PCR2 ## 7 P4_1… PCR1 E6 49 25.1 PCR2 ## 8 P16_… PCR1 A7 49 25.5 PCR2 ## 9 P10_… PCR1 D7 49 25.6 PCR2 ## 10 P10_… PCR1 F7 49 25.7 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 48 x 7 ## # Groups: ID [48] ## ID source_Plate source_Position volumeplus5 concentration dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P3_2… PCR1 A1 49 56.0 PCR2 ## 2 P7_2… PCR1 B1 49 57.7 PCR2 ## 3 P13_… PCR1 F1 49 60.5 PCR2 ## 4 P6_4… PCR1 H1 49 63.6 PCR2 ## 5 P7_3… PCR1 A2 49 63.7 PCR2 ## 6 P15_… PCR1 B2 49 64.4 PCR2 ## 7 P7_3… PCR1 C2 49 69.5 PCR2 ## 8 P13_… PCR1 D2 49 70.1 PCR2 ## 9 P7_3… PCR1 H2 49 73.1 PCR2 ## 10 P15_… PCR1 C3 47.7 75.0 PCR2 ## # … with 38 more rows, and 1 more variable: dest_Position &lt;chr&gt; ID Plate_concentration Position_concentration volumeplus5 concentration Plate_library Position_library P15_3_267 1 D1 98 3.002452 1 B1 P3_2_739 1 E1 98 3.096646 1 C1 P5_4_658 1 G1 98 3.355682 1 E1 P13_2_929 1 H1 98 3.446932 1 F1 P13_4_149 1 F2 98 3.929680 1 G1 P7_3_2837 1 G2 98 4.762713 1 H1 P4_1_3000 1 C3 98 5.895991 1 C2 P6_3_346 1 E3 98 6.172688 1 D2 P11_1_742 1 G3 98 6.908583 1 E2 P7_3_679 1 B2 98 3.761896 1 B4 P15_4_40 1 C2 98 3.829598 1 C4 P7_2_3049 1 D2 98 3.847259 1 F7 P10_3_2912 1 E2 95 3.912018 1 G7 P7_2_2520 1 H2 98 5.086507 1 H7 P4_2_3487 1 D3 98 6.096155 1 A8 P6_3_2800 1 D4 98 7.997708 1 D8 P7_3_2812 2 A11 98 19.118554 2 F3 Figure 3.8: Plates electrophoresis status before rearrangement. Figure 3.9: Plates electrophoresis status after rearrangement. 3.1.2.6 Concentration All individuals with an estimated concentration inferior to 19 \\(ng.\\mu L^{-1}\\) (Plates 1 and 2) have been dried in the speed vacuum centrifuge. And corresponding volume of milliQ water will be added to reach a concentration of 20 \\(ng.\\mu L^{-1}\\) (or at least 6.5 \\(\\mu L\\) to reach sample volume). Their DNA content in \\(ng\\) has been computed multiplying concentration with volume. The volume of water to add is thus the DNA content divided by the objective concentration of 20 \\(ng.\\mu L^{-1}\\): \\(V = \\frac{C_0*V_0}{20}\\). Corresponding volumes are shown in figure 3.11. Figure 3.10: Samples to be concentrated. Estimated concentration in ng/microL Figure 3.11: Volume to resuspend dry samples. ## # A tibble: 192 x 6 ## source_Plate source_Position sample_volume new_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 PCR1 A1 0 10 PCR2 ## 2 PCR1 B1 0 14 PCR2 ## 3 PCR1 C1 0 14.4 PCR2 ## 4 PCR1 D1 0 10 PCR2 ## 5 PCR1 E1 0 15.6 PCR2 ## 6 PCR1 F1 0 16 PCR2 ## 7 PCR1 G1 0 18.3 PCR2 ## 8 PCR1 H1 0 22.1 PCR2 ## 9 PCR1 A2 0 12 PCR2 ## 10 PCR1 B2 0 12 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; 3.1.2.7 Samples volume The objective was to get 100 \\(ng\\) of DNA in 6.5 \\(\\mu L\\) of sample for the library preparation. Consequently we needed to extract with the robot \\(V = \\frac{n}{C} = \\frac{100}{C}\\) with \\(C\\) the sample concentration in \\(ng.\\mu L^{-1}\\). Figure 3.12: Sample volume (microL) ## # A tibble: 192 x 7 ## # Groups: ID [192] ## ID source_Plate source_Position sample_volume water_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P15_… PCR1 A1 4.4 2.1 PCR2 ## 2 P1_4… PCR1 B1 4.3 2.2 PCR2 ## 3 OH29… PCR1 C1 4.1 2.4 PCR2 ## 4 P4_2… PCR1 D1 4.1 2.4 PCR2 ## 5 P13_… PCR1 E1 4.1 2.4 PCR2 ## 6 P7_2… PCR1 F1 4 2.5 PCR2 ## 7 P4_1… PCR1 G1 4 2.5 PCR2 ## 8 P16_… PCR1 H1 3.9 2.6 PCR2 ## 9 P10_… PCR1 A2 3.9 2.6 PCR2 ## 10 P10_… PCR1 B2 3.9 2.6 PCR2 ## # … with 182 more rows, and 1 more variable: dest_Position &lt;chr&gt; ## # A tibble: 48 x 7 ## # Groups: ID [48] ## ID source_Plate source_Position sample_volume water_volume dest_Plate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 P3_2… PCR1 A1 3.6 9.4 PCR2 ## 2 P7_2… PCR1 B1 3.5 9.5 PCR2 ## 3 P13_… PCR1 C1 3.3 9.7 PCR2 ## 4 P6_4… PCR1 D1 3.1 9.9 PCR2 ## 5 P7_3… PCR1 E1 3.1 9.9 PCR2 ## 6 P15_… PCR1 F1 3.1 9.9 PCR2 ## 7 P7_3… PCR1 G1 2.9 10.1 PCR2 ## 8 P13_… PCR1 H1 2.9 10.1 PCR2 ## 9 P7_3… PCR1 A2 2.7 10.3 PCR2 ## 10 P15_… PCR1 B2 2.7 10.3 PCR2 ## # … with 38 more rows, and 1 more variable: dest_Position &lt;chr&gt; Plate_library Position_library sample_volume water_volume 3 F3 4.782128 1.717872 3 G3 4.742738 1.757262 3 H3 4.676794 1.823206 3 A4 4.579085 1.920915 3 C7 5.004011 1.495988 3 D7 4.935673 1.564327 3 E7 4.933522 1.566478 3 F7 4.896546 1.603454 3 G7 4.860815 1.639185 3 H7 4.843489 1.656511 3 A8 4.799016 1.700984 3 B8 4.764021 1.735979 3 C8 4.757350 1.742650 3 D8 4.708556 1.791444 3 E8 4.669723 1.830277 3 F8 4.665875 1.834125 3 G8 4.639748 1.860252 3 H8 4.582792 1.917208 3 A9 4.520590 1.979410 3.2 Libraries preparation protocol The protocol is given per sample with the corresponding volume for a plate of 96 samples in bracket. 3.2.1 Material preparation 0.5 \\(\\mu L\\) of 10mM TrisHCL + 10 mM NaCl (48 \\(\\mu L\\) per plate) 46.875 \\(\\mu L\\) of 0.1X TE buffer (2 136.875 \\(\\mu L\\) per plate) = 4.7 \\(\\mu L\\) of TE buffer (213.7 \\(\\mu L\\) per plate) + 42.3 \\(\\mu L\\) of water (1 923.3 \\(\\mu L\\) per plate) 400 \\(\\mu L\\) of fresh 80% Ethanol (38 400 \\(\\mu L\\) per plate) 3.2.2 Fragmentation Prepare 6.5 \\(\\mu L\\) of samples with ca 100 \\(ng\\) of DNA (see previous chapter) On ice, pipette up and down ULTRA II FS Reaction Buffer 10X, vortex 5\" and spin On ice, vortex 5\" Ultra II FS Enzyme Mix and spin On ice, premix 0.5 \\(\\mu L\\) of Ultra II FS Enzyme Mix (48 \\(\\mu L\\) per plate) with 1.75 \\(\\mu L\\) of Ultra II FS Reaction Buffer (168 \\(\\mu L\\) per plate), vortex and spin On ice, add 2.25 \\(\\mu L\\) of premix to each sample, vortex 5\" and spin: Component Volume per library Volume per plate DNA 6.5 \\(\\mu L\\) Ultra II FS Enzyme Mix 0.5 \\(\\mu L\\) 48 \\(\\mu L\\) Ultra II FS Reaction Buffer 1.75 \\(\\mu L\\) 168 \\(\\mu L\\) Total 8.75 \\(\\mu L\\) Thermocycle with following programs depending on electrophoresis quality: Good: 13'@37°C, 30'@65°C, Hold@-4°C Medium: 9'@37°C, 30'@65°C, Hold@-4°C Bad: 1'@37°C, 30'@65°C, Hold@-4°C Optionally, put the NEBNext adaptor for Illumina out of the freezer (long to melt) Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.3 Adaptor ligation On ice, prepare diluted adaptor (1:5) with 0.125 \\(\\mu L\\) of NEBNext adaptor for Illumina (12 \\(\\mu L\\) per plate) diluted into 0.5 \\(\\mu L\\) of 10mM TrisHCL + 10 mM NaCl (48 \\(\\mu L\\) per plate) On ice, premix 7.5 \\(\\mu L\\) of NEBNext Ultra II Ligation Master Mix (720 \\(\\mu L\\) per plate) with 0.25 \\(\\mu L\\) of NEBNext ligation enhancer (24 \\(\\mu L\\) per plate), vortex and spin On ice, add 0.625 \\(\\mu L\\) of diluted adaptor and 7.75 \\(\\mu L\\) of premix to samples, mix and spin: Component Volume per library Volume per plate DNA 8.75 \\(\\mu L\\) NEBNext Ultra II Ligation Master Mix 7.5 \\(\\mu L\\) 720 \\(\\mu L\\) NEBNext ligation enhancer 0.25 \\(\\mu L\\) 24 \\(\\mu L\\) diluted NEBNext adaptor (1:5) 0.625 \\(\\mu L\\) 50 \\(\\mu L\\) Total 17.25 \\(\\mu L\\) Incubate 15'@20°C with lid open On ice, add 0.75 \\(\\mu L\\) of USER Enzyme (72 \\(\\mu L\\) per plate) to samples, mix and spin Incubate 15'@37°C with lid hot (&gt;47°C) Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.4 Size selection Bring the sample volume from 17.125 \\(\\mu L\\) to 27.125 \\(\\mu L\\) adding 10 \\(\\mu L\\) of 0.1X TE buffer (1 716 \\(\\mu L\\) per plate) Vortex PGTB beads from batch E at room temperature Add 7 \\(\\mu L\\) (~0.28X) of beads (672 \\(\\mu L\\) per plate) to each sample, mix, vortex 5\" keeping beads, incubet 5’, spin, place on magnet, wait 5’, and transfer ~32 \\(\\mu L\\) of sample to a new plate Add 3.5 \\(\\mu L\\) (~0.14X) of beads (336 \\(\\mu L\\) per plate) to each sample, mix, wait 5’ without the magnet Place on magnet, wait 5\" and discard ~35.5 \\(\\mu L\\) of supernatant Add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate) to the beads on the magnet, wait 30’ remove supernatant Repeat, add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate) to the beads on the magnet, wait 30\" remove supernatant Air dry beads 3’ on magnet Remove magnet, elute into 12 \\(\\mu L\\) of hot 0.1X TE (1 152 \\(\\mu L\\) per plate) (~40°C), mix, incubate 2’, spin, put on magnet, wait 5’ Transfer 2 x 5 \\(\\mu L\\) of supernatant to 2 new plates Optionally, samples can be stored overnight at \\(-20^\\circ\\) 3.2.5 Enrichment and purification protocol given for delivered oligos at \\(100mM\\), not NEBNext tag at \\(10mM\\) Prepare diluted index (1:10) with 0.16 \\(\\mu L\\) of Index Primer i5 and i7 diluted in 1.44 \\(\\mu L\\) of mQ \\(H_2O\\) (1.92 \\(\\mu L\\) of i5 per row and 1.28 \\(\\mu L\\) of i7 per column) Mix in each plate (2 for the 2 PCR), mix and spin : Component Volume per library Volume per plate/row/column sample 5 \\(\\mu L\\) NEBNext Ultra II Q5 Master Mix 8.3 \\(\\mu L\\) 796.8 \\(\\mu L\\) diluted Index Primer i5 (1:10) 1.6 \\(\\mu L\\) 19.2 \\(\\mu L\\) diluted Index Primer i7 (1:10) 1.6 \\(\\mu L\\) 12.8 \\(\\mu L\\) Total 16.5 \\(\\mu L\\) Thermocycle with following program 30\"@98°C 8 cycles of 10\"@98°C and 75\"@65°C 5'@65°C Hold@4°C Optionally, amplify only the first plate, assess it with electrophoresis, and adjust cycles number for the second amplification depending on gel migration Pool PCR results (~16.5 \\(\\mu L\\) per sample) from the 2 plates into one (~33.3K \\(\\mu L\\) per sample) Vortex PGTB beads from batch E at room temperature Add 30 \\(\\mu L\\) (~0.9X) of beads (2 880 \\(\\mu L\\) per plate), mix, vortex 5\" keeping beads, spin, place on magnet, wait 5’, and remove supernatant (~ 63 \\(\\mu L\\) per sample) Add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate), wait 30’ remove supernatant Repeat, add 100 \\(\\mu L\\) of fresh 80% Ethanol (9 600 \\(\\mu L\\) per plate), wait 30\" remove supernatant Air dry beads 3’ on magnet Remove magnet, elute into 22 \\(\\mu L\\) of hot 0.1X TE (2 112 \\(\\mu L\\) per plate) (~40°C), mix, incubate 2’, and spin Place on magnet, wait 5’, transfer 22 \\(\\mu L\\) of supernatant to a new plate and store at \\(-20^\\circ\\) 3.3 Library preparation results 3.3.1 Post-enrichment PCR1 quantification After the enrichment and the purification of the first PCR (PCR1), we quantified double strand DNA in every plate in order to adjust the second PCR (PCR2), and more specifically in order to increase the number of cycles in PCR2. We used both Quant-It and a few samples on Qubit and transformed raw absorbance results into concentration with regressions. 3.3.2 Post-enrichment (PCR1 &amp; PCR2) and amplification quantification Libraries showing no band or light smear in the electrophoresis have been amplified, resulting in amplified plates A1 and A2. We used the Quant-It to dose all samples (original libraries and amplified libraries). 3.3.3 Amplification result We used electrophoresis and noticed if re-amplified samples had a band (B), a light smear (L) or nothing (A). Samples without anything (A) had their library repeated. Figure 3.13: Electrophoresis Amplified 3.3.4 Library &amp; extraction repetition result 69 libraries were still not satisfying after amplification. Those libraries have been rebuilt from source DNA. Among them, 43 were still not good at the electrophoresis and DNA has been re-extracted. Electrophoresis of re-extracted samples show a high heterogeneity of size, and around 8 of them seem to have not worked. All new samples have been quantified and libraries re-prepared according to the previously detailed protocol. 3.4 Capture We did 16 reactions of gene capture by hybridization. Each reaction had up to 32 samples. We proceeded as follows: Amplifcation 1 Plate reorganization: plates state and volume have been assessed and 6 new plates (P1 to P6) have been built from (i) original libraries (P1-P5), (ii) reamplified libraries (A1-A2), and (iii) extraction and library repeat (P6). In order to do so, P6 stayed unchanged, and new plates 1 to 5 were either reamplified libraries or original libraries if not reamplified. Tip: remove unwanted cone from boxes when transferring original P1 to P5 to new ones to work with multi-channel pipette and prepare correspondence table to transfer reamplified plates A1 and A2 to new P1 to P5 plates crossing each line one-by-one. DNA dosage 1: with PicoGreen, we will assess DNA concentration of each sample with a ladder from 5 to 30 \\(ng.\\mu L^{-1}\\) in order to correctly dose low concentration samples. Amplification 2: Samples that have never been reamplified with a concentration below 1 \\(ng.\\mu L^{-1}\\) have been reorganized on a new plate (A3) and reamplified with 8 cycles. DNA dosage 2: Re-amplified samples (A3) have been dosed through NanoDrop and other more accurate technology depending on the availability. Amplifcation 2 and Library Repeat Plates reorganization: Re-amplified samples (A3) have been redistributed in their original position within library plates, and plates and 6.2 reorganized in a unique plate 6.3 for pools building. Pool building: Pool building followed plate organization, with re-extracted samples (P6.2) pooled together due to high fragment size heterogeneity. Pool building must be equimolar and thus depended on DNA dosage. Because we won’t pipette less than 0.5 \\(\\mu L\\) of the most concentrated sample of one pool, depending on the concentration of the less concentrated sample, we needed to do dilution. Purification &amp; Concentration: AMPure beads have been used to clean pools. We also used this step to concentrate samples in a smaller volume for the reaction (targeted volume of reaction is 7 \\(\\mu L\\) with 100 to 500 \\(ng\\) of DNA). Size assessment: Pools fragments size have been assessed with TapeStation, in order to check for correct fragment size distribution, and, if needed, further clean library pools. Size selection: if size distribution result was not good enough, we further cleaned library pools through size selection with a Pippin. Info: we thus avoid failure of capture with too small fragments but we risk losing libraries. Capture: Finally we realized capture by hybridization following ArborScience protocol 3.4.1 Amplifcation 1 Plate reorganization First amplification plates (A1 and A2) have been redistributed within their original library plates, removing previous libraries. Figure 3.14: Original libraries to be kept (P1-P5). Figure 3.15: Original position of amplified samples. 3.4.2 DNA dosage 1 Samples concentration has been assessed by PicoGreen with ca 60 samples having a concentration below \\(1 ng.\\mu L^{-1}\\) among which 50 have not been reamplified (34 among original libraries, and the rest among repeated libraries or extractions). Those samples have been reamplified. Figure 3.16: Sampled dosage by PicoGreen (concentration in ng.uL). Figure 3.17: Samples to be re-amplified. 3.4.3 Amplification 2 Figure 3.18: Original position of amplified samples in A3. 3.4.4 DNA dosage 2 Figure 3.19: Reamplified samples dosed using PicoGreen (concentration in ng.uL). 3.4.5 Amplification 2 and Library Repeat Plates reorganization Figure 3.20: Original position of plates 6.1 and 6.2 reorganized plate 6.3. 3.4.6 Pool building Due to non-uniformity of fragment size, re-extracted samples from P6 (P6.2) have been pooled into a single separated pool for the capture reaction (in total, we do 16 capture reactions on pooled samples, therefore we still have to constitute the 15 remaining pools). All other samples have been pooled by batches of 32 using the plate order illustrated in FIgure 3.21. We wanted 100 to 500 ng of DNA per reaction, and the reaction with the lowest number of samples had 16 samples. Consequently we used 15 ng of each sample, resulting in 240 to 645 ng of DNA per pool (but we may lose material in purification, so we aimed for extra). Samples reaching to high concentration, for which we should sample less than 0.5 \\(\\mu L\\) have been diluted 2 to 4 times. Figure 3.21: Sample reaction tube per plate. Figure 3.22: Sample reaction volume per plate. 3.4.7 Purification &amp; Concentration Figure 3.23: DNA content of library pools assessed by NanoDrop. 3.4.8 Size assessment We had a heterogeneity of fragment size distribution among pools with a large spectrum (Fig. 3.24). We used a TapeStation to select fragments between 330 and 700 bp. Figure 3.24: Pools size assessment. 3.4.9 Size selection We did pools of pools for the size selection with Pippin (Fig. 3.25), resulting in \\(22*4=88 \\mu L\\) per pool. But the Pippin used 30 \\(\\mu L\\) and we wanted to do two reactions of Pippin per pool. So we reduced pool volume to 60 \\(\\mu L\\) per pool with the speed vac. Then we used Pippin with a repeat of the 4 pools with 30 \\(\\mu L\\) per pool. We used Pippin to filter fragments between 330 and 750 bp. After the Pippin, we cleaned the samples with 1.8X PGTB Beads from Batch J, and assessed their concentration with QuBIT and their fragment size distribution with TapeStation. We obtained between 180 and 280 ng of DNA (Table 3.4), with fragments distributed between 300 and 700 bp (Fig. 3.26). Figure 3.25: Pool of reactions. Table 3.4: Concentrations for pools of library pools. Pool Repetition Volume (\\(\\mu L\\)) Concentration (\\(ng. \\mu L^{-1}\\)) DNA (\\(ng\\)) DNA origin (\\(ng\\)) Loss factor 1 1 37 4.94 182.78 874.0 5 2 1 37 5.33 197.21 489.0 2 3 1 37 7.38 273.06 588.5 2 4 1 37 3.98 147.26 514.0 3 Figure 3.26: Size selected pools assessment. 3.4.10 Capture We split the 4 pools in 16 reactions (4 replicate capture reactions for each pool) and conducted the capture following ArborScience protocol. After amplification we obtained between 227 and 987 ng of DNA per pool assessed by Qubit (with the four replicates summed, Table 3.5). We then pooled back the capture reactions, assessed their concentration by qPCR and adjusted final samples for sequencing by an equimolar pooling Pools 1 and 2, and 3 and 4 together. We thus obtained 22 \\(\\mu L\\) of Lane 1 at \\(7.19~nM\\) and 19 \\(\\mu L\\) of Lane 2 at \\(10.18~nM\\) (see google sheets for more details). The material has been sent to the Genotoul Get team for sequencing on an Illumina HiSeq 3000 on two lanes of pair-ends 150 bp sequences. Table 3.5: Capture result (Qubit). Reaction Pool Concentration (\\(ng. \\mu L^{-1}\\)) DNA (\\(ng\\)) DNA pool (\\(ng\\)) 1 1 11.300 440.700 957.450 2 1 5.850 228.150 957.450 3 1 5.500 214.500 957.450 4 1 1.900 74.100 957.450 5 2 1.250 48.750 242.775 6 2 1.075 41.925 242.775 7 2 2.350 91.650 242.775 8 2 1.550 60.450 242.775 9 3 7.350 286.650 986.700 10 3 5.650 220.350 986.700 11 3 5.800 226.200 986.700 12 3 6.500 253.500 986.700 13 4 1.380 53.820 227.955 14 4 1.095 42.705 227.955 15 4 1.935 75.465 227.955 16 4 1.435 55.965 227.955 \\[ C~in~nM = \\frac{C~in~ng/\\mu L}{660 .average~fragment~size}.10^6\\] Dilution for qPCR (1 pM) Dilute in cascade your samples from 20.4 - 4.9 nM to almost 1 pM. So we need a 10 000 times dilution. We will do 4 1:10 dilutions with \\(1 \\mu L\\) of sample in \\(9 \\mu L\\) of \\(H_2O~milliQ\\). Change of tips for every step and better use pipette in the middle of their range than in their extreme (e.g. for \\(100 \\mu L\\) better use a \\(200 \\mu L\\) than a \\(100 \\mu L\\) pipette). References "],["snp-calling-and-filtering.html", "Chapter 4 SNP calling and filtering 4.1 Quality Check 4.2 Mapping 4.3 Variant call 4.4 Variant filtering", " Chapter 4 SNP calling and filtering We assessed the quality of raw reads using multiqc (Ewels et al. 2016) and trimmed them with trimmomatic (Bolger et al. 2014). We kept only pair-end reads without adaptors and a phred score above 15 in a sliding window of 4. Seventy percent of trimmed reads mapped off-targets using bwa (Li &amp; Durbin 2009). We thus mapped trimmed reads on the hybrid reference built for the sequence capture experiment using bwa (Li &amp; Durbin 2009), picard (Broad Institute 2018), samtools (Li et al. 2009) and bedtools (Quinlan &amp; Hall 2010). We called variants for each individual using HaplotypeCaller, aggregated variants using GenomicsDBImport and jointly-genotyped individuals using GenotypeGVCFs all in GATK4 software (Auwera et al. 2013). We filtered biallelic SNPs with a quality above 30, a quality by depth above 2, a Fisher strand bias below 60 and a strand odds ratio above 3 using GATK4 (Auwera et al. 2013). Finally, we filtered individuals and SNPs for missing data with a maximum of 95% and 15% of missing data per individual and SNP, respectively, using plink2 (Chen et al. 2019). We obtained 454,262 biallelic SNPs over 385 individuals without outgroups, that we used for population genetic analyses. Since low-frequency alleles and linkage disequilibrium will bias the number of fixed loci and increase the number of false-positives in genomic scans for outliers (Foll &amp; Gaggiotti 2008), we built a second dataset for quantitative genomics and genomic scans, filtering variants with a minor allele frequency above 5% (18 individuals) and with linkage disequilibrium \\(r^2&lt;0.99\\). We further removed admixed individuals (see population genetic analyses for criteria) and retained 70,737 biallelic SNPs over 372 individuals. 4.1 Quality Check We received demultiplexed libraries from sequencing. We checked sequences quality combining already produced fastqc and compared them with originally furnished (i) baits, (ii) targets, and (iii) references: Multi Quality Check: we used multiqc to combined fastqc inputs for every library (1002 for forward and reverse individuals) and check sequences, counts, quality and GC content Trimming: we trimmed sequences removing bad quality and adaptors sequences Targets mapping: we mapped 10 libraries on targets to check proportion of off-targets sequences Reference mapping: we mapped 10 libraries on hybrid reference to check proportion of off-reference sequences, and assess the need for de novo assembly of captured sequences (in case of a high proportion of off-reference sequences) 4.1.1 Multi Quality Check We used multiqc to combine fastqc inputs for every library (1002 for forward and reverse individuals) and checked sequences, counts, quality and GC content. cd ~/Documents/BIOGECO/PhD/data/Eschweilera_Paracou/Sequences/quality multiqc fastqc mkdir multiqc mv multiqc_data/ multiqc_report.html L1.fastqc.tar.gz L2.fastqc.tar.gz multiqc 4.1.1.1 Counts We had a big heterogeneity of sample representativity (215 000 fold), but 85% of samples had more than 66 6667 sequences (ca 1M targets / 150 bp * 10X). Moreover, duplicated sequences were obviously more present in over-represented individuals, probably more linked to PCR biases than ro sequencing issues. Figure 4.1: Sequence counts. 4.1.1.2 Quality Sequence quality was very good as the Phred score is above 25 for every base on all positions across all sequences. Figure 4.2: Phred score. 4.1.1.3 GC content The mean GC content was 41.5 and only a few sequences had non expected global GC content or GC content across the sequence. Figure 4.3: GC content across sequences. Figure 4.4: GC content within sequences. 4.1.2 Trimming We listed all libraries in text files and trimmed all libraries with trimmomatic in pair end (PE) into paired and unpaired compressed fastq files (fq.gz). We trimmed the adaptor (ILLUMINACLIP) of our protocol (TruSeq3-PE) with a seed mismatch of 2 (mismatched count allowed), a threshold for clipping palindrome of 30 (authorized match for ligated adapters), a threshold for simple clip of 10 (match between adapter and sequence), a minimum adaptor length of 2, and keeping both reads each time (keepBothReads). We trimmed sequences on phred score with a minimum of 15 in a sliding window of 4 (SLIDINGWINDOW:4:15) without trimming the beginning (LEADING:X) or the end (TRAILING:X). Without surprise due to the high quality check of sequencing, trimming resulted in 99.91% of paired trimmed reads compared to raw reads (4.5). Thus the main issue of our dataset was more the representativity of sequences more than their quality. data.frame(libraries = list.files(file.path(path, &quot;Sequences&quot;, &quot;raw&quot;))) %&gt;% mutate(libraries = gsub(&quot;_R[12].fastq.gz&quot;, &quot;&quot;, libraries)) %&gt;% unique() %&gt;% write_tsv(path = file.path(path, &quot;Sequences&quot;, &quot;libraries.txt&quot;), col_names = F) read_tsv(file.path(path, &quot;Sequences&quot;, &quot;libraries.txt&quot;), col_names = &quot;Library&quot;) %&gt;% sample_n(10) %&gt;% write_tsv(path = file.path(path, &quot;Sequences&quot;, &quot;libraries_mapping.txt&quot;), col_names = F) #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J trimming #SBATCH -o trimming_output.out #SBATCH -e trimming_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL module load bioinfo/Trimmomatic-0.36 for library in $(cat libraries.txt) do java -jar $TRIM_HOME/trimmomatic.jar PE \\ raw/&quot;$library&quot;_R1.fastq.gz raw/&quot;$library&quot;_R2.fastq.gz \\ trimmed/paired/&quot;$library&quot;_R1_paired.fq.gz trimmed/unpaired/&quot;$library&quot;_R1_unpaired.fq.gz \\ trimmed/paired/&quot;$library&quot;_R2_paired.fq.gz trimmed/unpaired/&quot;$library&quot;_R2_unpaired.fq.gz \\ ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads \\ SLIDINGWINDOW:4:15 done cat trimmed/paired_stat.txt for file in $(ls trimmed/paired) do zcat trimmed/paired/$file | echo $file&quot; &quot;$((`wc -l`/4)) &gt;&gt; trimmed/paired_stat.txt done cat trimmed/unpaired_stat.txt for file in $(ls trimmed/unpaired) do zcat trimmed/unpaired/$file | echo $file&quot; &quot;$((`wc -l`/4)) &gt;&gt; trimmed/unpaired_stat.txt done Figure 4.5: Trimming results. 4.1.3 Targets mapping We mapped every library on the hybrid reference to check off-reference sequences, and assess the need for de novo assembly, in case many sequences would not map on the reference. Globally we had a low coverage of the reference (median of 19%, Fig. 4.6) but reads were 79% to 88% on-reference (Fig. 4.1) ! Finally, we had a median of 4Mb covered with 10X on reference, which is 4 times what we designed in probes. Consequently, we won’t need de novo assembly and will proceed to read mapping for every library on the built reference, already partly annotated. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J targetsMapping #SBATCH -o targetsMapping_output.out #SBATCH -e targetsMapping_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 targets=../Baits/files-Symphonia/target-sequences.fas bwa index $targets for library in $(cat libraries_mapping.txt) do rg=&quot;@RG\\tID:${library}\\tSM:${library}\\tPL:HiSeq4K&quot; bwa mem -M -R &quot;${rg}&quot; -t 16 $targets trimmed/paired/&quot;$library&quot;_R1_paired.fq.gz trimmed/paired/&quot;$library&quot;_R2_paired.fq.gz &gt; targetsMapping/sam/&quot;${library}.sam&quot; java -Xmx4g -jar $PICARD SortSam I=targetsMapping/sam/&quot;${library}.sam&quot; O=targetsMapping/bam/&quot;${library}&quot;.bam SORT_ORDER=coordinate java -Xmx4g -jar $PICARD BuildBamIndex I=targetsMapping/bam/&quot;${library}&quot;.bam O=targetsMapping/bam/&quot;${filename}&quot;.bai samtools index targetsMapping/bam/&quot;${library}&quot;.bam bedtools bamtobed -i =targetsMapping/bam/&quot;${library}&quot;.bam &gt; targetsMapping/bed/&quot;${library}&quot;.bed bedtools merge -i targetsMapping/bed/&quot;${library}&quot;.bed &gt; targetsMapping/merged_bed/&quot;${library}&quot;.bed done touch readsMappingStat.txt for file in $(ls bam/*.bam) do samtools flagstat $file | echo $file&quot; &quot;$(grep &quot;mapped (&quot;) &gt;&gt; readsMappingStat.txt done Figure 4.6: Reads alignment coverage on targets. Distribution has been cut at 2000X. Table 4.1: Reads mapped on targets statistics. Library Reads mapped Percentage of reads mapped P7-3-2806 358925 28.22 BCI-SG14 950 27.15 BCI-SG47 16677 27.18 P11-2-240 1064 19.25 P14-2-2842 607526 23.85 P2-2-675 499249 28.01 P4-2-2657 784026 26.77 P5-3-2202 722215 30.28 P6-3-2800 474588 20.19 P6-4-2867 1210288 19.31 P7-3-2806 358925 28.22 4.1.4 Reference mapping We mapped every library on hybrid reference to check off-reference sequences, and assess de novo usefulness. Globally we had a low coverage of the reference (median of 19%, 4.7) but reads were 79% to 88% on-reference (4.2) ! Finally, we had a median of 4Mb covered with 10X on reference, which is 4 times what we designed in probes. Consequently, we won’t need de novo assembly and will proceed to read mapping for every library on the built reference, already partly annotated. #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J referenceMapping #SBATCH -o treferenceMapping_output.out #SBATCH -e referenceMapping_error.out #SBATCH --mem=20G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 cat ../../Symphonia_Genomic/neutral_selection/merged.fasta &gt; referenceMapping/reference.fasta reference=referenceMapping/reference.fasta bwa index $reference for library in $(cat libraries_mapping.txt) do rg=&quot;@RG\\tID:${library}\\tSM:${library}\\tPL:HiSeq4K&quot; bwa mem -M -R &quot;${rg}&quot; -t 16 $reference trimmed/paired/&quot;$library&quot;_R1_paired.fq.gz trimmed/paired/&quot;$library&quot;_R2_paired.fq.gz &gt; referenceMapping/sam/&quot;${library}.sam&quot; java -Xmx4g -jar $PICARD SortSam I=referenceMapping/sam/&quot;${library}.sam&quot; O=referenceMapping/bam/&quot;${library}&quot;.bam SORT_ORDER=coordinate java -Xmx4g -jar $PICARD BuildBamIndex I=referenceMapping/bam/&quot;${library}&quot;.bam O=referenceMapping/bam/&quot;${filename}&quot;.bai samtools index targetsMapping/bam/&quot;${library}&quot;.bam bedtools bamtobed -i =referenceMapping/bam/&quot;${library}&quot;.bam &gt; referenceMapping/bed/&quot;${library}&quot;.bed bedtools merge -i referenceMapping/bed/&quot;${library}&quot;.bed &gt; referenceMapping/merged_bed/&quot;${library}&quot;.bed done touch readsMappingStat.txt for file in $(ls bam/*.bam) do samtools flagstat $file | echo $file&quot; &quot;$(grep &quot;mapped (&quot;) &gt;&gt; readsMappingStat.txt done Figure 4.7: Reads alignment coverage on reference. Distribution has been cut at 2000X. Table 4.2: Reads mapped on reference statistics. Library Reads mapped Percentage of reads mapped BCI-SG14 3232 85.28 BCI-SG47 57142 85.57 P11-2-240 4669 78.74 P14-2-2842 2384919 85.85 P2-2-675 1684774 86.47 P4-2-2657 2717886 85.82 P5-3-2202 2276779 87.75 P6-3-2800 2161522 84.74 P6-4-2867 5707686 83.93 P7-3-2806 1153783 83.91 4.2 Mapping We proceeded to read mapping for every library on the built reference, already partly annotated: Repeats merging: 41 libraries were repeated, we merged their fastq files before mapping to increase their information before variant calling Reads mapping: we mapped every library in pair end with bwa mem on the hybrid reference from Ivan Scotti and Sanna Olsson used to build the targets Reference sequences: we built bedtools for every alignment in order to list sequences with matches in the reference to be used to reduce the explored reference area in variant calling 4.2.1 Repeats merging 41 libraries were repeated, we merged their FASTQ to increase their information before variant calling. Merging repeats confirmed the presence of all 430 individuals at the end of the alignment (402 from Paracou, 20 from herbariums, and 8 from BCI, Itubera and La Selva). #!/bin/bash #SBATCH --time=36:00:00 #SBATCH -J compression #SBATCH -o compression_output.out #SBATCH -e compression_error.out #SBATCH --mem=4G #SBATCH --cpus-per-task=1 #SBATCH --mail-type=BEGIN,END,FAIL folder=trimmed.paired.joined/ name=symcapture.trimmed.paired.joined module purge mkdir trimmed.paired for file in $(ls paired/*) do mv $file trimmed.paired/$(basename $(echo $file | sed -e &#39;s/_[[:alpha:]]*-[[:alpha:]]*-[[:alnum:]]*//&#39;)) done rm -r paired cp ../libraries.txt ./ cat libraries.txt | sed -e &#39;s/_[[:alpha:]]*-[[:alpha:]]*-[[:alnum:]]*_L00[56]//&#39; | sort | uniq | sed -e &#39;s/-b//&#39; | sort | uniq &gt; libraries.uniq.txt mkdir trimmed.paired.joined for ind in $(cat libraries.uniq.txt) do echo $ind cat trimmed.paired/$ind*_R1_paired.fq.gz &gt; trimmed.paired.joined/&quot;$ind&quot;_R1_paired.fq.gz cat trimmed.paired/$ind*_R2_paired.fq.gz &gt; trimmed.paired.joined/&quot;$ind&quot;_R2_paired.fq.gz done rm -r trimmed.paired tar -zcvf $name.tar.gz $folder 4.2.2 Reads mapping We mapped every library in pair end with bwa mem on the hybrid reference from Ivan Scotti and Sanna Olsson used to build the targets (32 alignments with 2 processes on 64 cores of 1 node of the genologin computer cluster at Genotoul, Toulouse). We had globally a good mapping with more than 80% of the reads mapped for 98% of the libraries (Figure 4.8). #!/bin/bash #SBATCH --time=48:00:00 #SBATCH -J mapping #SBATCH -o mapping_output.out #SBATCH -e mapping_error.out #SBATCH --mem=160G #SBATCH --cpus-per-task=64 #SBATCH --mail-type=BEGIN,END,FAIL module purge module load bioinfo/bwa-0.7.15 module load bioinfo/picard-2.14.1 module load bioinfo/samtools-1.4 module load bioinfo/bedtools-2.26.0 task(){ echo MAPPING &quot;$1&quot; bwa mem -M -R &quot;@RG\\tID:$1\\tSM:$1\\tPL:HiSeq4K&quot; \\ -t 2 \\ reference/reference.fasta \\ trimming/trimmed.paired.joined/&quot;$1&quot;_R1_paired.fq.gz \\ trimming/trimmed.paired.joined/&quot;$1&quot;_R2_paired.fq.gz \\ &gt; mapping/sam/&quot;$1&quot;.sam rm trimming/trimmed.paired.joined/&quot;$1&quot;_R1_paired.fq.gz rm trimming/trimmed.paired.joined/&quot;$1&quot;_R2_paired.fq.gz java -Xmx4g -jar $PICARD SortSam \\ I=mapping/sam/&quot;$1&quot;.sam \\ O=mapping/bam2/&quot;$1&quot;.bam SORT_ORDER=coordinate rm mapping/sam/&quot;$1&quot;.sam samtools index mapping/bam2/&quot;$1&quot;.bam } mkdir mapping/sam mkdir mapping/bam2 N=32 ( for library in $(cat unmapped.txt) do ((i=i%N)); ((i++==0)) &amp;&amp; wait task &quot;$library&quot; &amp; done ) rm -r mapping/sam # folders mkdir mappingStat touch readsMappingStat.txt # test file=$(ls bam*/*.bam | head -n 1) module load bioinfo/samtools-1.4 ; samtools flagstat $file | echo $file&quot; &quot;$(grep &quot;mapped (&quot;) &gt;&gt; readsMappingStat.txt cat readsMappingStat.txt rm readsMappingStat.txt touch readsMappingStat.txt # sarray for file in $(ls bam*/*.bam); do echo &#39;module load bioinfo/samtools-1.4 ; samtools flagstat &#39;$file&#39; | echo &#39;$file&#39;&quot; &quot;$(grep &quot;mapped (&quot;) &gt;&gt; readsMappingStat.txt&#39;; done &gt; mappingStat.sh sarray -J mappingStat -o mappingStat/%j.out -e mappingStat/%j.err -t 1:00:00 --mail-type=BEGIN,END,FAIL mappingStat.sh # clean rm -r mappingStat Figure 4.8: Mapping result 4.2.3 Reference sequences We built bedtools for every alignment in order to list sequences with matches in the reference to be used to reduce the explored reference areas in variant calling. 99.98% of reference sequences had at least one library matching (Fig. 4.9). Consequently we used all sequences from the reference in the variant calling. Some reference sections were underrepresented in our libraries but they have been removed at the SNP filtering stage.. # folders mkdir bed mkdir bed.out # test file=$(ls bam*/*.bam | head -n 1) module load bioinfo/bedtools-2.26.0 ; bedtools bamtobed -i $file &gt; bed/$(basename &quot;${file%.*}&quot;).bed rm bed/* # sarray for file in $(ls bam*/*.bam); do echo &#39;module load bioinfo/bedtools-2.26.0 ; file=&#39;$file&#39; ; bedtools bamtobed -i $file &gt; bed/$(basename &quot;${file%.*}&quot;).bed&#39;; done &gt; bed.sh sarray -J bed -o bed.out/%j.out -e bed.out/%j.err -t 1:00:00 --mail-type=BEGIN,END,FAIL bed.sh # clean rm -r bed.out # statistics mkdir bed.out touch referenceMappedStats.txt for file in $(ls bed/*.bed); do echo &quot;cut $file -f1 | sort | uniq | awk -v file=&quot;$(basename &quot;${file%.*}&quot;)&quot; &#39;{print \\$1, file}&#39; &gt;&gt; referenceMappedStats.txt&quot; ; done &gt; bed.sh sarray -J bed -o bed.out/%j.out -e bed.out/%j.err -t 1:00:00 --mail-type=BEGIN,END,FAIL bed.sh rm -r bed.out Figure 4.9: Sequences from reference alignment with reads from all libraries. 4.3 Variant call We used GATK as it has apparently similar performance to other variant callers (Supernat et al. 2018) and was more known by Myriam. For that we used the following pipeline: Variant calling Run the HaplotypeCaller on each sample’s BAM files to create single-sample gVCFs using the .g.vcf extension for the output file. Data aggregation Aggregate the GVCF files and feed in one GVCF with GenomicsDBImport to be genotyped Joint genotyping Run GenotypeGVCFs on all of them together to create the raw SNP and indel VCFs that are usually emitted by the callers. 4.3.1 Variant calling Run the HaplotypeCaller on each sample’s BAM files to create single-sample gVCFs using the .g.vcf extension for the output file. We used sarray which is much more powerful than sbatch in parallel computing. # folders mkdir variantCalling/gvcf5 # test file=$(ls mapping/bam5/*.bam | head -n 1) srun --mem=20G --pty bash module load bioinfo/gatk-4.1.2.0 ; gatk --java-options &quot;-Xmx20G&quot; HaplotypeCaller -R reference/reference.fasta -I $file -O variantCalling/gvcf4/$(basename &quot;${file%.*}&quot;).g.vcf.gz -ERC GVCF exit rm variantCalling/gvcf4/* # sarray for file in $(ls mapping/bam5/*.bam); do echo &quot;module load bioinfo/gatk-4.1.2.0 ; gatk --java-options \\&quot;-Xmx20G\\&quot; HaplotypeCaller -R reference/reference.fasta -I $file -O variantCalling/gvcf5/$(basename &quot;${file%.*}&quot;).g.vcf.gz -ERC GVCF&quot;; done &gt; haplo5.sh mkdir haplo5 sarray -J haplo5 -o haplo5/%j.out -e haplo5/%j.err -t 48:00:00 --mem=20G --mail-type=BEGIN,END,FAIL haplo5.sh # clean rm -r haplo5 rm -r tmp 4.3.2 Data aggregation We aggregated the GVCF files and fed them into one GVCF database with GenomicsDBImport to be genotyped. Beware, GATK 4.0.0.0 does not deal with multiple intervals when using GenomicsDBImport, so we used GATK 4.1.2.0. We divided the step into several interval files of a maximum of 1000 sequences computed in parallel to speed up the operation. NB, we tested the pipeline with 3 individual haplotypes and 10 intervals of 100 sequences run in parallel; and it took 24 minutes. Consequently with 10 fold more sequences per interval we may increase to 4H, and the effect of 10 fold more individual haplotypes is hard to assess. Due to a memory overload on the cluster I boosted the sarray to 24G per node beside limiting gatk java session to 20G, still the overload is strange as if gatk was opening a parallel session of 20G java. We should not decrease batch size as a batch of 50 individuals means that we will use 9 batches ! If memory issues persist we may decrease the interval length (currently 1000 sequences) and increase the number of jobs in sarray. We may even decrease intervals to 100 sequences resulting in more than 800 jobs and run them by batch of 100 if they are really more efficient. Running a first batch of 10 samples on 100 sequences took 35 minutes. Thus 432 samples should take ca 1 day and 40 minutes. This is the first run of DB among 8, so in total DB build should take 8 days ! But on the other hand joint genotyping might be launched on each run as soon as they finish. So we might clean the first vcf and obtain a preview of population genetics structure with the first 100 sequences. # Sample map touch sample_map.txt for file in $(ls gvcf*/*.g.vcf.gz) do echo -e $(basename &quot;${file%.*}&quot;)&quot;\\t&quot;$file &gt;&gt; sample_map.txt done # seq lists mkdir reference.sequences.lists cut ../reference/reference.fasta.fai -f1 &gt; reference.sequences.lists/reference.sequences.list cd reference.sequences.lists split -l 100 -d reference.sequences.list reference.sequences_ --additional-suffix=.list rm reference.sequences.list ls | wc -l cd .. # folders mkdir tmp mkdir symcaptureDB # test srun --mem=24G --pty bash file=$(ls reference.sequences.lists/ | head -n 1) module load bioinfo/gatk-4.1.2.0 ; gatk --java-options &quot;-Xmx20g -Xms20g&quot; GenomicsDBImport --genomicsdb-workspace-path symcaptureDB/&quot;${file%.*}&quot;.DB -L reference.sequences.lists/$file --sample-name-map sample_map.txt --batch-size 50 --tmp-dir=tmp exit rm -r symcaptureDB/* rm tmp/* # sarray for file in $(ls reference.sequences.lists/); do echo &quot;module load bioinfo/gatk-4.1.2.0 ; gatk --java-options \\&quot;-Xmx20g -Xms20g\\&quot; GenomicsDBImport --genomicsdb-workspace-path symcaptureDB/\\&quot;${file%.*}\\&quot;.DB -L reference.sequences.lists/$file --sample-name-map sample_map.txt --batch-size 10 --consolidate&quot;; done &gt; combine.sh split -l 207 -d combine.sh combine_ --additional-suffix=.sh rm combine.sh mkdir combine sarray -J combine -o combine/%j.out -e combine/%j.err -t 48:00:00 --mem=40G --mail-type=BEGIN,END,FAIL combine.sh rm combine_00.sh rm -r combine rm -r tmp # clean rm -r combine rm -r tmp 4.3.3 Joint genotyping We joint-genotyped individuals with GenotypeGVCFs on all of them together to create the raw SNP and indel VCFs that are usually emitted by the callers. We divided the step into several intervals with a maximum of 1000 sequences computed in parallel to speed up the operation (similarly to the previous step). NB, we tested the pipeline with 3 individual haplotypes and 10 intervals of 100 sequences run in parallel; and it took 6 minutes. Consequently with 10 fold more sequences per interval we may increase to 1H, and the effect of 10 fold more individual haplotypes is hard to assess. Then we merged genotypes of all intervals with GatherVcfs from Picard in one raw VCF to be filtered. # folders mkdir tmp mkdir symcapture.vcf.gz # test file=$(ls reference.sequences.lists/ | head -n 1) srun --mem=20G --pty bash module load bioinfo/gatk-4.1.2.0 ; gatk --java-options &quot;-Xmx20g&quot; GenotypeGVCFs -R ../reference/reference.fasta -L reference.sequences.lists/$file -V gendb://symcaptureDB/$file -O symcapture.vcf.gz/&quot;${file%.*}&quot;.vcf.gz exit rm tmp/* rm symcapture.vcf.gz/* # sarray for file in $(ls reference.sequences.lists); do echo &quot;module load bioinfo/gatk-4.1.2.0 ; gatk --java-options \\&quot;-Xmx20g\\&quot; GenotypeGVCFs -R ../reference/reference.fasta -L reference.sequences.lists/$file -V gendb://symcaptureDB/${file%.*}.DB -O symcapture.vcf.gz/${file%.*}.vcf.gz&quot;; done &gt; genotype.sh mkdir genotype sarray -J genotype -o genotype.array/%j.out -e genotype.array/%j.err -t 48:00:00 --mem=20G --mail-type=BEGIN,END,FAIL genotype.array.sh # clean rm -r genotype.array rm -r tmp # merge echo -e &#39;#!/bin/bash\\n#SBATCH --time=48:00:00\\n#SBATCH -J gather\\n#SBATCH -o gather.out\\n#SBATCH -e gather.err\\n#SBATCH --mem=20G\\n#SBATCH --cpus-per-task=1\\n#SBATCH --mail-type=BEGIN,END,FAIL\\nmodule load bioinfo/picard-2.14.1\\njava -Xmx20g -jar $PICARD GatherVcfs \\&#39; &gt; gather.sh for file in $(ls symcapture.vcf.gz/*.gz) do echo -e &#39;\\tI=&#39;$file&#39; \\&#39; &gt;&gt; gather.sh done echo -e &#39;\\tO=symcapture.all.raw.vcf.gz\\n&#39; &gt;&gt; gather.sh 4.4 Variant filtering We filtered the previously produced raw vcf with several steps: Gather raw vcf files which resulted in 26 813 513 variants over 432 individuals Biallelic raw vcf filtering which resulted in 19 242 294 variants over 432 individuals SNP biallelic vcf filtering which resulted in 17 521 879 variants over 432 individuals Filters biallelic snps which resulted in 15 531 866 variants over 432 individuals Missing filtered biallelic snp vcf filtering which resulted in 454 262 variants over 406 individuals Paracou filtered &amp; non missing biallelic snp vcf filtering which resulted in 454 262 variants over 385 individuals 4.4.1 Gather We first gathered all raw vcf files. Individuals genotyping lost 42 reference scaffolds (over 878, 4%) in few batches of individuals, which blocked the functioning of gatk CombineVariants. We thus removed the variants associated with these 42 reference scaffolds. We obtained 26 813 513 variants. mkdir out mkdir missing_ind for file in $(ls symcapture.filtered.vcf/*.vcf.gz) ; do file=$(basename $file) ; file=${file%.*} ; echo &quot;module load bioinfo/tabix-0.2.5 ; module load bioinfo/vcftools-0.1.15 ; vcftools --gzvcf symcapture.filtered.vcf/$file.gz --missing-indv -c &gt; missing_ind/$file.missing.txt&quot;; done &gt; missingInd.sh sarray -J missingInd -o out/%j.missingInd.out -e out/%j.missingInd.err -t 1:00:00 --mail-type=BEGIN,END,FAIL missingInd.sh for file in $(ls missing_ind/*.missing.txt) ; do awk &#39;{{if (NR!=1) print FILENAME&quot;\\t&quot;$0}}&#39; $file ; done &gt; missingInd.txt rm - r out rm -r missing_ind echo -e &#39;#!/bin/bash\\n#SBATCH --time=48:00:00\\n#SBATCH -J gather\\n#SBATCH -o gather.out\\n#SBATCH -e gather.err\\n#SBATCH --mem=20G\\n#SBATCH --cpus-per-task=1\\n#SBATCH --mail-type=BEGIN,END,FAIL\\nmodule load bioinfo/picard-2.14.1\\njava -Xmx20g -jar $PICARD GatherVcfs \\&#39; &gt; gather.sh for file in $(cat nonmissing.list) do echo -e &#39;\\tI=symcapture.raw.vcf/&#39;$(basename $file)&#39; \\&#39; &gt;&gt; gather.sh done echo -e &#39;\\tO=symcapture.all.raw.vcf.gz\\n&#39; &gt;&gt; gather.sh zcat symcapture.all.raw.vcf.gz | grep &quot;#contig&quot; | wc -l 4.4.2 Biallelic We then used bcftools to limit data to biallelic variants (--max-alleles 2), resulting in 19 242 294 biallelic variants. srun --mem=80G --cpus-per-task=8 --pty bash module load bioinfo/bcftools-1.8 bcftools view --max-alleles 2 --threads 8 symcapture.all.raw.vcf.gz | bgzip -c --threads 8 &gt; symcapture.all.biallelic.vcf.gz bcftools stats --threads 8 symcapture.all.biallelic.vcf.gz 4.4.3 SNP We then used gatk to limit data to biallelic snps, resulting in 17 521 879 biallelic snps. module load bioinfo/gatk-4.1.2.0 gatk IndexFeatureFile \\ -F symcapture.all.biallelic.vcf.gz gatk SelectVariants \\ -V symcapture.all.biallelic.vcf.gz \\ -select-type SNP \\ -O symcapture.all.biallelic.snp.vcf.gz gatk IndexFeatureFile \\ -F symcapture.all.biallelic.snp.vcf.gz module load bioinfo/bcftools-1.8 bcftools stats --threads 8 symcapture.all.biallelic.snp.vcf.gz 4.4.4 Filters We filtered the biallelic snp vcf with following filters (name, filter, description), resulting in 15 531 866 filtered biallelic snps, using next histograms to set and test parameters values : Quality (QUAL) QUAL &lt; 30: represents the likelihood of the site to be homozygous across all samples, we filter out variants having a low quality score (4.10) Quality depth (QD) QD &lt; 2: filter out variants with low variant confidence (4.10) Fisher strand bias (FS) FS &gt; 60: filter out variants based on Phred-scaled p-value using Fisher’s exact test to detect strand bias (4.10) Strand odd ratio (SOR) SOR &lt; 3: filter out variants based on Phred-scaled p-value used to detect strand bias (4.10) vcftools --gzvcf reference.sequences_00.vcf.gz --missing-indv -c vcftools --gzvcf reference.sequences_00.vcf.gz --missing-site -c &gt; missing.txt vcftools --gzvcf reference.sequences_00.vcf.gz --site-quality -c &gt; QUAL.txt vcftools --gzvcf reference.sequences_00.vcf.gz \\ --get-INFO AC \\ --get-INFO AF \\ --get-INFO QD \\ --get-INFO FS \\ --get-INFO SOR \\ -c &gt; INFO.txt Figure 4.10: Quality, quality by depth, Fisher strand and strand odds ratios for biallelic SNPs. module load bioinfo/gatk-4.1.2.0 gatk VariantFiltration \\ -V symcapture.all.biallelic.snp.vcf.gz \\ --filter-expression &quot;QUAL &lt; 30.0 || QD &lt; 2.0 || FS &gt; 60.0 || SOR &gt; 3.0&quot; \\ --filter-name &quot;FAIL&quot; \\ -O symcapture.all.biallelic.snp.intermediate.vcf.gz gatk SelectVariants \\ -V symcapture.all.biallelic.snp.intermediate.vcf.gz \\ --exclude-filtered \\ -O symcapture.all.biallelic.snp.filtered.vcf.gz module load bioinfo/bcftools-1.8 bcftools stats --threads 8 symcapture.all.biallelic.snp.filtered.vcf.gz gatk IndexFeatureFile \\ -F symcapture.all.biallelic.snp.filtered.vcf.gz 4.4.5 Missing data Missing data filtering is a bit more tricky because missing data of SNPs and individuals are related, e.g. removing individuals with a lot of missing data results in the decrease of SNPs. Ideally, we wanted to keep all individuals, but this would result in a lot of SNP loss because of least represented individuals. So we needed to choose a threshold for missing data for individuals --mind and SNPs --geno. module load bioinfo/plink_high_contig_20190905 module load bioinfo/plink2_high_contig_20190905 mkdir filtered plink2 --threads 8 --memory 80000 \\ --vcf symcapture.all.biallelic.snp.filtered.vcf.gz \\ --allow-extra-chr \\ --make-bed --out filtered/symcapture.all.biallelic.snp.filtered cd filtered plink --threads 8 --memory 80000 \\ --bfile symcapture.all.biallelic.snp.filtered \\ --allow-extra-chr --missing --het --freq --pca --freqx \\ --out symcapture.all.biallelic.snp.filtered Figure 4.11: Missing data statistics for filtered biallelic SNPs before missing data filtering per individual. Figure 4.12: Missing data statistics for filtered biallelic SNPs before missing data filtering per SNP. 4.4.6 Normal filter With a maximum of 95% of missing data per individual --mind 0.95 and a maximum of 15% of missing data per SNP -geno 0.15, we obtained 454 262 biallelic filtered snps for 406 individuals. module load bioinfo/plink_high_contig_20190905 module load bioinfo/plink2_high_contig_20190905 mkdir nonmissing plink2 --threads 8 --memory 80000 \\ --bfile filtered/symcapture.all.biallelic.snp.filtered \\ --allow-extra-chr \\ --mind 0.95 --geno 0.15 \\ --make-bed --out nonmissing/symcapture.all.biallelic.snp.filtered.nonmissing cd nonmissing plink --threads 8 --memory 80000 \\ --bfile symcapture.all.biallelic.snp.filtered.nonmissing \\ --allow-extra-chr --missing --het --freqx --pca \\ --out symcapture.all.biallelic.snp.filtered.nonmissing Figure 4.13: Missing data statistics for filtered biallelic SNPs after missing data filtering (95% for individuals and 15% for SNPs) per individual. Figure 4.14: Missing data statistics for filtered biallelic SNPs after missing data filtering (95% for individuals and 15% for SNPs) per SNP. Figure 4.15: Heterozygosity statistics for filtered biallelic SNPs after missing data filtering (95% for individuals and 15% for SNPs) per SNP. 4.4.7 Paracou Finally, we subseted the filtered and biallelic SNPs to individuals from Paracou only, resulting in 385 remaining individuals (17 lost !). module load bioinfo/plink2-v2.0_alpha2 mkdir paracou plink2 \\ --bfile nonmissing/symcapture.all.biallelic.snp.filtered.nonmissing \\ --allow-extra-chr \\ --keep Paracou.fam \\ --make-bed --out paracou/symcapture.all.biallelic.snp.filtered.nonmissing.paracou # --recode vcf-iid References "],["genetic-species-delimitation.html", "Chapter 5 Genetic species delimitation 5.1 Populations structure 5.2 Kinship 5.3 Spatial auto-correlation 5.4 Introgression", " Chapter 5 Genetic species delimitation We investigated population genetic structure using admixture (Alexander &amp; Lange 2011), using 10 repetitions of K genetic groups varying from 1 to 10 and assessed the number of gene pools with cross validation. We defined individuals with a membership to gene pools below 90% as admixed and the remaining individuals as genetically pure. We further investigated admixture with the introgress R package (Gompert &amp; Alex Buerkle 2010), using genetically pure individuals as parental populations and all individuals as the hybrid population. We validated gene pool delimitation by comparison with botanical identifications using a confusion matrix, and we conducted a second blind-identification of every collected individual in November 2019. 5.1 Populations structure Symphonia individuals were structured in three gene pools in Paracou corresponding to field morphotypes (Fig. 5.1 and Fig. 5.2). The three genotypes correspond to the previously identified two morphotypes (70-80%) S. globulifera and S. sp1, with S. globulifera morphotype structured in two gene pools, which might match the two identified sub-morphotype in Paracou called S. globulifera type Paracou (80%) and S. globulifera type Régina (20%). Interestingly, we noticed the so-called Paracou type and Régina type within S. globulifera morphotype when sampling the individuals. And looking at a few identified individuals’ bark, the two identified gene pools correspond two these two morphotypes (Fig. 5.5). The Paracou type has a smoother and thinner bark compared to the thick and lashed bark of the Régina type. module load bioinfo/admixture_linux-1.3.0 module load bioinfo/plink-v1.90b5.3 mkdir admixture mkdir admixture/paracou mkdir out cd ../variantCalling mkdir paracouRenamed # read_tsv(file.path(pathCluster, &quot;paracou&quot;, &quot;symcapture.all.biallelic.snp.filtered.nonmissing.paracou.bim&quot;), # col_names = F) %&gt;% # mutate(X1 = as.numeric(as.factor(X1))) %&gt;% # write_tsv(file.path(pathCluster, &quot;paracouRenamed&quot;, &quot;symcapture.all.biallelic.snp.filtered.nonmissing.paracou.bim&quot;), # col_names = F) cp paracou/symcapture.all.biallelic.snp.filtered.nonmissing.paracou.bed paracouRenamed cp paracou/symcapture.all.biallelic.snp.filtered.nonmissing.paracou.fam paracouRenamed cd ../populationGenomics/admixture/paracou for k in $(seq 10) ; do echo &quot;module load bioinfo/admixture_linux-1.3.0 ; admixture --cv ../../variantCalling/paracouRenamed/symcapture.all.biallelic.snp.filtered.nonmissing.paracou.bed $k | tee log$k.out&quot; ; done &gt; admixture.sh sarray -J admixture -o ../../out/%j.admixture.out -e ../../out/%j.admixture.err -t 48:00:00 --mem=8G --mail-type=BEGIN,END,FAIL admixture.sh scp sschmitt@genologin.toulouse.inra.fr:~/Symcapture/populationGenomics/admixture/paracou/* grep -h CV log*.out &gt; CV.out for file in $(ls log*.out) ; do grep &quot;Fst divergences between estimated populations:&quot; -A 20 $file | head -n -2 &gt; matrices/$file ; done Figure 5.1: Cross-validation for the clustering of Paracou individuals. Y axis indicates cross-validation mean error, suggesting that 2 or 3 groups best represent the genetic structure of individuals in Paracou. Figure 5.2: Population structure of Paracou individuals for K=2 and K=3. Dark blue is associated with S. globulifera morphotype; whereas light blue is associated with S. sp1; and red is associated with a subgroup within the S. globulifera morphotype. Figure 5.3: Population structure of Paracou individuals for K = 2. Dark blue is associated with the S. globulifera morphotype; whereas light blue is associated with S. sp1 Figure 5.4: Clusters Fst relations for K=10. Figure 5.5: The Symphonia globulifera morphotypes identified in the field. The three morphotypes are identified with their bark with S. sp1 having a light grey thin and smooth bark, the S. globulifera type Paracou having a dark and intermediate thin and smooth bark compared to the thick and lashed bark of S. globulifera type Regina. 5.2 Kinship We calculated kinship matrix for every individual to be used in a genomic scan to control for population structure. 19 individuals, belonging to all gene pools, had only negative kinship values. After investigation it seems that these individuals are individuals without family in Paracou with null kinship with other individuals of their gene pools and negative values with other individuals of other gene pools. Interestingly though, individuals with only null or negative kinship were all located on the limit of Paracou plots. module load bioinfo/plink-v1.90b5.3 plink \\ --bfile symcapture.all.biallelic.snp.filtered.nonmissing.paracou \\ --allow-extra-chr \\ --recode vcf-iid \\ --out symcapture.all.biallelic.snp.filtered.nonmissing.paracou vcftools --gzvcf symcapture.all.biallelic.snp.filtered.nonmissing.paracou.vcf.gz --relatedness2 # an estimated kinship coefficient range &gt;0.354, [0.177, 0.354], [0.0884, 0.177] and [0.0442, 0.0884] corresponds to duplicate/MZ twin, 1st-degree, 2nd-degree, and 3rd-degree relationships respectively Figure 5.6: Individuals kinship matrix. Figure 5.7: Individuals kinship matrix. 5.3 Spatial auto-correlation plink=~/Tools/plink_linux_x86_64_20190617/plink $plink \\ --bfile ../paracou/symcapture.all.biallelic.snp.filtered.nonmissing.paracou \\ --allow-extra-chr \\ --keep sp1.fam \\ --recode vcf-iid \\ --thin-count 1000 \\ --out sp1.1k snps &lt;- vroom::vroom(file.path(path, &quot;..&quot;, &quot;variantCalling&quot;, &quot;spagedi&quot;, &quot;globuliferaTypeRegina.1k.genepop&quot;), skip = 1002, col_names = c(&quot;Lib&quot;, &quot;Lat&quot;, &quot;Long&quot;, paste0(&quot;SNP&quot;, 1:1000))) XY &lt;- mutate(snps, Ind = gsub(&quot;.g.vcf&quot;, &quot;&quot;, Lib)) %&gt;% dplyr::select(Ind) %&gt;% left_join(dplyr::select(trees, Ind, Xutm, Yutm)) snps$Lat &lt;- XY$Xutm snps$Long &lt;- XY$Yutm write_tsv(snps, path = file.path(path, &quot;..&quot;, &quot;variantCalling&quot;, &quot;spagedi&quot;, &quot;globuliferaTypeRegina.1k.spagedi.in&quot;), col_names = T) // #ind #cat #coord #loci #dig/loc #ploidy// this an example (lines beginning by // are comment lines) 231 0 2 1000 3 2 8 25 50 100 200 400 800 1600 3200 spagedi sp1.1k.spagedi.in sp1.1k.spagedi.out e return 13 3 return 1000 34 3 Locus intra-individual (inbreeding coef) 1 2 3 4 5 6 7 average 0-2704.88 b-lin(slope linear dist) b-log(slope log dist) ALL LOCI -0.0480 0.0079 0.0049 0.0046 0.0036 0.0035 0.0023 -0.0001 0.0001 -1.34448E-06 -0.00128963 F F1 F2 b-log Sp = –b-log / (1 − F1) ## [1] &quot;S. sp.1 Sp = 0.000458510425020048&quot; ## [1] &quot;S. sp.2 Sp = 0.00110720539398209&quot; ## [1] &quot;S. sp.3 Sp = 0.000132259359630633&quot; 5.4 Introgression We used the method developed by Gompert &amp; Buerkle (2009) implemented in introgress (Gompert &amp; Alex Buerkle 2010) to map admixture between Paracou genepools. We used individuals with more than 90% of the genotype belonging to the genepool to define parental allele frequencies and mapped admixture between the two pairs of S. sp1 - S. globulifera Paracou and S. sp1 - S. globulifera Regina as the remaining pair didn’t show any admixture signs with the admixture software. We furthered classified individuals as (i) pure-bred with a hybrid index \\(h\\) above 0.9, (ii) introgressed with \\(h \\in [0.6-0.9]\\), and (iii) admixed with \\(h \\in [0.5-0.6]\\). We obtained relatively low levels of admixture (Fig. 5.8) with 222 S. sp1 pure-bred, 108 S. globulifera Paracou pure-bred, and 30 S. globulifera Regina pure-bred. Only 5 individuals were admixed (2 S. sp1 - S. globulifera Regina and 3 S. sp1 - S. globulifera Paracou). Nevertheless S. sp1 showed 13(6%) individuals introgressed with S. globulifera Regina and S. globulifera Paracou showed 7(6%) individuals introgressed with S. sp1. Figure 5.8: Population structure and fraction of the genome inherited from S. sp1 for each individual (hybrid index or admixture coefficient). Population structure assessed with ADMIXTURE is represented with the color bar for each individual, with the percentage of membership to the S. sp1 gene pool represented by the bar height. The hybrid index and it’s confidence interval is represented by the black line and the white area. The white dashed line indicates levels used to define previous gene pools and parental alleles frequencies. References "],["neighbourhood-crowding-effect-on-neutral-and-adaptive-genetic-variation.html", "Chapter 6 Neighbourhood crowding effect on neutral and adaptive genetic variation 6.1 Simulated Animal Model 6.2 Neighbourhood crowding index 6.3 Genetic variance", " Chapter 6 Neighbourhood crowding effect on neutral and adaptive genetic variation We did environmental association analyses (Rellstab et al. 2015) in each complex using general linear mixed models developed for genome wide association studies (GWAS). We used mean neighbourhood crowding index (\\(NCI\\); Uriarte et al. 2004) over the last 30 years, an indirect measurement of access to light and forest gap dynamics, as the response variable and genetic structure (gene pools representing species) and relatedness (kinship matrix) as explanatory variables, as it is common practice (Rellstab et al. 2015). This analysis assumed that the neighbour crowding conditions where individuals have grown above 10-cm DBH are strongly correlated to the individual heritable phenotypes (e.g. Eckert et al. 2010). The mean neighborhood crowding index \\(NCI_i\\) from tree individual \\(i\\) was calculated as follows: \\[NCI_i=\\overline{\\sum_{j|\\delta_{i,j}&lt;20m}DBH^2_{j,t}.e^{-\\frac14\\delta_{i,j}}}\\] with \\(DBH_{j,t}\\) the diameter of the neighbouring tree \\(j\\) in year \\(t\\) and \\(\\delta_{i,j}\\) its distance to the individual tree \\(i\\). \\(NCI_i\\) is computed for all neighbours at a distance \\(\\delta_{i,j}\\) inferior to the maximum neighbouring distance of 20 meters. The power of neighbours \\(DBH_{j,t}\\) effect was set to 2 to represent a surface. The decrease of neighbours’ diameter effect with distance was set to -0.25 to represent trees at 20 meters of the focal trees having 1% of the effect of the same tree at 0 meters. \\(NCI_i\\) is computed as the mean of yearly \\(NCI_{i,t}\\) over the last 30 years denoted by the overline. We used genetic species and individual kinship in an animal model (Wilson et al. 2010) to estimate genetic variance associated with neighbour crowding index. We used a lognormal likelihood given that distributions of environmental variables were positive and skewed. We inferred individual kinship using KING (Manichaikul et al. 2010), as the method is robust to population structure. We set negative kinship values to null as they were confounding with population structure, and we further ensured that the matrix was positive-definite using the nearPD function from the R package Matrix. The environment \\(y_{s,i}\\) where individual \\(i\\) in species \\(s\\) grows was inferred with a lognormal distribution with the following formula: \\[y_{s,i} \\sim logN(log(\\mu_s.a_{i}),\\sigma^2_1)\\] \\[a_{i} \\sim MVlogN_N(log(1),\\sigma^2_2.K)\\] where \\(\\mu_s\\) is the mean environment of species \\(s\\), \\(a_i\\) is the breeding value of the individual \\(i\\) and \\(\\sigma^2_1\\) is the shape parameter of the lognormal. Individual breeding values \\(a_i\\) are defined following a multivariate lognormal law \\(\\mathcal{MVlogN}\\) of co-shape matrix defined as the product of the kinship matrix \\(K\\) with estimated individual genotypic variation \\(\\sigma^2_2\\). To estimate variances on a normal scale, we log-transformed species fixed effect, genetic additive values, and we calculated conditional and marginal \\(R^2\\) (Nakagawa &amp; Schielzeth 2013). A Bayesian method was used to infer parameters using stan language [Carpenter et al. (2017) and rstan package (Stan Development Team 2018) in the R environment (R Core Team 2020) using the No-U-Turn Sampler algorithm (NUTS, Hoffman &amp; Gelman 2014), which performs better for estimating genetic parameters and breeding values (Nishio &amp; Arakawa 2019). 6.1 Simulated Animal Model The aim of this subchapter is to explore the animal model with generated data to validate their behavior and use it on Symphonia real data. Let’s consider a set of \\(P=3\\) populations including each \\(Fam=3\\) families composed of \\(I = 14\\) individuals with arbitrary relationships (it’s only 126 individuals to do quick tests). Figure 6.1: Kinship matrix We used the following animal model with a lognormal distribution to estimate population and genotypic variance: \\[\\begin{equation} y_{p,i} \\sim \\mathcal{logN}(log(\\mu_p.a_{i}),\\sigma_1) \\\\ a_{p,i} \\sim \\mathcal{MVlogN_N}(log(1),\\sigma_2.K) \\tag{6.1} \\end{equation}\\] We fitted the equivalent model with following priors: \\[\\begin{equation} y_{p,i} \\sim \\mathcal{logN}(log(\\mu_p.\\hat{a_{i}}), \\sigma_1) \\\\ \\hat{a_{i}} = e^{\\sqrt{V_G}.A.\\epsilon_i} \\\\ \\epsilon_i \\sim \\mathcal{N}(0,1) \\\\ ~ \\\\ \\mu_p \\sim \\mathcal{logN}(log(1),1) \\\\ \\sigma_1 \\sim \\mathcal N_T(0,1) \\\\ ~ \\\\ V_Y = Var(log(y)) \\\\ V_P = Var(log(\\mu_p)) \\\\ V_R=\\sigma_1^2 \\\\ V_G = V_Y - V_P - V_R \\\\ \\tag{6.2} \\end{equation}\\] Table 6.1: Animal model fitted versus expected values. Parameter Estimate Expected Standard error \\(\\hat R\\) mu[1] 0.7484767 0.7357714 0.0535640 1.0054690 mu[2] 0.3968538 0.3633681 0.0308554 1.0010121 mu[3] 0.5184509 0.5420625 0.0469693 1.0023625 Vp 0.0711053 0.0841187 0.0151127 1.0011662 Vg 0.0772814 0.0837454 0.0223466 1.0014673 Vr 0.0385718 0.0400000 0.0145103 0.9997977 Figure 6.2: Parameters for Animal model trace plot and expected value in red. 6.2 Neighbourhood crowding index trees &lt;- src_sqlite(file.path(&quot;data&quot;, &quot;Paracou&quot;,&quot;trees&quot;, &quot;Paracou.sqlite&quot;)) %&gt;% tbl(&quot;Paracou&quot;) %&gt;% filter(Genus == &quot;Symphonia&quot;) %&gt;% filter(CensusYear == 2015) %&gt;% collect() trees &lt;- read_tsv(file.path(path, &quot;..&quot;, &quot;variantCalling&quot;, &quot;paracou3pop&quot;, &quot;symcapture.all.biallelic.snp.filtered.nonmissing.paracou3pop.fam&quot;), col_names = c(&quot;FID&quot;, &quot;IID&quot;, &quot;FIID&quot;, &quot;MIID&quot;, &quot;sex&quot;, &quot;phenotype&quot;)) %&gt;% mutate(Ind = gsub(&quot;.g.vcf&quot;, &quot;&quot;, IID)) %&gt;% mutate(X = gsub(&quot;P&quot;, &quot;&quot;, Ind)) %&gt;% separate(X, c(&quot;Plot&quot;, &quot;SubPlot&quot;, &quot;TreeFieldNum&quot;), convert = T) %&gt;% left_join(trees) %&gt;% left_join(read_tsv(file.path(path, &quot;bayescenv&quot;, &quot;paracou3pop.popmap&quot;), col_names = c(&quot;IID&quot;, &quot;pop&quot;))) cl &lt;- parallel::makeCluster(getOption(&quot;cl.cores&quot;, 4)) parallel::clusterExport(cl, list(&quot;trees&quot;)) NC &lt;- parallel::parLapply(cl, 1:nrow(trees), function(ind){ library(tidyverse) src_sqlite(file.path(&quot;data&quot;, &quot;Paracou&quot;, &quot;trees&quot;, &quot;Paracou.sqlite&quot;)) %&gt;% tbl(&quot;Paracou&quot;) %&gt;% filter(Plot == local(trees$Plot[ind])) %&gt;% filter(idTree != local(trees$idTree[ind])) %&gt;% mutate(dij = sqrt((local(trees$Xutm[ind]) - Xutm)^2+(local(trees$Yutm[ind]) - Yutm)^2)) %&gt;% filter(dij &lt; 20) %&gt;% mutate(con = ifelse(Genus == local(trees$Genus[ind]) &amp;&amp; Species == local(trees$Species[ind]), 1, 0)) %&gt;% mutate(DBH = CircCorr/pi) %&gt;% collect() %&gt;% group_by(CensusYear) %&gt;% summarise(NCI = sum(DBH*DBH*exp(-0.25*dij))) %&gt;% ungroup() %&gt;% summarise(idTree = local(trees$idTree[ind]), NCI = mean(NCI))}) parallel::stopCluster(cl) ; rm(cl) NC &lt;- bind_rows(NC) trees &lt;- left_join(trees, NC) %&gt;% dplyr::select(IID, Ind, pop, NCI) rm(NC) write_tsv(trees, file = &quot;save/NCI.tsv&quot;) 6.3 Genetic variance We used between individual kinship and a lognormal Animal model (Wilson et al. 2010) to estimate genetic variance associated to individuals’ global phenotype leaving in a given environment (see environmental association analyses with genome wide association study analyses in Rellstab et al. 2015). Animal model is calculated for the environmental values \\(y\\) of the \\(N\\) individuals with following formula: \\[\\begin{equation} y_{p,i} \\sim \\mathcal{logN}(log(a_{p,i}),\\sigma_1) \\\\ a_{p,i} \\sim \\mathcal{MVlogN_N}(log(\\mu_p),\\sigma_2.K) \\tag{6.3} \\end{equation}\\] where individual is defined as a normal law centered on the individual genetic additive effects \\(a\\) and associated individual remaining variance \\(\\sigma_R\\). Additive genetic variance \\(a\\) follow a multivariate lognormal law centered on the population mean \\(\\mu_{Population}\\) of covariance \\(\\sigma_G K\\). We fitted the equivalent model with following priors: \\[\\begin{equation} y_{p,i} \\sim \\mathcal{logN}(log(\\mu_p) + \\hat{\\sigma_2}.A.\\epsilon_i, \\sigma_1) \\\\ \\epsilon_i \\sim \\mathcal{N}(0,1) \\\\ ~ \\\\ \\mu_p \\sim \\mathcal{logN}(log(1),1) \\\\ \\sigma_1 \\sim \\mathcal N_T(0,1) \\\\ \\hat{\\sigma_2} = \\sqrt(V_G) ~ \\\\ V_Y = Var(log(y)) \\\\ V_P = Var(log(\\mu_p)) \\\\ V_G = V_Y - V_P - V_R \\\\ V_R=\\sigma_1^2 \\tag{6.4} \\end{equation}\\] Table 6.2: Summary table of the kinship growth model Variable Parameter Population Estimate \\(\\sigma\\) \\(\\hat{R}\\) NCI mu S. globulifera Paracou 0.7880048 0.0305778 0.9997771 NCI mu S. globulifera Regina 0.9443492 0.0643210 1.0003822 NCI mu S. sp1 0.9426952 0.0290419 1.0012267 NCI Vp 0.0071862 0.0033377 1.0004033 NCI Vg 0.0210950 0.0193455 1.0640539 NCI Vr 0.0922548 0.0193773 1.0615180 Figure 6.3: Traceplot for environmental variables. Figure 6.4: R2 for environmental variable Figure 6.5: Genetic variance partitioning for environmental variables. References "],["neutral-and-adaptive-genetic-variation-effect-on-individual-growth.html", "Chapter 7 Neutral and adaptive genetic variation effect on individual growth 7.1 Growth data 7.2 Simulated Growth and Animal Model 7.3 Genetic variance", " Chapter 7 Neutral and adaptive genetic variation effect on individual growth We investigated effects of ecological and evolutionary processes on individual growth, using genetic species and kinship. The individual growth of individual \\(i\\) in population \\(p\\) between individual recruitment \\(y_0\\) and 2017, correspond to the difference of DBH between the two years, and is defined with a hierarchical model in a lognormal distribution as follow: \\[DBH_{y=2017,p,i} - DBH_{y=y0,p,i} \\sim logN(log[\\sum_{y=y0}^{y=2017}AGR(DBH_{y,p,i})], \\sigma^2_1)\\] where the difference of DBH \\(DBH_{y=2017,p,i}-DBH_{y=y_0,p,i}\\) is defined with a lognormal distribution located on the logarithm of the sum of annual growth rates \\(AGR\\) during the period \\(y_0-2017\\) and of shape \\(\\sigma_1\\). The annual growth rates \\(AGR\\) for individual \\(i\\) in population \\(p\\) at year \\(y\\) with a diameter of \\(DBH_{y,p,i}\\) is defined following a Gompertz model (Gompertz 1825) already identified as the best model for growth-trajectories in Paracou (Hérault et al. 2011): \\[AGR(DBH_{y,p,i}) = Gmax_i.exp(-\\frac12[\\frac{log(\\frac{DBH_{y,p,i}}{Doptp})}{Ksp}]^2)\\] where \\(Gmax_i\\) is the maximum growth potential (maximal AGR during individual life) for individual \\(i\\), \\(Dopt_p\\) is the population optimal diameter at which the individual reach its maximum growth potential, and \\(Ks_p\\) is the population kurtosis defining the width of the bell-shaped growth-trajectory (see figure 1 in Hérault et al. 2011). To ease model inference population optimal diameter \\(Dopt_p\\) and kurtosis \\(Ks_p\\) were defined as random population effect centered on a global \\(Dopt\\) and \\(Ks\\) with corresponding variances \\(\\sigma^2_{P,Dopt}\\) and \\(\\sigma^2_{P,Ks}\\). Individual \\(i\\) maximum growth potential \\(Gmax_i\\) was defined in a nested Animal model with a lognormal distribution: \\[Gmax_i \\sim logN(log(Gmax_p.a_i), \\sigma_{R,Gmax})\\] \\[a_i \\sim MVlogN(log(1), \\sigma_{G,Gmax}.K)\\] where \\(Gmax_p\\) is the mean \\(Gmax\\) of population \\(p\\), \\(a_i\\) is the breeding value of individual \\(i\\), and \\(\\sigma_{R,Gmax}\\) is the shape of the lognormal distribution. Individual breeding values \\(a_i\\) are defined following a multivariate lognormal law \\(MVlogN\\) with a co-shape matrix defined as the product of the kinship matrix \\(K\\) and the genotypic variation \\(\\sigma_{G,Gmax}\\). To estimate variances on a normal-scale, we log-transformed population fixed effect, genetic additive values, and calculated conditional and marginal \\(R^2\\) (Nakagawa &amp; Schielzeth 2013). We used Bayesian inference with No-U-Turn Sampler (NUTS, Hoffman &amp; Gelman 2014) using stan language (Carpenter et al. 2017). 7.1 Growth data trees &lt;- src_sqlite(file.path(&quot;data&quot;, &quot;Paracou&quot;,&quot;trees&quot;, &quot;Paracou.sqlite&quot;)) %&gt;% tbl(&quot;Paracou&quot;) %&gt;% filter(Genus == &quot;Symphonia&quot;) %&gt;% mutate(DBH = CircCorr/pi) %&gt;% filter(!(CodeMeas %in% c(4))) %&gt;% collect() trees &lt;- read_tsv(file.path(path, &quot;..&quot;, &quot;variantCalling&quot;, &quot;paracou&quot;, &quot;symcapture.all.biallelic.snp.filtered.nonmissing.paracou.fam&quot;), col_names = c(&quot;FID&quot;, &quot;IID&quot;, &quot;FIID&quot;, &quot;MIID&quot;, &quot;sex&quot;, &quot;phenotype&quot;)) %&gt;% mutate(Ind = gsub(&quot;.g.vcf&quot;, &quot;&quot;, IID)) %&gt;% mutate(X = gsub(&quot;P&quot;, &quot;&quot;, Ind)) %&gt;% separate(X, c(&quot;Plot&quot;, &quot;SubPlot&quot;, &quot;TreeFieldNum&quot;), convert = T) %&gt;% left_join(trees) %&gt;% left_join(read_tsv(file.path(path, &quot;bayescenv&quot;, &quot;paracou3pop.popmap&quot;), col_names = c(&quot;IID&quot;, &quot;pop&quot;))) %&gt;% left_join(read_tsv(file.path(path, &quot;populations&quot;, &quot;paracou.hybridmap&quot;)), by = &quot;Ind&quot;, suffix = c(&quot;&quot;, &quot;.hybrid&quot;)) trees &lt;- trees %&gt;% group_by(Ind) %&gt;% mutate(Y0 = dplyr::first(CensusYear), DBH0 = dplyr::first(DBH), DBHtoday = dplyr::last(DBH), N = n()) %&gt;% ungroup() %&gt;% dplyr::select(Ind, Xutm, Yutm, IID, pop, Y0, DBH0, DBHtoday, N) %&gt;% unique() %&gt;% mutate(DBHtoday = ifelse(DBHtoday == DBH0, DBHtoday + 0.1, DBHtoday)) write_tsv(trees, file = &quot;save/Growth.tsv&quot;) 7.2 Simulated Growth and Animal Model We used the following growth model with a lognormal distribution to estimate individual growth potential and associated genotypic variation: \\[\\begin{equation} DBH_{y=today,p,i} - DBH_{y=y0,p,i} \\sim \\\\ \\mathcal{logN} (log(\\sum _{y=y_0} ^{y=today} \\theta_{1,p,i}.exp(-\\frac12.[\\frac{log(\\frac{DBH_{y,p,i}}{100.\\theta_{2,p}})}{\\theta_{3,p}}]^2)), \\sigma_1) \\\\ \\theta_{1,p,i} \\sim \\mathcal {logN}(log(\\theta_{1,p}.a_{1,i}), \\sigma_2) \\\\ \\theta_{2,p} \\sim \\mathcal {logN}(log(\\theta_2),\\sigma_3) \\\\ \\theta_{3,p} \\sim \\mathcal {logN}(log(\\theta_3),\\sigma_4) \\\\ a_{1,i} \\sim \\mathcal{MVlogN}(log(1), \\sigma_5.K) \\tag{7.1} \\end{equation}\\] We fitted the equivalent model with following priors: \\[\\begin{equation} DBH_{y=today,p,i} - DBH_{y=y0,p,i} \\sim \\\\ \\mathcal{logN} (log(\\sum _{y=y_0} ^{y=today} \\hat{\\theta_{1,p,i}}.exp(-\\frac12.[\\frac{log(\\frac{DBH_{y,p,i}}{100.\\hat{\\theta_{2,p}}})}{\\hat{\\theta_{3,p}}}]^2)), \\sigma_1) \\\\ \\hat{\\theta_{1,p,i}} = e^{log(\\theta_{1,p}.\\hat{a_{1,i}}) + \\sigma_2.\\epsilon_{1,i}} \\\\ \\hat{\\theta_{2,p}} = e^{log(\\theta_2) + \\sigma_3.\\epsilon_{2,p}} \\\\ \\hat{\\theta_{3,p}} = e^{log(\\theta_3) + \\sigma_4.\\epsilon_{3,p}} \\\\ \\hat{a_{1,i}} = e^{\\sigma_5.A.\\epsilon_{4,i}} \\\\ \\epsilon_{1,i} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{2,p} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{3,p} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{4,i} \\sim \\mathcal{N}(0,1) \\\\ ~ \\\\ (\\theta_{1,p}, \\theta_2, \\theta_3) \\sim \\mathcal{logN}^3(log(1),1) \\\\ (\\sigma_1, \\sigma_2, \\sigma_3, \\sigma_4, \\sigma_5) \\sim \\mathcal{N}^5_T(0,1) \\\\ ~ \\\\ V_P = Var(log(\\mu_p)) \\\\ V_G=\\sigma_5^2\\\\ V_R=\\sigma_2^2 \\tag{7.2} \\end{equation}\\] Table 7.1: Animal model fitted versus expected values. Parameter Estimate Standard error Expected \\(\\hat R\\) thetap1[1] 0.8266180 0.1121729 0.5300000 1.0008119 thetap1[2] 0.4816256 0.0889950 0.5400000 1.0015447 thetap1[3] 0.3413224 0.0629704 0.3600000 1.0009558 theta2 0.2596370 0.0764302 0.2500000 1.0004898 theta3 0.7276357 0.1440250 0.7000000 0.9996955 Vp 0.1379774 0.0635966 0.0352066 1.0016146 Vg 0.0280998 0.0758363 0.1350074 1.0016744 Vr 0.5217135 0.1090083 0.4489000 1.0170006 Figure 7.1: Parameters for Growth &amp; Animal model trace plot and expected value in red. 7.3 Genetic variance We used the following growth model with a lognormal distribution to estimate individual growth potential and associated genotypic variation: \\[\\begin{equation} DBH_{y=today,p,i} - DBH_{y=y0,p,i} \\sim \\\\ \\mathcal{logN} (log(\\sum _{y=y_0} ^{y=today} \\theta_{1,p,i}.exp(-\\frac12.[\\frac{log(\\frac{DBH_{y,p,i}}{100.\\theta_{2,p}})}{\\theta_{3,p}}]^2)), \\sigma_1) \\\\ \\theta_{1,p,i} \\sim \\mathcal {logN}(log(\\theta_{1,p}.a_{1,i}), \\sigma_2) \\\\ \\theta_{2,p} \\sim \\mathcal {logN}(log(\\theta_2),\\sigma_3) \\\\ \\theta_{3,p} \\sim \\mathcal {logN}(log(\\theta_3),\\sigma_4) \\\\ a_{1,i} \\sim \\mathcal{MVlogN}(log(1), \\sigma_5.K) \\tag{7.3} \\end{equation}\\] We fitted the equivalent model with following priors: \\[\\begin{equation} DBH_{y=today,p,i} - DBH_{y=y0,p,i} \\sim \\\\ \\mathcal{logN} (log(\\sum _{y=y_0} ^{y=today} \\hat{\\theta_{1,p,i}}.exp(-\\frac12.[\\frac{log(\\frac{DBH_{y,p,i}}{100.\\hat{\\theta_{2,p}}})}{\\hat{\\theta_{3,p}}}]^2)), \\sigma_1) \\\\ \\hat{\\theta_{1,p,i}} = e^{log(\\theta_{1,p}.\\hat{a_{1,i}}) + \\sigma_2.\\epsilon_{1,i}} \\\\ \\hat{\\theta_{2,p}} = e^{log(\\theta_2) + \\sigma_3.\\epsilon_{2,p}} \\\\ \\hat{\\theta_{3,p}} = e^{log(\\theta_3) + \\sigma_4.\\epsilon_{3,p}} \\\\ \\hat{a_{1,i}} = e^{\\sigma_5.A.\\epsilon_{4,i}} \\\\ \\epsilon_{1,i} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{2,p} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{3,p} \\sim \\mathcal{N}(0,1) \\\\ \\epsilon_{4,i} \\sim \\mathcal{N}(0,1) \\\\ ~ \\\\ (\\theta_{1,p}, \\theta_2, \\theta_3) \\sim \\mathcal{logN}^3(log(1),1) \\\\ (\\sigma_1, \\sigma_2, \\sigma_3, \\sigma_4, \\sigma_5) \\sim \\mathcal{N}^5_T(0,1) \\\\ ~ \\\\ V_P = Var(log(\\mu_p)) \\\\ V_G=\\sigma_5^2\\\\ V_R=\\sigma_2^2 \\tag{7.4} \\end{equation}\\] Table 7.2: Individual growth potential model. Parameter Estimate Standard error \\(\\hat R\\) \\(N_{eff}\\) thetap1[1] 0.5423337 0.0699702 1.002517 1993 thetap1[2] 0.5596376 0.1084135 1.001838 2331 thetap1[3] 0.3485849 0.0301761 1.002514 1218 theta2 0.2528277 0.0858377 1.005150 2249 theta3 0.6963378 0.1038580 1.006909 1345 sigma[1] 0.1373708 0.0742090 1.356851 22 sigma[2] 0.5075622 0.1714122 1.107800 61 sigma[3] 0.2805989 0.2994495 1.000577 2627 sigma[4] 0.1377079 0.2346745 1.002896 2934 sigma[5] 0.4684783 0.1850532 1.068632 87 Figure 7.2: Traceplot of model parameters. Figure 7.3: Energy of the model. Figure 7.4: Species predicted growth curve. Figure 7.5: R2 for Gmax. Figure 7.6: Genetic variance partitioning for Gmax. Figure 7.7: Relation between genotypic values for individual growth potential (Gmax) and neighbourhood crowding index (NCI), an indirect measurement of access to light, for different classes of diameters. Regression lines represent a linear model of form y ~ x. Annotations give for each diameter class the Pearson’s R correlation coefficient and the associated p-value. Figure 7.8: Spatial autocorrelogram (Moran’s I) of variables and associated genetic multiplicative values. References "],["references.html", "References", " References "]]
